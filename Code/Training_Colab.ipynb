{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ghudWqfJxx_",
      "metadata": {
        "id": "3ghudWqfJxx_"
      },
      "source": [
        "# Fusion ResNet Training on Google Colab\n",
        "\n",
        "This notebook allows you to run the Fusion ResNet training pipeline on Google Colab using a free GPU.\n",
        "\n",
        "### Instructions:\n",
        "1.  **Upload Data & Code**: Upload your entire `Research_Project` folder (containing `Code` and `Datasets`) to your Google Drive.\n",
        "2.  **Mount Drive**: Run the cell below to mount your Google Drive.\n",
        "3.  **Install Dependencies**: Run the installation cell.\n",
        "4.  **Data Augmentation**: Run `data_ingestion.py` which now parses 20-min overlapping windows (5x Dataset Expansion).\n",
        "5.  **Run Training**: Scalable Training with `AdamW` optimizer.\n",
        "6.  **Run XAI**: Generate explainability plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3aybLbJxyB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8f3aybLbJxyB",
        "outputId": "8d0d1496-25e8-4969-866e-7028f8c31e7e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ZrLCeOEJxyC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-ZrLCeOEJxyC",
        "outputId": "11bb9dcf-f61e-467f-a2f0-9ca279b64df5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# UPDATE THIS PATH to where you uploaded the 'Research Project' folder\n",
        "# Example: If you uploaded 'Research Project' to the root of 'MyDrive'\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/Research_Project/\"\n",
        "CODE_DIR = os.path.join(PROJECT_ROOT, \"Code\")\n",
        "\n",
        "# Check if path exists\n",
        "if not os.path.exists(PROJECT_ROOT):\n",
        "    print(f\"ERROR: Path not found: {PROJECT_ROOT}\")\n",
        "    print(\"Please verify your folder structure on Google Drive.\")\n",
        "else:\n",
        "    print(f\"Project found at: {PROJECT_ROOT}\")\n",
        "    os.chdir(CODE_DIR)\n",
        "    sys.path.append(CODE_DIR)\n",
        "    print(f\"Working directory set to: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95rMgqQDJxyC",
      "metadata": {
        "id": "95rMgqQDJxyC"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Fs9LUcfJxyD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5Fs9LUcfJxyD",
        "outputId": "b66004e9-d057-4a62-8946-1ebaa931ce30"
      },
      "outputs": [],
      "source": [
        "!pip install wfdb pandas==2.2.3 shap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-EHsA7c-JxyD",
      "metadata": {
        "id": "-EHsA7c-JxyD"
      },
      "source": [
        "### Step 1: Data Ingestion (Optional if already run locally)\n",
        "If you uploaded the `Datasets/processed` folder, you can skip this. If not, run this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OhepYqA5JxyD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OhepYqA5JxyD",
        "outputId": "5f1c5291-7fd2-4a6f-803a-c6cee2f26290"
      },
      "outputs": [],
      "source": [
        "!python data_ingestion.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uuCV2IHdJxyD",
      "metadata": {
        "id": "uuCV2IHdJxyD"
      },
      "source": [
        "### Step 2: Training\n",
        "This uses GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2FhBo0wJxyD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a2FhBo0wJxyD",
        "outputId": "e465ce01-bf2a-4f28-e5c9-5c9fd326dd19"
      },
      "outputs": [],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JErplfenJxyE",
      "metadata": {
        "id": "JErplfenJxyE"
      },
      "source": [
        "### Step 3: Explainability (XAI)\n",
        "Generates Grad-CAM and SHAP plots in `Code/figures/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p-yAmOlxJxyE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p-yAmOlxJxyE",
        "outputId": "053b8f60-572e-4b48-a723-d313ddf898eb"
      },
      "outputs": [],
      "source": [
        "!python xai.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-qNNIqm6xTAh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-qNNIqm6xTAh",
        "outputId": "0bafb00e-0676-4365-89b8-995e1475b14d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def quantize_model(fold_number):\n",
        "    # 1. Load the trained Keras model\n",
        "    model_path = f'/content/drive/MyDrive/Research_Project/Code/models/best_model_fold_{fold_number}.keras'\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # 2. Convert to TFLite with FP16 Quantization\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # 3. Save\n",
        "    tflite_path = f'/content/drive/MyDrive/Research_Project/Code/models/fusion_resnet_fold{fold_number}_fp16.tflite'\n",
        "    with open(tflite_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    # 4. Compare Sizes\n",
        "    keras_size = os.path.getsize(model_path) / 1024\n",
        "    tflite_size = os.path.getsize(tflite_path) / 1024\n",
        "    print(f\"Fold {fold_number} - Keras: {keras_size:.2f} KB | TFLite: {tflite_size:.2f} KB | Reduction: {(1-tflite_size/keras_size)*100:.1f}%\")\n",
        "\n",
        "# Quantize the best fold (Fold 5 based on your logs)\n",
        "print(\"--- QUANTIZING FOR EDGE DEPLOYMENT ---\")\n",
        "quantize_model(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y3sjh_J0Eb7L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y3sjh_J0Eb7L",
        "outputId": "2ccb9dd6-06cb-47c2-834a-4230ced75bd8"
      },
      "outputs": [],
      "source": [
        "# Install pyngrok to expose the local server\n",
        "!pip install streamlit pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nspsbwCWFglJ",
      "metadata": {
        "id": "nspsbwCWFglJ"
      },
      "outputs": [],
      "source": [
        "# Kill existing ngrok and streamlit processes\n",
        "!pkill ngrok\n",
        "!pkill streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z2sA13iD1TYs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z2sA13iD1TYs",
        "outputId": "403585f6-d6c3-4382-8ec4-8c6601ef6951"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Authenticate ngrok (Optional but recommended for stability)\n",
        "# Sign up at ngrok.com for a free token if you want the link to last longer\n",
        "!ngrok authtoken \"paste_your_token_here\"\n",
        "\n",
        "# Run Streamlit in the background\n",
        "!streamlit run /content/drive/MyDrive/Research_Project/Code/app.py &>/dev/null&\n",
        "\n",
        "# Create the public tunnel\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(f\"ðŸš€ Dashboard Live at: {public_url}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}