{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# NeuroFetal AI - Enhanced Fusion ResNet Training\n",
        "\n",
        "**Version 2.0** - With Advanced Enhancements:\n",
        "- 3-Input Architecture (FHR + Tabular + CSP)\n",
        "- Squeeze-and-Excitation (SE) Blocks\n",
        "- Multi-Head Self-Attention\n",
        "- 19 CSP Features\n",
        "- Focal Loss for Class Imbalance\n",
        "\n",
        "### Instructions:\n",
        "1. **Runtime -> Change runtime type -> GPU (T4)**\n",
        "2. Run cells in order\n",
        "3. Results save to `Reports/training_logs/`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auth-section",
      "metadata": {},
      "source": [
        "## GitHub Authentication\n",
        "Enter your Personal Access Token when prompted (not saved to notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "github-auth",
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "GITHUB_REPO = \"Krishna200608/NeuroFetal-AI\"\n",
        "GITHUB_TOKEN = getpass(\"GitHub Personal Access Token: \")\n",
        "\n",
        "os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
        "os.environ['GITHUB_REPO'] = GITHUB_REPO\n",
        "print(\"Token saved to session.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clone-section",
      "metadata": {},
      "source": [
        "## Step 0: Clone Repository\n",
        "Dataset is included in the repo at `Datasets/ctu_uhb_data/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clone-repo",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "GITHUB_REPO = os.environ.get('GITHUB_REPO', 'Krishna200608/NeuroFetal-AI')\n",
        "GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN', '')\n",
        "BRANCH = \"main\"\n",
        "\n",
        "if not os.path.exists(\"/content/NeuroFetal-AI\"):\n",
        "    if GITHUB_TOKEN:\n",
        "        !git clone --branch {BRANCH} https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git /content/NeuroFetal-AI\n",
        "    else:\n",
        "        !git clone --branch {BRANCH} https://github.com/{GITHUB_REPO}.git /content/NeuroFetal-AI\n",
        "    print(\"Repository cloned!\")\n",
        "else:\n",
        "    os.chdir(\"/content/NeuroFetal-AI\")\n",
        "    !git pull origin {BRANCH}\n",
        "    print(\"Repository updated!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-paths",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "PROJECT_ROOT = \"/content/NeuroFetal-AI/\"\n",
        "CODE_DIR = os.path.join(PROJECT_ROOT, \"Code\")\n",
        "SCRIPTS_DIR = os.path.join(CODE_DIR, \"scripts\")\n",
        "UTILS_DIR = os.path.join(CODE_DIR, \"utils\")\n",
        "DATASET_DIR = os.path.join(PROJECT_ROOT, \"Datasets\", \"ctu_uhb_data\")\n",
        "\n",
        "os.chdir(SCRIPTS_DIR)\n",
        "sys.path.insert(0, SCRIPTS_DIR)\n",
        "sys.path.insert(0, UTILS_DIR)\n",
        "sys.path.insert(0, CODE_DIR)\n",
        "\n",
        "print(f\"Working dir: {os.getcwd()}\")\n",
        "print(f\"Dataset: {len([f for f in os.listdir(DATASET_DIR) if f.endswith('.dat')])} records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "install-deps",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pip-install",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q wfdb shap scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-gpu",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ingestion-section",
      "metadata": {},
      "source": [
        "## Step 2: Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "data-ingestion",
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_dir = os.path.join(PROJECT_ROOT, \"Datasets\", \"processed\")\n",
        "if os.path.exists(os.path.join(processed_dir, \"X_fhr.npy\")):\n",
        "    print(\"Processed data exists. Skipping.\")\n",
        "else:\n",
        "    print(\"Running data ingestion...\")\n",
        "    !python data_ingestion.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_fhr = np.load(os.path.join(processed_dir, \"X_fhr.npy\"))\n",
        "X_tabular = np.load(os.path.join(processed_dir, \"X_tabular.npy\"))\n",
        "y = np.load(os.path.join(processed_dir, \"y.npy\"))\n",
        "\n",
        "print(f\"FHR: {X_fhr.shape}, Tabular: {X_tabular.shape}, Labels: {y.shape}\")\n",
        "print(f\"Class Balance: {np.mean(y):.2%} positive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model-section",
      "metadata": {},
      "source": [
        "## Step 3: Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inspect-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import build_enhanced_fusion_resnet\n",
        "\n",
        "model = build_enhanced_fusion_resnet(\n",
        "    input_shape_fhr=(X_fhr.shape[1], 1),\n",
        "    input_shape_tabular=(X_tabular.shape[1],),\n",
        "    input_shape_csp=(19,),\n",
        "    use_se_blocks=True,\n",
        "    use_attention=True\n",
        ")\n",
        "print(f\"Parameters: {model.count_params():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "training-section",
      "metadata": {},
      "source": [
        "## Step 4: Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-training",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xai-section",
      "metadata": {},
      "source": [
        "## Step 5: Explainability (XAI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-xai",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python xai.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "save-section",
      "metadata": {},
      "source": [
        "## Step 6: Push Results to GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "git-config",
      "metadata": {},
      "outputs": [],
      "source": [
        "!git config --global user.email \"krishnabhujel2006@gmail.com\"\n",
        "!git config --global user.name \"Krishna Bhujel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "git-push",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "!git add Code/models/*.keras Reports/training_logs/*.json Code/figures/*.png 2>/dev/null || true\n",
        "!git status\n",
        "!git commit -m \"Add trained model from Colab\" || echo \"Nothing to commit\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "results-section",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "show-results",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, glob\n",
        "\n",
        "log_dir = os.path.join(PROJECT_ROOT, \"Reports\", \"training_logs\")\n",
        "logs = sorted(glob.glob(os.path.join(log_dir, \"training_log_*.json\")))\n",
        "\n",
        "if logs:\n",
        "    with open(logs[-1]) as f:\n",
        "        r = json.load(f)\n",
        "    print(f\"Mean AUC: {r['summary']['mean_auc']:.4f} +/- {r['summary']['std_auc']:.4f}\")\n",
        "else:\n",
        "    print(\"No training logs found.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}