{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_md"
      },
      "source": [
        "# NeuroFetal AI — SOTA Training Pipeline\n",
        "\n",
        "**Version 4.0** — TimeGAN Augmentation Phase (AUC 0.90+ Target)\n",
        "\n",
        "This notebook orchestrates the full SOTA pipeline on Google Colab with GPU acceleration.\n",
        "\n",
        "### V4.0 Upgrade: TimeGAN Replaces SMOTE\n",
        "Instead of tabular SMOTE (linear interpolation), V4.0 uses a **1D Convolutional WGAN-GP** to generate\n",
        "synthetic pathological FHR/UC traces that preserve temporal dynamics. The generator was trained in\n",
        "`TimeGAN_Colab.ipynb` and produced 1,410 synthetic traces saved to `Datasets/synthetic/`.\n",
        "\n",
        "### Pipeline Steps\n",
        "| # | Phase | Script | Expected AUC Lift |\n",
        "|---|-------|--------|-------------------|\n",
        "| 1 | Setup | Clone repo (`feat/v4.0-timegan`), install deps | — |\n",
        "| 2 | Data Ingestion | `data_ingestion.py` — 18 features, pH 7.15, quality filter | +5–8 pts |\n",
        "| 3 | SSL Pretraining | `pretrain.py` — Masked Autoencoder on FHR | +2–3 pts |\n",
        "| 4 | Primary Training (TimeGAN) | `train.py --augmentation timegan` | +3–5 pts |\n",
        "| 4b | Primary Training (SMOTE baseline) | `train.py --augmentation smote` | baseline |\n",
        "| 5 | Ensemble Training | `train_diverse_ensemble.py` — InceptionNet + XGB + Stacking | +3–5 pts |\n",
        "| 6 | Evaluation | `evaluate_ensemble.py` — Temp scaling, TTA, calibration | +1–2 pts |\n",
        "| 7 | Deployment | `convert_to_tflite.py` — TFLite & auto-push | — |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_md"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "github_auth",
        "outputId": "675bd473-a158-49d6-de55-4528656622c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GitHub Token loaded from Secrets.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# 1. GitHub Authentication\n",
        "GITHUB_REPO = \"Krishna200608/NeuroFetal-AI\"\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "    print(\"✓ GitHub Token loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Error loading GITHUB_TOKEN from Secrets. Falling back to manual input.\")\n",
        "    from getpass import getpass\n",
        "    GITHUB_TOKEN = getpass(\"Enter GitHub Personal Access Token (PAT): \")\n",
        "\n",
        "os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
        "os.environ['GITHUB_REPO'] = GITHUB_REPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone_repo",
        "outputId": "1018a6c7-09b9-4f26-c07b-85c77ca9d305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Cloning into 'NeuroFetal-AI'...\n",
            "remote: Enumerating objects: 2361, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 2361 (delta 107), reused 99 (delta 88), pack-reused 2219 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2361/2361), 809.40 MiB | 33.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1381/1381), done.\n",
            "Updating files: 100% (1220/1220), done.\n",
            "Branch 'feat/v4.0-timegan' set up to track remote branch 'feat/v4.0-timegan' from 'origin'.\n",
            "Switched to a new branch 'feat/v4.0-timegan'\n",
            "From https://github.com/Krishna200608/NeuroFetal-AI\n",
            " * branch            feat/v4.0-timegan -> FETCH_HEAD\n",
            "Already up to date.\n",
            "✓ Cloned and checked out feat/v4.0-timegan!\n"
          ]
        }
      ],
      "source": [
        "# 2. Clone Repository & Checkout V4.0 Branch\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Reset to /content before deleting the repo folder\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Clean up any previous clone\n",
        "if os.path.exists(\"/content/NeuroFetal-AI\"):\n",
        "    shutil.rmtree(\"/content/NeuroFetal-AI\")\n",
        "\n",
        "print(\"Cloning repository...\")\n",
        "!git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\n",
        "\n",
        "os.chdir(\"/content/NeuroFetal-AI\")\n",
        "\n",
        "# Checkout V4.0 TimeGAN branch\n",
        "!git checkout feat/v4.0-timegan\n",
        "!git pull origin feat/v4.0-timegan\n",
        "print(\"✓ Cloned and checked out feat/v4.0-timegan!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "git_config_md"
      },
      "source": [
        "### 1.5 Git Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "git_config",
        "outputId": "d79612dc-a9dd-49f9-d04e-74dcc587204b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Git credentials set.\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.email \"krishnasikheriya001@gmail.com\"\n",
        "!git config --global user.name \"Krishna200608\"\n",
        "print(\"✓ Git credentials set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deps_md"
      },
      "source": [
        "### 1.6 Install Dependencies\n",
        "Installs all packages required for the full SOTA pipeline (including XGBoost/LightGBM for ensemble)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_deps",
        "outputId": "e03d40f4-4c37-4d75-daf0-9e005ac8a5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing libraries...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✓ Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing libraries...\")\n",
        "!pip install -q wfdb shap scipy imbalanced-learn pyngrok filterpy \\\n",
        "    scikit-learn matplotlib seaborn pandas numpy tensorflow \\\n",
        "    streamlit plotly python-dotenv xgboost lightgbm\n",
        "print(\"✓ Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_md"
      },
      "source": [
        "---\n",
        "## 2. Data Ingestion (Phase 1–2)\n",
        "\n",
        "Processes raw `.dat`/`.hea` files into clean `.npy` arrays.\n",
        "\n",
        "**SOTA enhancements:**\n",
        "- 18 tabular features (13 signal-derived: STV, LTV, accels/decels, baseline, variability…)\n",
        "- FHR normalization excluding 0-gaps\n",
        "- pH threshold relaxed to 7.15 (FIGO)\n",
        "- Signal quality filter (skip >50% loss)\n",
        "- Feature standardization (Z-score) with saved scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_ingestion",
        "outputId": "c4bda2a5-d75c-4fe5-cc09-0d76e1ab3077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 552 records.\n",
            "pH threshold: 7.15\n",
            "Max signal loss: 50%\n",
            "Processed 100 records...\n",
            "Processed 200 records...\n",
            "Processed 300 records...\n",
            "Processed 400 records...\n",
            "Processed 500 records...\n",
            "\n",
            "Processing complete.\n",
            "  Patients: 552\n",
            "  Total windows: 2546\n",
            "  Skipped (quality): 214\n",
            "  Shapes: X_fhr=(2546, 1200), X_uc=(2546, 1200), X_tabular=(2546, 18), y=(2546,)\n",
            "  Tabular features (18): ['Age', 'Parity', 'Gestation', 'Gravidity', 'Weight', 'fhr_baseline', 'fhr_stv', 'fhr_ltv', 'fhr_accel_count', 'fhr_decel_count', 'fhr_decel_area', 'fhr_range', 'fhr_iqr', 'fhr_entropy', 'uc_freq', 'uc_intensity_mean', 'fhr_uc_lag', 'signal_loss_pct']\n",
            "  Class balance: 470.0 compromised / 2546 total (18.5%)\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/data_ingestion.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_5_md"
      },
      "source": [
        "---\n",
        "## 3. Self-Supervised Pretraining\n",
        "\n",
        "Train the Masked Autoencoder (MAE) on unlabelled FHR data to learn robust temporal representations.\n",
        "\n",
        "Saves encoder weights → `Code/models/pretrained_fhr_encoder.weights.keras`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_pretrain",
        "outputId": "bd8abd13-a349-460f-aad7-c5fdf45442a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-21 08:31:37.664905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771662697.685697    1627 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771662697.692585    1627 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771662697.709324    1627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771662697.709347    1627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771662697.709351    1627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771662697.709354    1627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-21 08:31:37.713859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "============================================================\n",
            "SSL Pretraining: Masked Autoencoder\n",
            "============================================================\n",
            "Loading data...\n",
            "Data shape: (2546, 1200, 1)\n",
            "Building MAE...\n",
            "2026-02-21 08:31:46.982051: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771662706.984573    1627 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Starting training for 50 epochs...\n",
            "Epoch 1/50\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771662724.875304    1703 service.cc:152] XLA service 0x7d5cbc00d190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771662724.875338    1703 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-21 08:32:05.364254: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2026-02-21 08:32:06.194251: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:62] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. random_uniform/RandomUniform\n",
            "I0000 00:00:1771662728.006941    1703 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-21 08:32:11.412527: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 08:32:11.719571: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 08:32:11.870605: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "2026-02-21 08:32:12.870691: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.32 = (f32[64,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,128,1,150]{3,2,1,0} %bitcast.27442, f32[128,128,1,3]{3,2,1,0} %bitcast.27446), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-21 08:32:13.080930: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 08:32:13.589921: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 08:32:13.653815: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.783220241s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.32 = (f32[64,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,128,1,150]{3,2,1,0} %bitcast.27442, f32[128,128,1,3]{3,2,1,0} %bitcast.27446), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "I0000 00:00:1771662747.673047    1703 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 514ms/step - loss: 0.1268\n",
            "Epoch 2/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0582\n",
            "Epoch 3/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0504\n",
            "Epoch 4/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0455\n",
            "Epoch 5/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0421\n",
            "Epoch 6/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0405\n",
            "Epoch 7/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0395\n",
            "Epoch 8/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0366\n",
            "Epoch 9/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0361\n",
            "Epoch 10/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0377\n",
            "Epoch 11/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0345\n",
            "Epoch 12/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0349\n",
            "Epoch 13/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0347\n",
            "Epoch 14/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0341\n",
            "Epoch 15/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0349\n",
            "Epoch 16/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0340\n",
            "Epoch 17/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0334\n",
            "Epoch 18/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0335\n",
            "Epoch 19/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0325\n",
            "Epoch 20/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0317\n",
            "Epoch 21/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0325\n",
            "Epoch 22/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0331\n",
            "Epoch 23/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0321\n",
            "Epoch 24/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0316\n",
            "Epoch 25/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0318\n",
            "Epoch 26/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0313\n",
            "Epoch 27/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0316\n",
            "Epoch 28/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0320\n",
            "Epoch 29/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0311\n",
            "Epoch 30/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0309\n",
            "Epoch 31/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0314\n",
            "Epoch 32/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0307\n",
            "Epoch 33/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0299\n",
            "Epoch 34/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0305\n",
            "Epoch 35/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0297\n",
            "Epoch 36/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0294\n",
            "Epoch 37/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0290\n",
            "Epoch 38/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0296\n",
            "Epoch 39/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0288\n",
            "Epoch 40/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0295\n",
            "Epoch 41/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0334\n",
            "Epoch 42/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0297\n",
            "Epoch 43/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0296\n",
            "Epoch 44/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0284\n",
            "Epoch 45/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0295\n",
            "Epoch 46/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0286\n",
            "Epoch 47/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0291\n",
            "Epoch 48/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0292\n",
            "Epoch 49/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0285\n",
            "Epoch 50/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0283\n",
            "Saving encoder model to /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "✓ Pretraining complete!\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/pretrain.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_md"
      },
      "source": [
        "---\n",
        "## 4. Primary Model Training (V4.0 TimeGAN)\n",
        "\n",
        "Train the **AttentionFusionResNet** using 5-Fold Cross-Validation with **TimeGAN augmentation**.\n",
        "\n",
        "**V4.0 upgrade:** Replaces tabular SMOTE with pre-generated synthetic pathological traces from WGAN-GP.\n",
        "\n",
        "**SOTA enhancements (carried from V3.0):**\n",
        "- 200 epochs with cosine annealing + warmup\n",
        "- Focal Loss (α=0.65, γ=2.0)\n",
        "- 4x data augmentation (SpecAugment + CutMix + time-warp + jitter + mixup)\n",
        "- AdamW with weight decay 5e-4\n",
        "- SSL pretrained backbone\n",
        "- Early stopping patience = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pull_before_train",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001533ab-e6bb-41d4-c344-bf93c10cbe4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Krishna200608/NeuroFetal-AI\n",
            " * branch            feat/v4.0-timegan -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# Pull latest changes from V4.0 branch\n",
        "!git pull origin feat/v4.0-timegan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_training",
        "outputId": "5e33063c-0d7b-4873-f457-4fb61055f26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-21 08:34:18.482456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771662858.503655    2809 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771662858.510652    2809 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771662858.527201    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771662858.527229    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771662858.527233    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771662858.527238    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-21 08:34:18.531942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "============================================================\n",
            "NeuroFetal AI - Enhanced Training Pipeline\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Data loaded:\n",
            "  FHR: (2546, 1200, 1)\n",
            "  Tabular: (2546, 18)\n",
            "  Labels: (2546,)\n",
            "  UC: Available\n",
            "  Class balance: 18.46% positive (compromised)\n",
            "\n",
            "✓ Real UC data available - CSP features ENABLED.\n",
            "\n",
            "========================================\n",
            "Running Fold 1/5\n",
            "========================================\n",
            "\n",
            "Applying TimeGAN Augmentation to Fold 1...\n",
            "  Before: 376.0 positives / 2036 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2490 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  After:  830.0 positives / 2490 total\n",
            "\n",
            "Extracting CSP features for Fold 1...\n",
            "  CSP features: train=(2490, 19), val=(510, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 1\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2490 → 9960\n",
            "Applied label smoothing (factor=0.1)\n",
            "2026-02-21 08:34:36.425838: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771662876.427418    2809 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "I0000 00:00:1771662879.016067    2809 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9960 samples, validating on 510 samples\n",
            "Class balance - Train: 35.00% positive, Val: 18.43% positive\n",
            "Epoch 1/150\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771662902.183703    2909 service.cc:152] XLA service 0x7d83cc002870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771662902.183737    2909 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-21 08:35:02.844404: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2026-02-21 08:35:52.793217: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 08:35:52.872021: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.21 = (f32[32,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,1,150]{3,2,1,0} %bitcast.70353, f32[128,128,1,3]{3,2,1,0} %bitcast.70357), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/AttentionFusionResNet_1/shared_fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-21 08:35:53.236718: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 08:35:53.268611: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.396687978s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.21 = (f32[32,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,1,150]{3,2,1,0} %bitcast.70353, f32[128,128,1,3]{3,2,1,0} %bitcast.70357), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/AttentionFusionResNet_1/shared_fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "I0000 00:00:1771662975.576573    2909 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - auc: 0.0000e+00 - loss: 0.2614 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.49867, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 610ms/step - auc: 0.0000e+00 - loss: 0.2613 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4987 - val_loss: 0.1419 - val_sens_at_spec_85: 0.1277 - learning_rate: 1.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1647 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.49867 to 0.51984, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1646 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5198 - val_loss: 0.1484 - val_sens_at_spec_85: 0.0957 - learning_rate: 2.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1363 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.51984 to 0.57168, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1363 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5717 - val_loss: 0.1421 - val_sens_at_spec_85: 0.2553 - learning_rate: 3.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1366 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.57168\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1366 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5683 - val_loss: 0.1570 - val_sens_at_spec_85: 0.1702 - learning_rate: 4.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1342 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.57168\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1342 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5554 - val_loss: 0.1481 - val_sens_at_spec_85: 0.1915 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1289 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.57168\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1289 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5642 - val_loss: 0.1639 - val_sens_at_spec_85: 0.2234 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1284 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.57168 to 0.58245, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1284 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5824 - val_loss: 0.1420 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.9994e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1243 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc improved from 0.58245 to 0.58283, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1243 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5828 - val_loss: 0.1426 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9977e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1226 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc improved from 0.58283 to 0.65099, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1226 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6510 - val_loss: 0.1394 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.9947e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1194 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.65099 to 0.66390, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1194 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6639 - val_loss: 0.1379 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.9906e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1191 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.66390\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1191 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6546 - val_loss: 0.1411 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9853e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1154 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.66390\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1154 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6494 - val_loss: 0.1435 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.9789e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1142 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc improved from 0.66390 to 0.67787, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1142 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6779 - val_loss: 0.1358 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.9713e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1136 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc improved from 0.67787 to 0.69460, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1136 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6946 - val_loss: 0.1342 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.9625e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1130 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.69460\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1130 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6359 - val_loss: 0.1743 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9526e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1104 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.69460\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1103 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6723 - val_loss: 0.1504 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.9416e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1093 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.69460\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1093 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6853 - val_loss: 0.1414 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.9293e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1059 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc improved from 0.69460 to 0.69887, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1059 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6989 - val_loss: 0.1351 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9160e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1027 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.69887\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1027 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6869 - val_loss: 0.1453 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.9015e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0999 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc improved from 0.69887 to 0.72973, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0999 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7297 - val_loss: 0.1437 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.8859e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0944 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.72973\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0944 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7050 - val_loss: 0.1406 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.8691e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0954 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.72973\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0954 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6342 - val_loss: 0.3825 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.8513e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0911 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.72973\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0911 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6694 - val_loss: 0.1577 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.8323e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0910 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc improved from 0.72973 to 0.76101, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0909 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7610 - val_loss: 0.1905 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.8123e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0801 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc improved from 0.76101 to 0.76834, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0801 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7683 - val_loss: 0.1403 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.7911e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0800 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.76834\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0800 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7593 - val_loss: 0.1664 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.7689e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0760 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.76834\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0760 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7510 - val_loss: 0.1950 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.7457e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.76834\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0690 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7004 - val_loss: 0.2193 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.7213e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0700 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.76834\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0700 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7579 - val_loss: 0.1824 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.6960e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0624 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.76834\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0624 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7621 - val_loss: 0.1741 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.6696e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0638 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.76834\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0638 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7373 - val_loss: 0.1997 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.6421e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0604 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc improved from 0.76834 to 0.77869, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0605 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7787 - val_loss: 0.2152 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.6137e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0565 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.77869\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0565 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7330 - val_loss: 0.2184 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.5843e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc improved from 0.77869 to 0.79627, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7963 - val_loss: 0.1309 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.5539e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0511 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0511 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7561 - val_loss: 0.4305 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.5225e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0509 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0509 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7945 - val_loss: 0.3373 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.4902e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0497 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0497 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7681 - val_loss: 0.2268 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.4570e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0412 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0412 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7853 - val_loss: 0.3183 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.4228e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7535 - val_loss: 0.3496 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.3878e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0379 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0379 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7669 - val_loss: 0.2905 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.3518e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0383 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0383 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7543 - val_loss: 0.2483 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.3150e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0508 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.79627\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0507 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7750 - val_loss: 0.4458 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.2773e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc improved from 0.79627 to 0.80372, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8037 - val_loss: 0.3176 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.2388e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0329 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0329 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7508 - val_loss: 0.6303 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.1995e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0315 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0315 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7630 - val_loss: 0.4311 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.1594e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0369 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0369 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7798 - val_loss: 0.5421 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.1185e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0296 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0296 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7901 - val_loss: 0.3957 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.0768e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0308 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0308 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7685 - val_loss: 0.4216 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.0344e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0271 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0271 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7631 - val_loss: 0.9430 - val_sens_at_spec_85: 0.4362 - learning_rate: 3.9913e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0225 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0225 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7323 - val_loss: 1.1167 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.9475e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0198 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0198 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7798 - val_loss: 0.5514 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.9030e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0214 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0214 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7991 - val_loss: 0.2856 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.8578e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0267 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0267 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7850 - val_loss: 0.9264 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.8120e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0219 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0219 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7785 - val_loss: 0.6324 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.7656e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0255 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0255 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7338 - val_loss: 1.3884 - val_sens_at_spec_85: 0.4787 - learning_rate: 3.7186e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7908 - val_loss: 0.5469 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.6710e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0276 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0276 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7702 - val_loss: 0.6300 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.6229e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0172 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0172 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7779 - val_loss: 0.8723 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.5742e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0204 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0205 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7834 - val_loss: 0.8129 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.5251e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0180 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0180 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7884 - val_loss: 0.9022 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.4754e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7490 - val_loss: 1.1898 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.4253e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7725 - val_loss: 0.7015 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.3748e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0198 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0198 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7616 - val_loss: 0.5925 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.3239e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0173 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0173 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7863 - val_loss: 0.5114 - val_sens_at_spec_85: 0.5745 - learning_rate: 3.2725e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0131 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0131 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7915 - val_loss: 0.6084 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.2209e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0212 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0212 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7685 - val_loss: 1.0455 - val_sens_at_spec_85: 0.4468 - learning_rate: 3.1688e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0134 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0134 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7929 - val_loss: 0.8645 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.1165e-04\n",
            "Epoch 68/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0167 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0167 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7773 - val_loss: 0.7264 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.0638e-04\n",
            "Epoch 69/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0153 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0152 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7427 - val_loss: 1.6329 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.0109e-04\n",
            "Epoch 70/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0139 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0139 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7855 - val_loss: 1.1187 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.9578e-04\n",
            "Epoch 71/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0106 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0106 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7424 - val_loss: 1.4716 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.9045e-04\n",
            "Epoch 72/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0135 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7674 - val_loss: 1.1552 - val_sens_at_spec_85: 0.5851 - learning_rate: 2.8509e-04\n",
            "Epoch 73/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0122 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0122 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7612 - val_loss: 1.0935 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.7972e-04\n",
            "Epoch 74/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0166 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0165 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7836 - val_loss: 1.0105 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.7434e-04\n",
            "Epoch 75/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0129 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0129 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7602 - val_loss: 1.0656 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.6894e-04\n",
            "Epoch 76/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0117 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0117 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7472 - val_loss: 1.3648 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.6353e-04\n",
            "Epoch 77/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0113 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0113 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7494 - val_loss: 1.5137 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.5812e-04\n",
            "Epoch 78/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0132 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0132 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7851 - val_loss: 0.8336 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.5271e-04\n",
            "Epoch 79/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0169 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.80372\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0169 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7949 - val_loss: 0.6902 - val_sens_at_spec_85: 0.5851 - learning_rate: 2.4729e-04\n",
            "Epoch 80/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0148 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc improved from 0.80372 to 0.81429, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0147 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8143 - val_loss: 0.9159 - val_sens_at_spec_85: 0.5957 - learning_rate: 2.4188e-04\n",
            "Epoch 81/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0107 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0107 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7955 - val_loss: 1.2397 - val_sens_at_spec_85: 0.5957 - learning_rate: 2.3647e-04\n",
            "Epoch 82/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7721 - val_loss: 1.4608 - val_sens_at_spec_85: 0.5745 - learning_rate: 2.3106e-04\n",
            "Epoch 83/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0121 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0121 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7576 - val_loss: 1.6099 - val_sens_at_spec_85: 0.5851 - learning_rate: 2.2566e-04\n",
            "Epoch 84/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0090 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0090 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7904 - val_loss: 1.5075 - val_sens_at_spec_85: 0.5745 - learning_rate: 2.2028e-04\n",
            "Epoch 85/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0074 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0074 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7900 - val_loss: 1.2343 - val_sens_at_spec_85: 0.6064 - learning_rate: 2.1491e-04\n",
            "Epoch 86/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0187 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0187 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7870 - val_loss: 0.8834 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.0955e-04\n",
            "Epoch 87/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0082 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0082 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7975 - val_loss: 0.9818 - val_sens_at_spec_85: 0.6064 - learning_rate: 2.0422e-04\n",
            "Epoch 88/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7755 - val_loss: 0.9028 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.9891e-04\n",
            "Epoch 89/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0073 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0073 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7854 - val_loss: 1.3126 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.9362e-04\n",
            "Epoch 90/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0061 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0061 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7632 - val_loss: 1.3293 - val_sens_at_spec_85: 0.4894 - learning_rate: 1.8835e-04\n",
            "Epoch 91/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7711 - val_loss: 1.4845 - val_sens_at_spec_85: 0.5426 - learning_rate: 1.8312e-04\n",
            "Epoch 92/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0055 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0055 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7451 - val_loss: 1.6940 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.7791e-04\n",
            "Epoch 93/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0066 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0067 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7781 - val_loss: 1.1527 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.7275e-04\n",
            "Epoch 94/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0058 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0058 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7665 - val_loss: 1.3635 - val_sens_at_spec_85: 0.5000 - learning_rate: 1.6761e-04\n",
            "Epoch 95/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7379 - val_loss: 1.6277 - val_sens_at_spec_85: 0.5426 - learning_rate: 1.6252e-04\n",
            "Epoch 96/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0093 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0094 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7688 - val_loss: 0.9982 - val_sens_at_spec_85: 0.5000 - learning_rate: 1.5747e-04\n",
            "Epoch 97/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0070 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0070 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7702 - val_loss: 1.3207 - val_sens_at_spec_85: 0.5426 - learning_rate: 1.5246e-04\n",
            "Epoch 98/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0099 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0099 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7569 - val_loss: 1.3886 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.4749e-04\n",
            "Epoch 99/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0069 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0069 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7491 - val_loss: 1.6655 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.4258e-04\n",
            "Epoch 100/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7486 - val_loss: 1.6514 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.3771e-04\n",
            "Epoch 101/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0070 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0070 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7489 - val_loss: 1.6224 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.3290e-04\n",
            "Epoch 102/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7443 - val_loss: 1.8316 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.2814e-04\n",
            "Epoch 103/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 103: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7398 - val_loss: 1.6828 - val_sens_at_spec_85: 0.4787 - learning_rate: 1.2344e-04\n",
            "Epoch 104/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0047 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 104: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0047 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7341 - val_loss: 1.6477 - val_sens_at_spec_85: 0.5000 - learning_rate: 1.1880e-04\n",
            "Epoch 105/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 105: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7699 - val_loss: 1.3833 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.1422e-04\n",
            "Epoch 106/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 106: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7459 - val_loss: 1.6576 - val_sens_at_spec_85: 0.5426 - learning_rate: 1.0970e-04\n",
            "Epoch 107/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 107: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7251 - val_loss: 1.5628 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.0525e-04\n",
            "Epoch 108/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.0000e+00 - loss: 0.0065 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 108: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0065 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7193 - val_loss: 1.7648 - val_sens_at_spec_85: 0.4787 - learning_rate: 1.0087e-04\n",
            "Epoch 109/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0042 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 109: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0042 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7480 - val_loss: 1.4211 - val_sens_at_spec_85: 0.4894 - learning_rate: 9.6559e-05\n",
            "Epoch 110/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0041 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 110: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0041 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7291 - val_loss: 1.6694 - val_sens_at_spec_85: 0.4894 - learning_rate: 9.2319e-05\n",
            "Epoch 111/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.0000e+00 - loss: 0.0035 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 111: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0035 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7286 - val_loss: 1.6733 - val_sens_at_spec_85: 0.5000 - learning_rate: 8.8153e-05\n",
            "Epoch 112/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0039 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 112: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0039 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7274 - val_loss: 1.7179 - val_sens_at_spec_85: 0.5106 - learning_rate: 8.4063e-05\n",
            "Epoch 113/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 113: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7304 - val_loss: 1.6996 - val_sens_at_spec_85: 0.5000 - learning_rate: 8.0051e-05\n",
            "Epoch 114/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0050 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 114: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0050 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7304 - val_loss: 1.7495 - val_sens_at_spec_85: 0.5000 - learning_rate: 7.6119e-05\n",
            "Epoch 115/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0042 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 115: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0042 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7410 - val_loss: 1.6265 - val_sens_at_spec_85: 0.5106 - learning_rate: 7.2268e-05\n",
            "Epoch 116/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 116: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7184 - val_loss: 1.7343 - val_sens_at_spec_85: 0.5000 - learning_rate: 6.8501e-05\n",
            "Epoch 117/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0038 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 117: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0038 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7305 - val_loss: 1.5485 - val_sens_at_spec_85: 0.4894 - learning_rate: 6.4819e-05\n",
            "Epoch 118/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0030 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 118: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0030 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7301 - val_loss: 1.6982 - val_sens_at_spec_85: 0.4894 - learning_rate: 6.1224e-05\n",
            "Epoch 119/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0033 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 119: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0033 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7274 - val_loss: 1.7208 - val_sens_at_spec_85: 0.4787 - learning_rate: 5.7717e-05\n",
            "Epoch 120/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 120: val_auc did not improve from 0.81429\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7207 - val_loss: 1.7134 - val_sens_at_spec_85: 0.5106 - learning_rate: 5.4301e-05\n",
            "Epoch 120: early stopping\n",
            "Restoring model weights from the end of the best epoch: 80.\n",
            "\n",
            "Fold 1 Results:\n",
            "  loss: 0.9159\n",
            "  auc: 0.8143\n",
            "  sens_at_spec_85: 0.5957\n",
            "\n",
            "========================================\n",
            "Running Fold 2/5\n",
            "========================================\n",
            "\n",
            "Applying TimeGAN Augmentation to Fold 2...\n",
            "  Before: 376.0 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  After:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 2...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 2\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.99% positive, Val: 18.47% positive\n",
            "Epoch 1/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - auc: 0.0000e+00 - loss: 0.2809 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.50704, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 658ms/step - auc: 0.0000e+00 - loss: 0.2807 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5070 - val_loss: 0.1483 - val_sens_at_spec_85: 0.0851 - learning_rate: 1.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1469 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.50704 to 0.58495, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1469 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5850 - val_loss: 0.1485 - val_sens_at_spec_85: 0.2234 - learning_rate: 2.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1415 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1415 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5665 - val_loss: 0.1421 - val_sens_at_spec_85: 0.2660 - learning_rate: 3.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1355 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1355 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5693 - val_loss: 0.1439 - val_sens_at_spec_85: 0.1383 - learning_rate: 4.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1347 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1347 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5821 - val_loss: 0.1420 - val_sens_at_spec_85: 0.2553 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1305 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1305 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5312 - val_loss: 0.3186 - val_sens_at_spec_85: 0.1489 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1297 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1297 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5118 - val_loss: 0.1537 - val_sens_at_spec_85: 0.1383 - learning_rate: 4.9994e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1268 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1268 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5276 - val_loss: 0.1430 - val_sens_at_spec_85: 0.0745 - learning_rate: 4.9977e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1242 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.58495\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1242 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5678 - val_loss: 0.1457 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.9947e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1245 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.58495 to 0.59322, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1245 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5932 - val_loss: 0.1416 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.9906e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1205 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc improved from 0.59322 to 0.61113, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1206 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6111 - val_loss: 0.1405 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9853e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1199 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.61113\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1199 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5974 - val_loss: 0.1440 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.9789e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1125 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc did not improve from 0.61113\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1125 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5820 - val_loss: 0.2478 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.9713e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc did not improve from 0.61113\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6043 - val_loss: 0.1514 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.9625e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1136 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc improved from 0.61113 to 0.61991, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1136 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6199 - val_loss: 0.1477 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9526e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1091 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc improved from 0.61991 to 0.62502, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1091 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6250 - val_loss: 0.1478 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9416e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1056 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.62502\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1056 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6066 - val_loss: 0.1481 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.9293e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1067 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc improved from 0.62502 to 0.63140, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1067 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6314 - val_loss: 0.1440 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.9160e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0972 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.63140\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0972 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6059 - val_loss: 0.1642 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.9015e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0992 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc improved from 0.63140 to 0.64019, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0992 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6402 - val_loss: 0.1471 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.8859e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0951 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.64019\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0951 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6091 - val_loss: 0.2018 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.8691e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0894 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.64019\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0895 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6384 - val_loss: 0.1547 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.8513e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0903 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc improved from 0.64019 to 0.67147, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0903 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6715 - val_loss: 0.1518 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.8323e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0837 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0837 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6488 - val_loss: 0.1654 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.8123e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0827 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0827 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5834 - val_loss: 0.2100 - val_sens_at_spec_85: 0.1915 - learning_rate: 4.7911e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0788 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0788 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6302 - val_loss: 0.1848 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.7689e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0747 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0747 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6114 - val_loss: 0.1907 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.7457e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0698 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0698 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6220 - val_loss: 0.1880 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.7213e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0716 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0716 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6331 - val_loss: 0.1806 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.6960e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0677 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0677 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6595 - val_loss: 0.2014 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.6696e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0604 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0604 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6669 - val_loss: 0.1881 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.6421e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0560 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.67147\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0560 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6339 - val_loss: 0.3122 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.6137e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0607 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc improved from 0.67147 to 0.68434, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0607 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6843 - val_loss: 0.2366 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.5843e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0485 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.68434\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0486 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6702 - val_loss: 0.2370 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.5539e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0567 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.68434\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0567 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6404 - val_loss: 0.3009 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.5225e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.68434\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0535 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6622 - val_loss: 0.3917 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.4902e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0527 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.68434\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0527 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6555 - val_loss: 0.2962 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.4570e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0401 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.68434\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0401 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6558 - val_loss: 0.3769 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.4228e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0391 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.68434\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0391 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6643 - val_loss: 0.6128 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.3878e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0395 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc improved from 0.68434 to 0.69724, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0395 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6972 - val_loss: 0.5055 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.3518e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0386 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0386 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6898 - val_loss: 0.6490 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.3150e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0355 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0355 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6564 - val_loss: 0.7576 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.2773e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0341 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0341 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6711 - val_loss: 0.5716 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.2388e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0360 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0360 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6727 - val_loss: 0.4981 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.1995e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0310 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0310 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6733 - val_loss: 0.6753 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.1594e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0249 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0249 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6427 - val_loss: 1.1068 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.1185e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0343 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0343 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6763 - val_loss: 0.9792 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.0768e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0325 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0325 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6702 - val_loss: 0.5501 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.0344e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0350 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.69724\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0350 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6905 - val_loss: 0.8562 - val_sens_at_spec_85: 0.3936 - learning_rate: 3.9913e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0328 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc improved from 0.69724 to 0.71589, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0328 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7159 - val_loss: 0.9406 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.9475e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0300 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0299 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6994 - val_loss: 0.7117 - val_sens_at_spec_85: 0.3298 - learning_rate: 3.9030e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0279 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0279 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6906 - val_loss: 0.7488 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.8578e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0204 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0204 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6734 - val_loss: 1.3017 - val_sens_at_spec_85: 0.3617 - learning_rate: 3.8120e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7041 - val_loss: 0.8467 - val_sens_at_spec_85: 0.4043 - learning_rate: 3.7656e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0264 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0264 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6889 - val_loss: 1.0353 - val_sens_at_spec_85: 0.4043 - learning_rate: 3.7186e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0150 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0150 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7078 - val_loss: 1.1984 - val_sens_at_spec_85: 0.4787 - learning_rate: 3.6710e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6847 - val_loss: 1.1856 - val_sens_at_spec_85: 0.3617 - learning_rate: 3.6229e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0198 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0198 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6954 - val_loss: 0.8366 - val_sens_at_spec_85: 0.4362 - learning_rate: 3.5742e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0230 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0229 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6702 - val_loss: 1.4397 - val_sens_at_spec_85: 0.3191 - learning_rate: 3.5251e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6752 - val_loss: 1.2620 - val_sens_at_spec_85: 0.2447 - learning_rate: 3.4754e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6914 - val_loss: 0.8806 - val_sens_at_spec_85: 0.3404 - learning_rate: 3.4253e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0145 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0145 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7080 - val_loss: 1.6525 - val_sens_at_spec_85: 0.4468 - learning_rate: 3.3748e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6821 - val_loss: 1.5479 - val_sens_at_spec_85: 0.3936 - learning_rate: 3.3239e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0156 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7106 - val_loss: 1.3194 - val_sens_at_spec_85: 0.4468 - learning_rate: 3.2725e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0095 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0095 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7050 - val_loss: 1.2147 - val_sens_at_spec_85: 0.4149 - learning_rate: 3.2209e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0177 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0177 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7032 - val_loss: 0.9647 - val_sens_at_spec_85: 0.4574 - learning_rate: 3.1688e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7113 - val_loss: 0.9717 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.1165e-04\n",
            "Epoch 68/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0150 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0150 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7070 - val_loss: 0.8582 - val_sens_at_spec_85: 0.4149 - learning_rate: 3.0638e-04\n",
            "Epoch 69/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0123 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0123 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6970 - val_loss: 1.6130 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.0109e-04\n",
            "Epoch 70/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6882 - val_loss: 1.1425 - val_sens_at_spec_85: 0.3617 - learning_rate: 2.9578e-04\n",
            "Epoch 71/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0158 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.71589\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0158 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7074 - val_loss: 1.4105 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.9045e-04\n",
            "Epoch 72/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0105 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc improved from 0.71589 to 0.71876, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0105 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7188 - val_loss: 1.6721 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.8509e-04\n",
            "Epoch 73/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0165 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.71876\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0165 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7090 - val_loss: 1.0218 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.7972e-04\n",
            "Epoch 74/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.71876\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7060 - val_loss: 1.2094 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.7434e-04\n",
            "Epoch 75/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0096 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.71876\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0096 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7132 - val_loss: 1.5284 - val_sens_at_spec_85: 0.4574 - learning_rate: 2.6894e-04\n",
            "Epoch 76/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0073 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.71876\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0074 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7140 - val_loss: 1.0855 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.6353e-04\n",
            "Epoch 77/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc improved from 0.71876 to 0.72084, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7208 - val_loss: 1.2292 - val_sens_at_spec_85: 0.4255 - learning_rate: 2.5812e-04\n",
            "Epoch 78/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6895 - val_loss: 1.8513 - val_sens_at_spec_85: 0.4149 - learning_rate: 2.5271e-04\n",
            "Epoch 79/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0084 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0084 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7010 - val_loss: 1.1180 - val_sens_at_spec_85: 0.4043 - learning_rate: 2.4729e-04\n",
            "Epoch 80/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0132 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0132 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7074 - val_loss: 1.4451 - val_sens_at_spec_85: 0.4255 - learning_rate: 2.4188e-04\n",
            "Epoch 81/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0095 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0095 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6866 - val_loss: 1.1866 - val_sens_at_spec_85: 0.4362 - learning_rate: 2.3647e-04\n",
            "Epoch 82/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0119 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0118 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6923 - val_loss: 1.7086 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.3106e-04\n",
            "Epoch 83/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6901 - val_loss: 0.9288 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.2566e-04\n",
            "Epoch 84/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7066 - val_loss: 1.3138 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.2028e-04\n",
            "Epoch 85/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0069 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0069 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6931 - val_loss: 1.6410 - val_sens_at_spec_85: 0.4043 - learning_rate: 2.1491e-04\n",
            "Epoch 86/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6962 - val_loss: 1.8275 - val_sens_at_spec_85: 0.4574 - learning_rate: 2.0955e-04\n",
            "Epoch 87/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7146 - val_loss: 1.4485 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.0422e-04\n",
            "Epoch 88/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0061 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0061 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6930 - val_loss: 1.7326 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.9891e-04\n",
            "Epoch 89/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6974 - val_loss: 2.1251 - val_sens_at_spec_85: 0.4362 - learning_rate: 1.9362e-04\n",
            "Epoch 90/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0045 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0046 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6925 - val_loss: 1.8983 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.8835e-04\n",
            "Epoch 91/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0064 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0064 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6907 - val_loss: 1.6939 - val_sens_at_spec_85: 0.4149 - learning_rate: 1.8312e-04\n",
            "Epoch 92/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6862 - val_loss: 1.8902 - val_sens_at_spec_85: 0.4255 - learning_rate: 1.7791e-04\n",
            "Epoch 93/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0077 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0077 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7000 - val_loss: 1.5490 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.7275e-04\n",
            "Epoch 94/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0055 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0055 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6953 - val_loss: 1.8636 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.6761e-04\n",
            "Epoch 95/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0047 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0047 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7127 - val_loss: 1.6627 - val_sens_at_spec_85: 0.4787 - learning_rate: 1.6252e-04\n",
            "Epoch 96/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.72084\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7205 - val_loss: 1.6388 - val_sens_at_spec_85: 0.4681 - learning_rate: 1.5747e-04\n",
            "Epoch 97/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0059 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc improved from 0.72084 to 0.72211, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0059 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7221 - val_loss: 1.3624 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.5246e-04\n",
            "Epoch 98/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0072 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.72211\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0072 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7209 - val_loss: 1.4869 - val_sens_at_spec_85: 0.4149 - learning_rate: 1.4749e-04\n",
            "Epoch 99/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0035 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc improved from 0.72211 to 0.72943, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0035 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7294 - val_loss: 1.1628 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.4258e-04\n",
            "Epoch 100/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7264 - val_loss: 1.4696 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.3771e-04\n",
            "Epoch 101/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0052 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0052 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7140 - val_loss: 1.7233 - val_sens_at_spec_85: 0.4255 - learning_rate: 1.3290e-04\n",
            "Epoch 102/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0046 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0046 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7167 - val_loss: 1.7082 - val_sens_at_spec_85: 0.4362 - learning_rate: 1.2814e-04\n",
            "Epoch 103/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 103: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7013 - val_loss: 1.8137 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.2344e-04\n",
            "Epoch 104/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0042 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 104: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0042 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7102 - val_loss: 1.7512 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.1880e-04\n",
            "Epoch 105/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0040 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 105: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0041 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7068 - val_loss: 1.4384 - val_sens_at_spec_85: 0.4043 - learning_rate: 1.1422e-04\n",
            "Epoch 106/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0064 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 106: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0064 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7045 - val_loss: 1.4045 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.0970e-04\n",
            "Epoch 107/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0036 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 107: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0036 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7174 - val_loss: 1.2775 - val_sens_at_spec_85: 0.4255 - learning_rate: 1.0525e-04\n",
            "Epoch 108/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0044 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 108: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0044 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7105 - val_loss: 1.7803 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.0087e-04\n",
            "Epoch 109/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0050 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 109: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0050 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7090 - val_loss: 1.5353 - val_sens_at_spec_85: 0.4468 - learning_rate: 9.6559e-05\n",
            "Epoch 110/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 110: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7183 - val_loss: 1.6495 - val_sens_at_spec_85: 0.4574 - learning_rate: 9.2319e-05\n",
            "Epoch 111/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0032 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 111: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0032 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7083 - val_loss: 1.6604 - val_sens_at_spec_85: 0.4787 - learning_rate: 8.8153e-05\n",
            "Epoch 112/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 112: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7094 - val_loss: 2.0020 - val_sens_at_spec_85: 0.4787 - learning_rate: 8.4063e-05\n",
            "Epoch 113/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0028 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 113: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0028 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7087 - val_loss: 1.8432 - val_sens_at_spec_85: 0.5213 - learning_rate: 8.0051e-05\n",
            "Epoch 114/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0028 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 114: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0028 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7080 - val_loss: 1.7320 - val_sens_at_spec_85: 0.4787 - learning_rate: 7.6119e-05\n",
            "Epoch 115/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0040 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 115: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0040 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7041 - val_loss: 1.7764 - val_sens_at_spec_85: 0.4574 - learning_rate: 7.2268e-05\n",
            "Epoch 116/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 116: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7192 - val_loss: 1.6963 - val_sens_at_spec_85: 0.4894 - learning_rate: 6.8501e-05\n",
            "Epoch 117/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 117: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7144 - val_loss: 2.0548 - val_sens_at_spec_85: 0.4149 - learning_rate: 6.4819e-05\n",
            "Epoch 118/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0030 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 118: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0030 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7140 - val_loss: 1.7071 - val_sens_at_spec_85: 0.5000 - learning_rate: 6.1224e-05\n",
            "Epoch 119/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0026 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 119: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0026 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7274 - val_loss: 2.0152 - val_sens_at_spec_85: 0.4681 - learning_rate: 5.7717e-05\n",
            "Epoch 120/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0031 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 120: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0031 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7038 - val_loss: 1.9778 - val_sens_at_spec_85: 0.4468 - learning_rate: 5.4301e-05\n",
            "Epoch 121/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0031 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 121: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0031 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7111 - val_loss: 2.0360 - val_sens_at_spec_85: 0.4574 - learning_rate: 5.0977e-05\n",
            "Epoch 122/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0027 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 122: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0027 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7005 - val_loss: 2.0710 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.7746e-05\n",
            "Epoch 123/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0025 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 123: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0025 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7149 - val_loss: 2.0282 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.4610e-05\n",
            "Epoch 124/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 124: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7111 - val_loss: 2.0982 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.1570e-05\n",
            "Epoch 125/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 125: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7015 - val_loss: 2.1134 - val_sens_at_spec_85: 0.4468 - learning_rate: 3.8628e-05\n",
            "Epoch 126/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 126: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7043 - val_loss: 2.1580 - val_sens_at_spec_85: 0.4255 - learning_rate: 3.5786e-05\n",
            "Epoch 127/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0024 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 127: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0024 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7043 - val_loss: 2.0449 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.3044e-05\n",
            "Epoch 128/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 128: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7106 - val_loss: 2.0317 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.0404e-05\n",
            "Epoch 129/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 129: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7175 - val_loss: 1.9456 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.7866e-05\n",
            "Epoch 130/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0030 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 130: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0030 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7159 - val_loss: 1.9494 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.5434e-05\n",
            "Epoch 131/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0033 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 131: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0033 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7151 - val_loss: 1.8889 - val_sens_at_spec_85: 0.5000 - learning_rate: 2.3106e-05\n",
            "Epoch 132/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 132: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0023 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7201 - val_loss: 1.9744 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.0885e-05\n",
            "Epoch 133/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0025 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 133: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0025 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7105 - val_loss: 2.0563 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.8772e-05\n",
            "Epoch 134/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0020 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 134: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0020 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7113 - val_loss: 2.0451 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.6767e-05\n",
            "Epoch 135/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0022 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 135: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0022 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7168 - val_loss: 2.0193 - val_sens_at_spec_85: 0.4468 - learning_rate: 1.4872e-05\n",
            "Epoch 136/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0022 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 136: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0022 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7214 - val_loss: 2.0356 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.3087e-05\n",
            "Epoch 137/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 137: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0029 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7270 - val_loss: 1.9955 - val_sens_at_spec_85: 0.4362 - learning_rate: 1.1413e-05\n",
            "Epoch 138/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0022 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 138: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0022 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7188 - val_loss: 2.0742 - val_sens_at_spec_85: 0.4681 - learning_rate: 9.8512e-06\n",
            "Epoch 139/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0040 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 139: val_auc did not improve from 0.72943\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0040 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7250 - val_loss: 1.9680 - val_sens_at_spec_85: 0.4468 - learning_rate: 8.4021e-06\n",
            "Epoch 139: early stopping\n",
            "Restoring model weights from the end of the best epoch: 99.\n",
            "\n",
            "Fold 2 Results:\n",
            "  loss: 1.1628\n",
            "  auc: 0.7294\n",
            "  sens_at_spec_85: 0.4574\n",
            "\n",
            "========================================\n",
            "Running Fold 3/5\n",
            "========================================\n",
            "\n",
            "Applying TimeGAN Augmentation to Fold 3...\n",
            "  Before: 376.0 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  After:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 3...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 3\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.99% positive, Val: 18.47% positive\n",
            "Epoch 1/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - auc: 0.0000e+00 - loss: 0.2364 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.47930, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 639ms/step - auc: 0.0000e+00 - loss: 0.2363 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4793 - val_loss: 0.1437 - val_sens_at_spec_85: 0.1702 - learning_rate: 1.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1497 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.47930 to 0.57920, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1497 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5792 - val_loss: 0.1433 - val_sens_at_spec_85: 0.0957 - learning_rate: 2.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1401 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.57920 to 0.58397, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1400 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5840 - val_loss: 0.1577 - val_sens_at_spec_85: 0.2447 - learning_rate: 3.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1364 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.58397\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1364 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5609 - val_loss: 0.1471 - val_sens_at_spec_85: 0.2234 - learning_rate: 4.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1318 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.58397\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1318 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5618 - val_loss: 0.1425 - val_sens_at_spec_85: 0.2128 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1315 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc improved from 0.58397 to 0.60277, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1315 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6028 - val_loss: 0.1567 - val_sens_at_spec_85: 0.1809 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1297 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.60277 to 0.62554, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1297 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6255 - val_loss: 0.1410 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.9994e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1258 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc improved from 0.62554 to 0.65054, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1258 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6505 - val_loss: 0.1351 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.9977e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1247 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc improved from 0.65054 to 0.66029, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1247 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6603 - val_loss: 0.1373 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.9947e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1210 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.66029\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1210 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6359 - val_loss: 0.1428 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.9906e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1190 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc improved from 0.66029 to 0.69442, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1190 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6944 - val_loss: 0.1352 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9853e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1152 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.69442\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1152 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6781 - val_loss: 0.1674 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.9789e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1140 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc improved from 0.69442 to 0.69959, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1140 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6996 - val_loss: 0.1330 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.9713e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1112 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc improved from 0.69959 to 0.71056, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1112 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7106 - val_loss: 0.1342 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9625e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1071 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.71056\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1071 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7050 - val_loss: 0.1359 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.9526e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1070 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc improved from 0.71056 to 0.72930, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1070 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7293 - val_loss: 0.1304 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9416e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1035 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1035 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6896 - val_loss: 0.1937 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.9293e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1058 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7108 - val_loss: 0.1400 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.9160e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0990 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0991 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7095 - val_loss: 0.1501 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9015e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1017 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1017 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7194 - val_loss: 0.1472 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.8859e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0931 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0931 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6390 - val_loss: 0.1464 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.8691e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0889 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0890 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6992 - val_loss: 0.1450 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.8513e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0890 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0890 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6918 - val_loss: 0.1544 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.8323e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0824 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0824 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7066 - val_loss: 0.1636 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.8123e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0864 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0864 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6865 - val_loss: 0.1574 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.7911e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0784 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.72930\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0784 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6976 - val_loss: 0.1610 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.7689e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0784 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc improved from 0.72930 to 0.74002, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0784 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7400 - val_loss: 0.1484 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.7457e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0768 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.74002\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0768 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7119 - val_loss: 0.2029 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.7213e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0745 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.74002\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0745 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6933 - val_loss: 0.1511 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.6960e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0701 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc improved from 0.74002 to 0.74148, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0701 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7415 - val_loss: 0.1520 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.6696e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0674 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.74148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0674 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7363 - val_loss: 0.1960 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.6421e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0614 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.74148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0614 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7413 - val_loss: 0.1635 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.6137e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0637 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.74148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0637 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7216 - val_loss: 0.1785 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.5843e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0612 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.74148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0612 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7375 - val_loss: 0.2224 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.5539e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0506 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc improved from 0.74148 to 0.74377, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0506 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7438 - val_loss: 0.2176 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.5225e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0515 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.74377\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0515 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7317 - val_loss: 0.2436 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.4902e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0484 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.74377\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0484 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7391 - val_loss: 0.4031 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.4570e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0424 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc improved from 0.74377 to 0.76446, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0424 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7645 - val_loss: 0.2289 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.4228e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0449 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.76446\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0449 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7383 - val_loss: 0.3515 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.3878e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0412 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.76446\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0412 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7433 - val_loss: 0.1966 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.3518e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0504 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.76446\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7373 - val_loss: 0.3442 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.3150e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0382 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.76446\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0382 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7559 - val_loss: 0.6791 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.2773e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0444 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.76446\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0443 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7580 - val_loss: 0.5510 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.2388e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0385 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.76446\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0385 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7482 - val_loss: 0.5352 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.1995e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0502 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc improved from 0.76446 to 0.77793, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0502 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7779 - val_loss: 0.2815 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.1594e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.77793\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7617 - val_loss: 0.7558 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.1185e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0290 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc improved from 0.77793 to 0.78470, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0290 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7847 - val_loss: 0.4866 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.0768e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0336 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.78470\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0336 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7699 - val_loss: 0.6964 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.0344e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0307 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.78470\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0307 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7817 - val_loss: 0.4358 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.9913e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0291 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.78470\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0291 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7431 - val_loss: 0.6151 - val_sens_at_spec_85: 0.4255 - learning_rate: 3.9475e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0249 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.78470\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0249 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7535 - val_loss: 0.5441 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.9030e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0252 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc improved from 0.78470 to 0.79428, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0252 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7943 - val_loss: 0.5415 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.8578e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0213 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0213 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7930 - val_loss: 0.2241 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.8120e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0361 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0361 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7710 - val_loss: 0.3900 - val_sens_at_spec_85: 0.4574 - learning_rate: 3.7656e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0266 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0266 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7371 - val_loss: 0.3278 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.7186e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0205 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0205 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7831 - val_loss: 0.6662 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.6710e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0239 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0239 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7793 - val_loss: 0.5616 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.6229e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0194 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0194 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7595 - val_loss: 0.7369 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.5742e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0187 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0187 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7247 - val_loss: 0.5329 - val_sens_at_spec_85: 0.3830 - learning_rate: 3.5251e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0167 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0167 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7646 - val_loss: 0.8788 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.4754e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0184 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.79428\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0184 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7828 - val_loss: 0.5029 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.4253e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0164 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc improved from 0.79428 to 0.80069, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0164 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8007 - val_loss: 0.4694 - val_sens_at_spec_85: 0.5745 - learning_rate: 3.3748e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0190 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0190 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7572 - val_loss: 1.0749 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.3239e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0218 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0218 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7377 - val_loss: 1.4838 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.2725e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0185 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0185 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7434 - val_loss: 0.8162 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.2209e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0149 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0149 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6959 - val_loss: 2.0394 - val_sens_at_spec_85: 0.4043 - learning_rate: 3.1688e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0139 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0140 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7833 - val_loss: 0.6442 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.1165e-04\n",
            "Epoch 68/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0157 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0157 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7783 - val_loss: 0.8968 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.0638e-04\n",
            "Epoch 69/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0109 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0109 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7472 - val_loss: 0.9683 - val_sens_at_spec_85: 0.4787 - learning_rate: 3.0109e-04\n",
            "Epoch 70/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0175 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0175 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7586 - val_loss: 1.1860 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.9578e-04\n",
            "Epoch 71/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7546 - val_loss: 1.1540 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.9045e-04\n",
            "Epoch 72/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7711 - val_loss: 0.7403 - val_sens_at_spec_85: 0.4362 - learning_rate: 2.8509e-04\n",
            "Epoch 73/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0138 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0139 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7644 - val_loss: 0.8204 - val_sens_at_spec_85: 0.4574 - learning_rate: 2.7972e-04\n",
            "Epoch 74/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7696 - val_loss: 0.8868 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.7434e-04\n",
            "Epoch 75/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0116 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0116 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7602 - val_loss: 1.1723 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.6894e-04\n",
            "Epoch 76/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0088 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0088 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7656 - val_loss: 1.4775 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.6353e-04\n",
            "Epoch 77/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0102 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0102 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7593 - val_loss: 1.1118 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.5812e-04\n",
            "Epoch 78/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0104 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0104 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7602 - val_loss: 0.9426 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.5271e-04\n",
            "Epoch 79/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0114 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7171 - val_loss: 1.9777 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.4729e-04\n",
            "Epoch 80/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0148 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0148 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7710 - val_loss: 0.7561 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.4188e-04\n",
            "Epoch 81/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0121 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0121 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7676 - val_loss: 1.5055 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.3647e-04\n",
            "Epoch 82/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0099 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0099 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7753 - val_loss: 1.0272 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.3106e-04\n",
            "Epoch 83/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0112 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0112 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7690 - val_loss: 1.1632 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.2566e-04\n",
            "Epoch 84/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7387 - val_loss: 1.7582 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.2028e-04\n",
            "Epoch 85/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0101 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0101 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7803 - val_loss: 0.6910 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.1491e-04\n",
            "Epoch 86/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0106 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0105 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7686 - val_loss: 1.3552 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.0955e-04\n",
            "Epoch 87/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0072 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0072 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7571 - val_loss: 0.9500 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.0422e-04\n",
            "Epoch 88/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0089 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0089 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7619 - val_loss: 1.4595 - val_sens_at_spec_85: 0.4681 - learning_rate: 1.9891e-04\n",
            "Epoch 89/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0048 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0048 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7561 - val_loss: 1.4372 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.9362e-04\n",
            "Epoch 90/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7527 - val_loss: 1.3374 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.8835e-04\n",
            "Epoch 91/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0070 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0070 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7812 - val_loss: 0.7573 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.8312e-04\n",
            "Epoch 92/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7526 - val_loss: 1.2405 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.7791e-04\n",
            "Epoch 93/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7728 - val_loss: 1.0034 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.7275e-04\n",
            "Epoch 94/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0058 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0058 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7595 - val_loss: 1.3697 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.6761e-04\n",
            "Epoch 95/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7571 - val_loss: 1.1618 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.6252e-04\n",
            "Epoch 96/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0071 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7356 - val_loss: 1.6121 - val_sens_at_spec_85: 0.4574 - learning_rate: 1.5747e-04\n",
            "Epoch 97/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0061 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0061 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7190 - val_loss: 1.3983 - val_sens_at_spec_85: 0.4255 - learning_rate: 1.5246e-04\n",
            "Epoch 98/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0056 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7396 - val_loss: 1.2424 - val_sens_at_spec_85: 0.5000 - learning_rate: 1.4749e-04\n",
            "Epoch 99/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0068 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0068 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7543 - val_loss: 1.2588 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.4258e-04\n",
            "Epoch 100/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7633 - val_loss: 1.1559 - val_sens_at_spec_85: 0.4787 - learning_rate: 1.3771e-04\n",
            "Epoch 101/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0055 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0055 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7370 - val_loss: 1.5644 - val_sens_at_spec_85: 0.4787 - learning_rate: 1.3290e-04\n",
            "Epoch 102/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc did not improve from 0.80069\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7438 - val_loss: 1.4703 - val_sens_at_spec_85: 0.4362 - learning_rate: 1.2814e-04\n",
            "Epoch 102: early stopping\n",
            "Restoring model weights from the end of the best epoch: 62.\n",
            "\n",
            "Fold 3 Results:\n",
            "  loss: 0.4694\n",
            "  auc: 0.8007\n",
            "  sens_at_spec_85: 0.5745\n",
            "\n",
            "========================================\n",
            "Running Fold 4/5\n",
            "========================================\n",
            "\n",
            "Applying TimeGAN Augmentation to Fold 4...\n",
            "  Before: 376.0 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  After:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 4...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 4\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.99% positive, Val: 18.47% positive\n",
            "Epoch 1/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - auc: 0.0000e+00 - loss: 0.2432 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.47061, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 642ms/step - auc: 0.0000e+00 - loss: 0.2431 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4706 - val_loss: 0.1541 - val_sens_at_spec_85: 0.0745 - learning_rate: 1.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1501 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.47061 to 0.56421, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1501 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5642 - val_loss: 0.1420 - val_sens_at_spec_85: 0.2447 - learning_rate: 2.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1388 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.56421 to 0.60678, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1388 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6068 - val_loss: 0.1426 - val_sens_at_spec_85: 0.3617 - learning_rate: 3.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1326 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.60678\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1326 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5799 - val_loss: 0.1442 - val_sens_at_spec_85: 0.2021 - learning_rate: 4.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1322 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.60678\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1322 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5040 - val_loss: 0.1436 - val_sens_at_spec_85: 0.0426 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1326 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.60678\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1326 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5438 - val_loss: 0.1421 - val_sens_at_spec_85: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1284 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.60678\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1284 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5911 - val_loss: 0.1441 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9994e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1310 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc improved from 0.60678 to 0.64710, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1310 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6471 - val_loss: 0.1340 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.9977e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1244 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc improved from 0.64710 to 0.65140, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1244 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6514 - val_loss: 0.1331 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.9947e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1207 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.65140 to 0.69269, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1207 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6927 - val_loss: 0.1359 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9906e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1210 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc improved from 0.69269 to 0.71328, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1210 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7133 - val_loss: 0.1296 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.9853e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1206 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc improved from 0.71328 to 0.72148, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1206 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7215 - val_loss: 0.1305 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9789e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1168 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc did not improve from 0.72148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1168 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7172 - val_loss: 0.1369 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.9713e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1202 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc did not improve from 0.72148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1202 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6936 - val_loss: 0.1355 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9625e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.72148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6933 - val_loss: 0.1323 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9526e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1122 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.72148\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1122 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7192 - val_loss: 0.1319 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.9416e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1105 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc improved from 0.72148 to 0.73190, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1105 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7319 - val_loss: 0.1349 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9293e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1098 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc did not improve from 0.73190\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1098 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6814 - val_loss: 0.1672 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.9160e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1095 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.73190\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1095 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7307 - val_loss: 0.1354 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9015e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1098 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.73190\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1097 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6229 - val_loss: 0.1396 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.8859e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1032 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc improved from 0.73190 to 0.75537, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1032 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7554 - val_loss: 0.1325 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.8691e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1024 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1025 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7068 - val_loss: 0.1447 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.8513e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1001 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1001 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7023 - val_loss: 0.1459 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.8323e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1008 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1008 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7525 - val_loss: 0.1381 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.8123e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0997 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0997 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7180 - val_loss: 0.1455 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.7911e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0927 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0927 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7518 - val_loss: 0.1361 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.7689e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0894 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0894 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7537 - val_loss: 0.1379 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.7457e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0909 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0909 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7295 - val_loss: 0.1422 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.7213e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0871 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0871 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7438 - val_loss: 0.1419 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.6960e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0851 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0851 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7194 - val_loss: 0.1450 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.6696e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0848 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0848 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7078 - val_loss: 0.1519 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.6421e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0817 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.75537\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0817 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7324 - val_loss: 0.1440 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.6137e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0795 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc improved from 0.75537 to 0.75822, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0795 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7582 - val_loss: 0.1749 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.5843e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0798 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0798 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7519 - val_loss: 0.1873 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.5539e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0717 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0717 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7353 - val_loss: 0.1783 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.5225e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0699 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0699 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6942 - val_loss: 0.1742 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.4902e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0638 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0638 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7543 - val_loss: 0.1681 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.4570e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0659 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0659 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7445 - val_loss: 0.1765 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.4228e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0587 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0587 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7504 - val_loss: 0.1746 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.3878e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0586 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0586 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7494 - val_loss: 0.2210 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.3518e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0485 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.75822\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0486 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7260 - val_loss: 0.2733 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.3150e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0647 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc improved from 0.75822 to 0.79477, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0647 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7948 - val_loss: 0.1890 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.2773e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0522 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0522 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7356 - val_loss: 0.2791 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.2388e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0437 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0437 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7731 - val_loss: 0.3075 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.1995e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0405 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0405 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7752 - val_loss: 0.1887 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.1594e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0428 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0428 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7459 - val_loss: 0.4355 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.1185e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0445 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0445 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7372 - val_loss: 0.2921 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.0768e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0423 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0423 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6984 - val_loss: 0.2988 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.0344e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0451 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0450 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7658 - val_loss: 0.2494 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.9913e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0352 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0352 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7472 - val_loss: 0.3769 - val_sens_at_spec_85: 0.4468 - learning_rate: 3.9475e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0392 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0392 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7758 - val_loss: 0.3895 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.9030e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0348 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.79477\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0348 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7855 - val_loss: 0.3793 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.8578e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0305 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc improved from 0.79477 to 0.79563, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0305 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7956 - val_loss: 0.3416 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.8120e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0312 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.79563\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0312 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7815 - val_loss: 0.3507 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.7656e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0392 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc improved from 0.79563 to 0.80514, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.0391 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8051 - val_loss: 0.4305 - val_sens_at_spec_85: 0.6383 - learning_rate: 3.7186e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0266 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0266 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7877 - val_loss: 0.4280 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.6710e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0317 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0316 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7877 - val_loss: 0.6582 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.6229e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0261 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0261 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7926 - val_loss: 0.5064 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.5742e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0235 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0235 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8026 - val_loss: 0.4993 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.5251e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0241 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0241 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7634 - val_loss: 0.5274 - val_sens_at_spec_85: 0.4574 - learning_rate: 3.4754e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0224 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0224 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7907 - val_loss: 0.3314 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.4253e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0250 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0250 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8021 - val_loss: 0.5442 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.3748e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0238 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0238 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7692 - val_loss: 0.4598 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.3239e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0231 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0231 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7947 - val_loss: 0.4247 - val_sens_at_spec_85: 0.5745 - learning_rate: 3.2725e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0216 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0216 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7803 - val_loss: 0.5489 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.2209e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0164 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0164 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7659 - val_loss: 0.7022 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.1688e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0191 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0191 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7565 - val_loss: 1.0303 - val_sens_at_spec_85: 0.4574 - learning_rate: 3.1165e-04\n",
            "Epoch 68/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0186 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0186 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7949 - val_loss: 0.9974 - val_sens_at_spec_85: 0.5745 - learning_rate: 3.0638e-04\n",
            "Epoch 69/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0312 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0312 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7804 - val_loss: 0.8227 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.0109e-04\n",
            "Epoch 70/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0202 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0202 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7861 - val_loss: 0.5451 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.9578e-04\n",
            "Epoch 71/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0223 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0223 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7870 - val_loss: 1.1628 - val_sens_at_spec_85: 0.5638 - learning_rate: 2.9045e-04\n",
            "Epoch 72/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0158 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0158 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7890 - val_loss: 1.2440 - val_sens_at_spec_85: 0.5851 - learning_rate: 2.8509e-04\n",
            "Epoch 73/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0195 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0195 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7674 - val_loss: 1.0880 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.7972e-04\n",
            "Epoch 74/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0168 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0168 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7890 - val_loss: 1.1350 - val_sens_at_spec_85: 0.6277 - learning_rate: 2.7434e-04\n",
            "Epoch 75/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0147 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0147 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7565 - val_loss: 1.3527 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.6894e-04\n",
            "Epoch 76/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0154 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0154 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7704 - val_loss: 1.2213 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.6353e-04\n",
            "Epoch 77/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0186 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0186 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7727 - val_loss: 1.1899 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.5812e-04\n",
            "Epoch 78/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0124 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0124 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7513 - val_loss: 1.6781 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.5271e-04\n",
            "Epoch 79/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0146 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0147 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7629 - val_loss: 0.6054 - val_sens_at_spec_85: 0.4787 - learning_rate: 2.4729e-04\n",
            "Epoch 80/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0135 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0135 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7983 - val_loss: 0.7740 - val_sens_at_spec_85: 0.5957 - learning_rate: 2.4188e-04\n",
            "Epoch 81/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0124 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0124 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7858 - val_loss: 1.2136 - val_sens_at_spec_85: 0.5638 - learning_rate: 2.3647e-04\n",
            "Epoch 82/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0136 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0137 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7854 - val_loss: 1.0998 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.3106e-04\n",
            "Epoch 83/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0116 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0116 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7883 - val_loss: 1.1232 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.2566e-04\n",
            "Epoch 84/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0120 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.80514\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0120 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7900 - val_loss: 0.7977 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.2028e-04\n",
            "Epoch 85/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0112 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc improved from 0.80514 to 0.81829, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.0112 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8183 - val_loss: 0.6245 - val_sens_at_spec_85: 0.6170 - learning_rate: 2.1491e-04\n",
            "Epoch 86/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0096 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0096 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7979 - val_loss: 1.0685 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.0955e-04\n",
            "Epoch 87/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7644 - val_loss: 1.3585 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.0422e-04\n",
            "Epoch 88/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0114 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0114 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7891 - val_loss: 1.0044 - val_sens_at_spec_85: 0.5745 - learning_rate: 1.9891e-04\n",
            "Epoch 89/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0111 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0112 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7771 - val_loss: 0.8769 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.9362e-04\n",
            "Epoch 90/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0116 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0116 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7873 - val_loss: 1.2668 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.8835e-04\n",
            "Epoch 91/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0156 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7796 - val_loss: 0.9967 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.8312e-04\n",
            "Epoch 92/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0100 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0100 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8080 - val_loss: 0.7656 - val_sens_at_spec_85: 0.6064 - learning_rate: 1.7791e-04\n",
            "Epoch 93/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0103 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0103 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7833 - val_loss: 1.3266 - val_sens_at_spec_85: 0.5638 - learning_rate: 1.7275e-04\n",
            "Epoch 94/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0075 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0075 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7742 - val_loss: 1.4920 - val_sens_at_spec_85: 0.5745 - learning_rate: 1.6761e-04\n",
            "Epoch 95/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0098 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0098 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7913 - val_loss: 1.0689 - val_sens_at_spec_85: 0.5851 - learning_rate: 1.6252e-04\n",
            "Epoch 96/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0093 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0093 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7927 - val_loss: 0.9563 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.5747e-04\n",
            "Epoch 97/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7850 - val_loss: 1.2721 - val_sens_at_spec_85: 0.5426 - learning_rate: 1.5246e-04\n",
            "Epoch 98/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0128 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0128 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7683 - val_loss: 1.6571 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.4749e-04\n",
            "Epoch 99/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7632 - val_loss: 1.8797 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.4258e-04\n",
            "Epoch 100/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0074 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0074 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7765 - val_loss: 1.7918 - val_sens_at_spec_85: 0.5638 - learning_rate: 1.3771e-04\n",
            "Epoch 101/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7726 - val_loss: 1.4013 - val_sens_at_spec_85: 0.5319 - learning_rate: 1.3290e-04\n",
            "Epoch 102/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0075 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0075 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7728 - val_loss: 1.5744 - val_sens_at_spec_85: 0.5745 - learning_rate: 1.2814e-04\n",
            "Epoch 103/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0087 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 103: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0087 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7828 - val_loss: 1.4440 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.2344e-04\n",
            "Epoch 104/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0069 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 104: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0069 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7638 - val_loss: 1.6725 - val_sens_at_spec_85: 0.5851 - learning_rate: 1.1880e-04\n",
            "Epoch 105/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0053 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 105: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0053 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7579 - val_loss: 1.8222 - val_sens_at_spec_85: 0.5532 - learning_rate: 1.1422e-04\n",
            "Epoch 106/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 106: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0108 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7581 - val_loss: 1.5740 - val_sens_at_spec_85: 0.5851 - learning_rate: 1.0970e-04\n",
            "Epoch 107/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0077 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 107: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0077 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7563 - val_loss: 1.3503 - val_sens_at_spec_85: 0.5000 - learning_rate: 1.0525e-04\n",
            "Epoch 108/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 108: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0086 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7603 - val_loss: 1.1880 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.0087e-04\n",
            "Epoch 109/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0067 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 109: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0067 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7565 - val_loss: 1.6421 - val_sens_at_spec_85: 0.5426 - learning_rate: 9.6559e-05\n",
            "Epoch 110/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 110: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7814 - val_loss: 1.5057 - val_sens_at_spec_85: 0.5213 - learning_rate: 9.2319e-05\n",
            "Epoch 111/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 111: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7852 - val_loss: 1.3159 - val_sens_at_spec_85: 0.5532 - learning_rate: 8.8153e-05\n",
            "Epoch 112/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0059 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 112: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0059 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7785 - val_loss: 1.3560 - val_sens_at_spec_85: 0.5426 - learning_rate: 8.4063e-05\n",
            "Epoch 113/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 113: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0051 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7729 - val_loss: 1.5725 - val_sens_at_spec_85: 0.5532 - learning_rate: 8.0051e-05\n",
            "Epoch 114/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 114: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7520 - val_loss: 1.5949 - val_sens_at_spec_85: 0.5426 - learning_rate: 7.6119e-05\n",
            "Epoch 115/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 115: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0062 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7589 - val_loss: 1.4745 - val_sens_at_spec_85: 0.5319 - learning_rate: 7.2268e-05\n",
            "Epoch 116/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0052 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 116: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0052 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7592 - val_loss: 1.6329 - val_sens_at_spec_85: 0.5532 - learning_rate: 6.8501e-05\n",
            "Epoch 117/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0045 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 117: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0045 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7588 - val_loss: 1.4946 - val_sens_at_spec_85: 0.5106 - learning_rate: 6.4819e-05\n",
            "Epoch 118/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 118: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0060 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7510 - val_loss: 1.8272 - val_sens_at_spec_85: 0.5213 - learning_rate: 6.1224e-05\n",
            "Epoch 119/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0052 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 119: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0052 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7648 - val_loss: 1.7434 - val_sens_at_spec_85: 0.5319 - learning_rate: 5.7717e-05\n",
            "Epoch 120/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 120: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0054 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7771 - val_loss: 1.3720 - val_sens_at_spec_85: 0.5213 - learning_rate: 5.4301e-05\n",
            "Epoch 121/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0044 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 121: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0044 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7745 - val_loss: 1.6483 - val_sens_at_spec_85: 0.5319 - learning_rate: 5.0977e-05\n",
            "Epoch 122/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0034 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 122: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0034 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7654 - val_loss: 1.5057 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.7746e-05\n",
            "Epoch 123/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0048 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 123: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0048 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7689 - val_loss: 1.6379 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.4610e-05\n",
            "Epoch 124/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0046 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 124: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0047 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7750 - val_loss: 1.4778 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.1570e-05\n",
            "Epoch 125/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 125: val_auc did not improve from 0.81829\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0043 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7573 - val_loss: 1.6523 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.8628e-05\n",
            "Epoch 125: early stopping\n",
            "Restoring model weights from the end of the best epoch: 85.\n",
            "\n",
            "Fold 4 Results:\n",
            "  loss: 0.6245\n",
            "  auc: 0.8183\n",
            "  sens_at_spec_85: 0.6170\n",
            "\n",
            "========================================\n",
            "Running Fold 5/5\n",
            "========================================\n",
            "\n",
            "Applying TimeGAN Augmentation to Fold 5...\n",
            "  Before: 376.0 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  After:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 5...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 5\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.99% positive, Val: 18.47% positive\n",
            "Epoch 1/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - auc: 0.0000e+00 - loss: 0.2426 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.52544, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 643ms/step - auc: 0.0000e+00 - loss: 0.2425 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5254 - val_loss: 0.1461 - val_sens_at_spec_85: 0.1170 - learning_rate: 1.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1476 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.52544 to 0.54559, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1476 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5456 - val_loss: 0.2321 - val_sens_at_spec_85: 0.1915 - learning_rate: 2.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1388 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.54559 to 0.54803, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1388 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5480 - val_loss: 0.1442 - val_sens_at_spec_85: 0.1809 - learning_rate: 3.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1360 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.54803\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1360 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5205 - val_loss: 0.1486 - val_sens_at_spec_85: 0.0426 - learning_rate: 4.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1355 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc improved from 0.54803 to 0.55911, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1355 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5591 - val_loss: 0.1754 - val_sens_at_spec_85: 0.1915 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1326 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.55911\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1326 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5119 - val_loss: 0.1446 - val_sens_at_spec_85: 0.0532 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1276 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.55911 to 0.58557, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1276 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5856 - val_loss: 0.1430 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.9994e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1280 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.58557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1280 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5720 - val_loss: 0.1435 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.9977e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1268 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc improved from 0.58557 to 0.69699, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1268 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6970 - val_loss: 0.1444 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.9947e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1231 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.69699 to 0.73639, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1231 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7364 - val_loss: 0.1320 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9906e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1179 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1179 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6010 - val_loss: 0.2046 - val_sens_at_spec_85: 0.1702 - learning_rate: 4.9853e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1163 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1162 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6648 - val_loss: 0.1686 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.9789e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1138 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1138 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7083 - val_loss: 0.1369 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.9713e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1119 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1119 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7254 - val_loss: 0.1421 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.9625e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1117 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1117 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7305 - val_loss: 0.1331 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.9526e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1091 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1091 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6564 - val_loss: 0.1775 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.9416e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1066 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1066 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7198 - val_loss: 0.1404 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.9293e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1011 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1011 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6667 - val_loss: 0.1873 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.9160e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0994 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0994 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7228 - val_loss: 0.1416 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.9015e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1012 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.73639\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1012 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6739 - val_loss: 0.1421 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.8859e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0977 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc improved from 0.73639 to 0.73946, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0977 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7395 - val_loss: 0.1316 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.8691e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0929 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0929 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6830 - val_loss: 0.1537 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.8513e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0922 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0922 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7120 - val_loss: 0.1447 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.8323e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0911 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0911 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7109 - val_loss: 0.1614 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.8123e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0876 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0876 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6938 - val_loss: 0.2286 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.7911e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0815 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0815 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7090 - val_loss: 0.2008 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.7689e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0743 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0743 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7196 - val_loss: 0.1578 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.7457e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0725 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.73946\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0725 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7105 - val_loss: 0.1713 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.7213e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0753 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc improved from 0.73946 to 0.75209, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0753 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7521 - val_loss: 0.2885 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.6960e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0721 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.75209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0721 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7491 - val_loss: 0.2402 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.6696e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0633 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.75209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0633 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7429 - val_loss: 0.1493 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.6421e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0601 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.75209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0601 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7330 - val_loss: 0.2244 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.6137e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0572 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.75209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0572 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7398 - val_loss: 0.2546 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.5843e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0526 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc improved from 0.75209 to 0.77430, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0526 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7743 - val_loss: 0.1782 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.5539e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0543 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.77430\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0543 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7183 - val_loss: 0.4619 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.5225e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0491 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.77430\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0491 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7650 - val_loss: 0.2186 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.4902e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0506 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.77430\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0506 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7349 - val_loss: 0.2195 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.4570e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc improved from 0.77430 to 0.77757, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7776 - val_loss: 0.3365 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.4228e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0477 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0478 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7120 - val_loss: 0.3138 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.3878e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7611 - val_loss: 0.3388 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.3518e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0468 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0467 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7561 - val_loss: 0.4491 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.3150e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0428 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0428 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7542 - val_loss: 0.7220 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.2773e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0381 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0381 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7625 - val_loss: 0.4049 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.2388e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0368 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0368 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7527 - val_loss: 0.3990 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.1995e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0376 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0376 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7370 - val_loss: 0.4469 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.1594e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0342 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0342 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7730 - val_loss: 0.3472 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.1185e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0379 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.77757\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0379 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7660 - val_loss: 0.4322 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.0768e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0365 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc improved from 0.77757 to 0.79207, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0365 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7921 - val_loss: 0.2325 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.0344e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0315 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0315 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7578 - val_loss: 0.4538 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.9913e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0300 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0300 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7565 - val_loss: 0.4346 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.9475e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0333 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0334 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7066 - val_loss: 0.2803 - val_sens_at_spec_85: 0.4149 - learning_rate: 3.9030e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0280 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0280 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7625 - val_loss: 0.5455 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.8578e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0239 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0239 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7542 - val_loss: 0.3459 - val_sens_at_spec_85: 0.4362 - learning_rate: 3.8120e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0306 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0306 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7669 - val_loss: 0.7814 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.7656e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0223 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0223 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7674 - val_loss: 0.4633 - val_sens_at_spec_85: 0.4787 - learning_rate: 3.7186e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0254 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0254 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7568 - val_loss: 0.2616 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.6710e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0405 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0405 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7734 - val_loss: 0.3736 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.6229e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0249 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0249 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7773 - val_loss: 0.3334 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.5742e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0191 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0191 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7686 - val_loss: 0.3780 - val_sens_at_spec_85: 0.4255 - learning_rate: 3.5251e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7621 - val_loss: 0.6761 - val_sens_at_spec_85: 0.4468 - learning_rate: 3.4754e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0238 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0238 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7755 - val_loss: 0.4864 - val_sens_at_spec_85: 0.4787 - learning_rate: 3.4253e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0228 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0227 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7565 - val_loss: 0.7531 - val_sens_at_spec_85: 0.3936 - learning_rate: 3.3748e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0202 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0202 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7494 - val_loss: 0.5610 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.3239e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0181 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0181 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7308 - val_loss: 1.0386 - val_sens_at_spec_85: 0.4043 - learning_rate: 3.2725e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0167 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0167 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7254 - val_loss: 1.4977 - val_sens_at_spec_85: 0.4362 - learning_rate: 3.2209e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0214 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0214 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7489 - val_loss: 0.8800 - val_sens_at_spec_85: 0.4574 - learning_rate: 3.1688e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0177 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7336 - val_loss: 0.9754 - val_sens_at_spec_85: 0.4149 - learning_rate: 3.1165e-04\n",
            "Epoch 68/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0159 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0159 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7584 - val_loss: 0.9046 - val_sens_at_spec_85: 0.4255 - learning_rate: 3.0638e-04\n",
            "Epoch 69/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0142 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7357 - val_loss: 0.4970 - val_sens_at_spec_85: 0.4149 - learning_rate: 3.0109e-04\n",
            "Epoch 70/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0237 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0236 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7355 - val_loss: 1.1963 - val_sens_at_spec_85: 0.4149 - learning_rate: 2.9578e-04\n",
            "Epoch 71/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0176 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7419 - val_loss: 1.2053 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.9045e-04\n",
            "Epoch 72/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0182 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0182 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7391 - val_loss: 0.7109 - val_sens_at_spec_85: 0.4255 - learning_rate: 2.8509e-04\n",
            "Epoch 73/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0146 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0146 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7572 - val_loss: 1.1174 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.7972e-04\n",
            "Epoch 74/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0147 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0147 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7705 - val_loss: 0.9361 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.7434e-04\n",
            "Epoch 75/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0118 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0118 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7873 - val_loss: 1.0127 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.6894e-04\n",
            "Epoch 76/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0132 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0132 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7501 - val_loss: 1.2428 - val_sens_at_spec_85: 0.4362 - learning_rate: 2.6353e-04\n",
            "Epoch 77/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0114 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7623 - val_loss: 0.8869 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.5812e-04\n",
            "Epoch 78/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0156 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7575 - val_loss: 0.9616 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.5271e-04\n",
            "Epoch 79/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0109 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0109 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7666 - val_loss: 1.0313 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.4729e-04\n",
            "Epoch 80/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0073 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0073 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7595 - val_loss: 1.2005 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.4188e-04\n",
            "Epoch 81/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0093 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0093 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7383 - val_loss: 1.1697 - val_sens_at_spec_85: 0.4574 - learning_rate: 2.3647e-04\n",
            "Epoch 82/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0085 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0085 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7340 - val_loss: 1.7330 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.3106e-04\n",
            "Epoch 83/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0139 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0139 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7682 - val_loss: 0.8842 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.2566e-04\n",
            "Epoch 84/150\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0106 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0106 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7839 - val_loss: 1.0950 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.2028e-04\n",
            "Epoch 85/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0143 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0143 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7572 - val_loss: 0.9879 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.1491e-04\n",
            "Epoch 86/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0091 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0091 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7546 - val_loss: 0.9792 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.0955e-04\n",
            "Epoch 87/150\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0115 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7526 - val_loss: 0.9612 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.0422e-04\n",
            "Epoch 88/150\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0079 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.79207\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0079 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7485 - val_loss: 1.1389 - val_sens_at_spec_85: 0.4787 - learning_rate: 1.9891e-04\n",
            "Epoch 88: early stopping\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "\n",
            "Fold 5 Results:\n",
            "  loss: 0.2325\n",
            "  auc: 0.7921\n",
            "  sens_at_spec_85: 0.5745\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE - SUMMARY\n",
            "============================================================\n",
            "\n",
            "AUC across folds: 0.7910 ± 0.0322\n",
            "  Individual folds: ['0.8143', '0.7294', '0.8007', '0.8183', '0.7921']\n",
            "\n",
            "Results saved to: /content/NeuroFetal-AI/Reports/training_logs/training_log_20260221_102159.json\n",
            "\n",
            "============================================================\n",
            "✓ Training pipeline completed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# V4.0: TimeGAN augmentation (default)\n",
        "!python Code/scripts/train.py --augmentation timegan --epochs 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4_comparison_md"
      },
      "source": [
        "### 4b. SMOTE Baseline Comparison (Optional)\n",
        "\n",
        "Run this cell to compare TimeGAN vs SMOTE augmentation. Skip if you only need TimeGAN results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4_smote_comparison"
      },
      "source": [
        "# Optional: Run SMOTE baseline for comparison\n",
        "# !python Code/scripts/train.py --augmentation smote --epochs 150"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "push_models",
        "outputId": "8e436d53-9973-45ce-aa41-659984c713d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pushing model for Fold 1...\n",
            "On branch feat/v4.0-timegan\n",
            "Your branch is ahead of 'origin/feat/v4.0-timegan' by 5 commits.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   Code/models/pretrained_fhr_encoder.weights.keras\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mReports/training_logs/training_log_20260221_102159.json\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Enumerating objects: 33, done.\n",
            "Counting objects: 100% (33/33), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (25/25), done.\n",
            "Writing objects: 100% (25/25), 117.51 MiB | 10.29 MiB/s, done.\n",
            "Total 25 (delta 15), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (15/15), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   dfbe571..97ae102  feat/v4.0-timegan -> feat/v4.0-timegan\n",
            "✓ Fold 1 pushed.\n",
            "Pushing model for Fold 2...\n",
            "On branch feat/v4.0-timegan\n",
            "Your branch is up to date with 'origin/feat/v4.0-timegan'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   Code/models/pretrained_fhr_encoder.weights.keras\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mReports/training_logs/training_log_20260221_102159.json\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Everything up-to-date\n",
            "✓ Fold 2 pushed.\n",
            "Pushing model for Fold 3...\n",
            "On branch feat/v4.0-timegan\n",
            "Your branch is up to date with 'origin/feat/v4.0-timegan'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   Code/models/pretrained_fhr_encoder.weights.keras\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mReports/training_logs/training_log_20260221_102159.json\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Everything up-to-date\n",
            "✓ Fold 3 pushed.\n",
            "Pushing model for Fold 4...\n",
            "On branch feat/v4.0-timegan\n",
            "Your branch is up to date with 'origin/feat/v4.0-timegan'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   Code/models/pretrained_fhr_encoder.weights.keras\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mReports/training_logs/training_log_20260221_102159.json\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Everything up-to-date\n",
            "✓ Fold 4 pushed.\n",
            "Pushing model for Fold 5...\n",
            "On branch feat/v4.0-timegan\n",
            "Your branch is up to date with 'origin/feat/v4.0-timegan'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   Code/models/pretrained_fhr_encoder.weights.keras\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mReports/training_logs/training_log_20260221_102159.json\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Everything up-to-date\n",
            "✓ Fold 5 pushed.\n"
          ]
        }
      ],
      "source": [
        "# Auto-push trained models to GitHub\n",
        "import os\n",
        "\n",
        "for fold in range(1, 6):\n",
        "    model_path = f\"Code/models/enhanced_model_fold_{fold}.keras\"\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Pushing model for Fold {fold}...\")\n",
        "        !git add {model_path}\n",
        "        !git commit -m \"Auto-save: Trained SOTA model Fold {fold}\"\n",
        "        !git push origin feat/v4.0-timegan\n",
        "        print(f\"✓ Fold {fold} pushed.\")\n",
        "    else:\n",
        "        print(f\"⚠️ Not found: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzEALoB7Xxvj",
        "outputId": "a285fbfa-902b-42d2-bb5e-3fc51b10def6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 1.35 KiB | 689.00 KiB/s, done.\n",
            "From https://github.com/Krishna200608/NeuroFetal-AI\n",
            " * branch            feat/v4.0-timegan -> FETCH_HEAD\n",
            "   97ae102..ad2241e  feat/v4.0-timegan -> origin/feat/v4.0-timegan\n",
            "Updating 97ae102..ad2241e\n",
            "Fast-forward\n",
            " Code/scripts/train_diverse_ensemble.py | 36 \u001b[32m++++++++++++++++++++++++\u001b[m\u001b[31m----------\u001b[m\n",
            " 1 file changed, 26 insertions(+), 10 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull origin feat/v4.0-timegan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_md"
      },
      "source": [
        "---\n",
        "## 5. Diverse Ensemble Training (Phase 5)\n",
        "\n",
        "Train three diverse model families and combine with a stacking meta-learner:\n",
        "\n",
        "1. **AttentionFusionResNet** — primary (already trained above)\n",
        "2. **1D-InceptionNet** — multi-scale temporal patterns (kernel 5/15/40)\n",
        "3. **XGBoost / LightGBM** — gradient boosting on tabular + CSP + FHR features\n",
        "\n",
        "Out-of-fold predictions across 5 folds → Logistic Regression stacking\n",
        "\n",
        "**Expected additional AUC lift: +3–5 pts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_ensemble_training",
        "outputId": "647b40a4-7342-41f1-9d75-22b24d650008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NeuroFetal AI — Diverse Ensemble Training (Phase 5)\n",
            "============================================================\n",
            "\n",
            "Data: FHR=(2546, 1200, 1), Tab=(2546, 18), y=(2546,)\n",
            "Class balance: 18.5% positive\n",
            "2026-02-21 10:46:47.377580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771670807.398267   45986 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771670807.404943   45986 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771670807.420862   45986 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771670807.420887   45986 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771670807.420891   45986 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771670807.420897   45986 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-21 10:46:47.425409: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "============================================================\n",
            "Fold 1/5\n",
            "============================================================\n",
            "  Applying TimeGAN augmentation...\n",
            "    Before: 376 positives / 2036 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2490 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  TimeGAN Augmentation: 686 → 830 positives / 2490 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "    After:  830 positives / 2490 total\n",
            "  CSP features padded: 2036 → 2490 rows\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "2026-02-21 10:46:53.361854: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771670813.363367   45986 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771670817.547364   46042 service.cc:152] XLA service 0x79a1700021c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771670817.547397   46042 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-21 10:46:57.614911: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1771670817.973523   46042 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1771670822.086315   46042 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "    Model A fold 1 AUC: 0.7774\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "2026-02-21 10:47:18.870000: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 10:47:19.214638: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 10:47:19.280830: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.16 = (f32[32,80,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,1,150]{3,2,1,0} %bitcast.26425, f32[64,80,1,15]{3,2,1,0} %bitcast.26429), window={size=1x15 pad=0_0x7_7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/InceptionFusionNet_1/inc2_conv15_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-21 10:47:19.566108: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 10:47:19.585949: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.305226109s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.16 = (f32[32,80,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,1,150]{3,2,1,0} %bitcast.26425, f32[64,80,1,15]{3,2,1,0} %bitcast.26429), window={size=1x15 pad=0_0x7_7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/InceptionFusionNet_1/inc2_conv15_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-21 10:47:20.398633: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 10:47:20.733608: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 10:47:20.856194: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.17 = (f32[32,80,1,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,1,150]{3,2,1,0} %bitcast.26438, f32[32,80,1,40]{3,2,1,0} %bitcast.26442), window={size=1x40 pad=0_0x19_19}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/InceptionFusionNet_1/inc2_conv40_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-21 10:47:21.058358: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-21 10:47:21.078202: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.222117234s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.17 = (f32[32,80,1,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,1,150]{3,2,1,0} %bitcast.26438, f32[32,80,1,40]{3,2,1,0} %bitcast.26442), window={size=1x40 pad=0_0x19_19}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/InceptionFusionNet_1/inc2_conv40_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "    Model B fold 1 AUC: 0.8052\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:385: UserWarning: [10:49:23] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8625\n",
            "\n",
            "============================================================\n",
            "Fold 2/5\n",
            "============================================================\n",
            "  Applying TimeGAN augmentation...\n",
            "    Before: 376 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  TimeGAN Augmentation: 679 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "    After:  830 positives / 2491 total\n",
            "  CSP features padded: 2037 → 2491 rows\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 2 AUC: 0.7208\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 2 AUC: 0.7390\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:385: UserWarning: [10:51:36] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8075\n",
            "\n",
            "============================================================\n",
            "Fold 3/5\n",
            "============================================================\n",
            "  Applying TimeGAN augmentation...\n",
            "    Before: 376 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  TimeGAN Augmentation: 681 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "    After:  830 positives / 2491 total\n",
            "  CSP features padded: 2037 → 2491 rows\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 3 AUC: 0.7468\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 3 AUC: 0.8524\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:385: UserWarning: [10:54:02] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8416\n",
            "\n",
            "============================================================\n",
            "Fold 4/5\n",
            "============================================================\n",
            "  Applying TimeGAN augmentation...\n",
            "    Before: 376 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  TimeGAN Augmentation: 695 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "    After:  830 positives / 2491 total\n",
            "  CSP features padded: 2037 → 2491 rows\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 4 AUC: 0.7866\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 4 AUC: 0.8251\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:385: UserWarning: [10:56:24] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8859\n",
            "\n",
            "============================================================\n",
            "Fold 5/5\n",
            "============================================================\n",
            "  Applying TimeGAN augmentation...\n",
            "    Before: 376 positives / 2037 total\n",
            "  TimeGAN Augmentation: 376 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "  TimeGAN Augmentation: 678 → 830 positives / 2491 total\n",
            "  Injected 454 synthetic traces (from 1410 available)\n",
            "    After:  830 positives / 2491 total\n",
            "  CSP features padded: 2037 → 2491 rows\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 5 AUC: 0.7613\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 5 AUC: 0.8159\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:385: UserWarning: [10:58:12] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8730\n",
            "\n",
            "============================================================\n",
            "OOF AUC Summary\n",
            "============================================================\n",
            "  model_a: 0.7586 ± 0.0233\n",
            "  model_b: 0.8075 ± 0.0377\n",
            "  model_c: 0.8541 ± 0.0274\n",
            "\n",
            "  Stacking Meta-Learner AUC: 0.8639\n",
            "  Meta-learner weights: [1.35455446 2.49973544 4.49834891]\n",
            "  Meta-learner bias: [-4.47610401]\n",
            "  Weighted Average AUC (w=[0.4, 0.3, 0.3]): 0.8562\n",
            "  Meta-learner saved to: /content/NeuroFetal-AI/Code/models/stacking_meta_learner.pkl\n",
            "\n",
            "Results saved to: /content/NeuroFetal-AI/Reports/training_logs/ensemble_log_20260221_105813.json\n",
            "\n",
            "✓ Diverse ensemble training complete!\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/train_diverse_ensemble.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "push_ensemble",
        "outputId": "c580c385-1380-40e0-fd2a-338079403e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch feat/v4.0-timegan\n",
            "Your branch is ahead of 'origin/feat/v4.0-timegan' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   Code/models/pretrained_fhr_encoder.weights.keras\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_1/calibration_curve.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_1/uncertainty_histogram.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_2/calibration_curve.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_2/uncertainty_histogram.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_3/calibration_curve.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_3/uncertainty_histogram.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_4/calibration_curve.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_4/uncertainty_histogram.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_5/calibration_curve.png\u001b[m\n",
            "\t\u001b[31mmodified:   Reports/uncertainty_analysis/fold_5/uncertainty_histogram.png\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mCode/models/inception_model_fold_1.keras\u001b[m\n",
            "\t\u001b[31mCode/models/inception_model_fold_2.keras\u001b[m\n",
            "\t\u001b[31mCode/models/inception_model_fold_3.keras\u001b[m\n",
            "\t\u001b[31mCode/models/inception_model_fold_4.keras\u001b[m\n",
            "\t\u001b[31mCode/models/inception_model_fold_5.keras\u001b[m\n",
            "\t\u001b[31mCode/models/oof_labels.npy\u001b[m\n",
            "\t\u001b[31mCode/models/oof_predictions.npy\u001b[m\n",
            "\t\u001b[31mCode/models/optimal_thresholds.json\u001b[m\n",
            "\t\u001b[31mCode/models/temperature_scaling.json\u001b[m\n",
            "\t\u001b[31mCode/models/xgboost_model_fold_1.pkl\u001b[m\n",
            "\t\u001b[31mCode/models/xgboost_model_fold_2.pkl\u001b[m\n",
            "\t\u001b[31mCode/models/xgboost_model_fold_3.pkl\u001b[m\n",
            "\t\u001b[31mCode/models/xgboost_model_fold_4.pkl\u001b[m\n",
            "\t\u001b[31mCode/models/xgboost_model_fold_5.pkl\u001b[m\n",
            "\t\u001b[31mReports/ensemble_analysis/\u001b[m\n",
            "\t\u001b[31mReports/training_logs/ensemble_log_20260221_105813.json\u001b[m\n",
            "\t\u001b[31mReports/training_logs/training_log_20260221_102159.json\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 513 bytes | 513.00 KiB/s, done.\n",
            "Total 5 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   ad2241e..a65dc13  feat/v4.0-timegan -> feat/v4.0-timegan\n",
            "✓ Pushed 1 ensemble artifacts.\n"
          ]
        }
      ],
      "source": [
        "# Push ensemble artifacts\n",
        "import os\n",
        "\n",
        "ensemble_files = [\n",
        "    \"Code/models/stacking_meta_learner.pkl\",\n",
        "    \"Code/models/xgb_model.pkl\",\n",
        "]\n",
        "\n",
        "# Also push any InceptionNet fold models\n",
        "for fold in range(1, 6):\n",
        "    inception_path = f\"Code/models/inception_fold_{fold}.keras\"\n",
        "    if os.path.exists(inception_path):\n",
        "        ensemble_files.append(inception_path)\n",
        "\n",
        "pushed = []\n",
        "for f in ensemble_files:\n",
        "    if os.path.exists(f):\n",
        "        !git add {f}\n",
        "        pushed.append(f)\n",
        "\n",
        "if pushed:\n",
        "    !git commit -m \"Auto-save: Diverse ensemble models (InceptionNet + XGB + meta-learner)\"\n",
        "    !git push origin feat/v4.0-timegan\n",
        "    print(f\"✓ Pushed {len(pushed)} ensemble artifacts.\")\n",
        "else:\n",
        "    print(\"⚠️ No ensemble files found to push.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_5_md"
      },
      "source": [
        "---\n",
        "## 6. Evaluation & Calibration (Phase 6)\n",
        "\n",
        "**Stacking Ensemble Evaluation** with:\n",
        "- Temperature scaling (Guo et al., 2017)\n",
        "- Optimal threshold search (Youden's J / F1 / cost-sensitive)\n",
        "- Enhanced 3-pass TTA (original + flip + noise)\n",
        "- AUPRC reporting for imbalanced data\n",
        "\n",
        "**Uncertainty Quantification** via MC Dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_eval",
        "outputId": "34ba28cb-2857-41ee-8df0-1bdf716a0c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Stacking Ensemble Evaluation...\n",
            "2026-02-21 11:00:43.132845: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771671643.168453   56912 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771671643.178397   56912 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771671643.203490   56912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671643.203525   56912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671643.203528   56912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671643.203532   56912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-21 11:00:43.210691: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "============================================================\n",
            "Ensemble & TTA Evaluation (SOTA with Calibration)\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Data shape: FHR=(2546, 1200, 1), Tab=(2546, 18), Labels=(2546,)\n",
            "Class balance: 18.5% positive\n",
            "\n",
            "--- Stacking Ensemble Evaluation ---\n",
            "  Stacking AUC: 0.8639\n",
            "  Model weights: [1.35455446 2.49973544 4.49834891]\n",
            "  AttentionFusionResNet AUC: 0.7040\n",
            "  InceptionNet AUC: 0.7886\n",
            "  XGBoost AUC: 0.8512\n",
            "\n",
            "--- Per-Fold Model A Evaluation ---\n",
            "\n",
            "--- Fold 1 ---\n",
            "2026-02-21 11:00:49.080302: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771671649.081848   56912 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771671656.213095   56954 service.cc:152] XLA service 0x7bf2000036b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771671656.213126   56954 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-21 11:00:56.260847: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1771671656.615721   56954 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1771671659.860073   56954 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "  Fold 1 AUC (with TTA): 0.8171\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Fold 2 AUC (with TTA): 0.7103\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Fold 3 AUC (with TTA): 0.7811\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Fold 4 AUC (with TTA): 0.8144\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Fold 5 AUC (with TTA): 0.8114\n",
            "\n",
            "--- Temperature Scaling ---\n",
            "  Optimal temperature: 2.909\n",
            "  Calibrated AUC: 0.7674\n",
            "\n",
            "--- Optimal Threshold Search ---\n",
            "  Youden's J optimal threshold: 0.2560\n",
            "  At this threshold: Sensitivity=0.698, Specificity=0.882\n",
            "  F1 optimal threshold: 0.2560\n",
            "  At this threshold: Precision=0.572, Recall=0.698\n",
            "  Cost-sensitive threshold (FN penalty=3.0x): 0.2600\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "  Mean Fold AUC (Model A + TTA):       0.7869 ± 0.0404\n",
            "  Global OOF AUC (Raw):                0.7674\n",
            "  Global OOF AUC (Rank Normalized):    0.7869\n",
            "  Global OOF AUC (Calibrated):         0.7674\n",
            "  Stacking Ensemble AUC:               0.8639\n",
            "\n",
            "  Optimal Thresholds:\n",
            "    youden: 0.2560\n",
            "    f1: 0.2560\n",
            "    cost_sensitive: 0.2600\n",
            "    default: 0.5000\n",
            "\n",
            "  Classification Report (threshold=0.256):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.93      0.88      0.90      2076\n",
            " Compromised       0.57      0.70      0.63       470\n",
            "\n",
            "    accuracy                           0.85      2546\n",
            "   macro avg       0.75      0.79      0.77      2546\n",
            "weighted avg       0.86      0.85      0.85      2546\n",
            "\n",
            "  AUPRC (Average Precision): 0.6338\n",
            "\n",
            "  Results saved to: /content/NeuroFetal-AI/Reports/ensemble_analysis/evaluation_results_20260221_110154.json\n",
            "\n",
            "------------------------------------------------------------\n",
            "  🎯 TARGET ACHIEVED: AUC = 0.8639 (> 0.84)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Running Uncertainty Quantification (MC Dropout)...\n",
            "2026-02-21 11:01:56.512338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771671716.546073   57454 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771671716.557160   57454 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771671716.582131   57454 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671716.582173   57454 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671716.582183   57454 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671716.582189   57454 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-21 11:01:56.588855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading data...\n",
            "Detailed: Loaded UC signals for CSP.\n",
            "\n",
            "Processing Fold 1...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "2026-02-21 11:02:04.354649: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771671724.356190   57454 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "I0000 00:00:1771671727.234765   57454 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.2903\n",
            "  Mean uncertainty: 0.1655\n",
            "  Max uncertainty: 0.3955\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.8088\n",
            "  Expected Calibration Error: 0.1124\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 238\n",
            "  High uncertainty samples: 272\n",
            "  AUC (low uncertainty): 0.9044\n",
            "  AUC (high uncertainty): 0.6792\n",
            "\n",
            "⚠️  Clinical Alert: 94 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_1/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_1/uncertainty_histogram.png\n",
            "Fold 1 AUC: 0.8088\n",
            "\n",
            "Processing Fold 2...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.2852\n",
            "  Mean uncertainty: 0.1528\n",
            "  Max uncertainty: 0.3747\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.7152\n",
            "  Expected Calibration Error: 0.1664\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 258\n",
            "  High uncertainty samples: 251\n",
            "  AUC (low uncertainty): 0.7586\n",
            "  AUC (high uncertainty): 0.6058\n",
            "\n",
            "⚠️  Clinical Alert: 69 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_2/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_2/uncertainty_histogram.png\n",
            "Fold 2 AUC: 0.7152\n",
            "\n",
            "Processing Fold 3...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.3316\n",
            "  Mean uncertainty: 0.1436\n",
            "  Max uncertainty: 0.2999\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.7857\n",
            "  Expected Calibration Error: 0.1469\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 243\n",
            "  High uncertainty samples: 266\n",
            "  AUC (low uncertainty): 0.8439\n",
            "  AUC (high uncertainty): 0.6923\n",
            "\n",
            "⚠️  Clinical Alert: 71 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_3/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_3/uncertainty_histogram.png\n",
            "Fold 3 AUC: 0.7857\n",
            "\n",
            "Processing Fold 4...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.3955\n",
            "  Mean uncertainty: 0.1529\n",
            "  Max uncertainty: 0.3519\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.8111\n",
            "  Expected Calibration Error: 0.2108\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 237\n",
            "  High uncertainty samples: 272\n",
            "  AUC (low uncertainty): 0.8749\n",
            "  AUC (high uncertainty): 0.7021\n",
            "\n",
            "⚠️  Clinical Alert: 100 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_4/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_4/uncertainty_histogram.png\n",
            "Fold 4 AUC: 0.8111\n",
            "\n",
            "Processing Fold 5...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.4246\n",
            "  Mean uncertainty: 0.1583\n",
            "  Max uncertainty: 0.3108\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.8120\n",
            "  Expected Calibration Error: 0.2399\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 210\n",
            "  High uncertainty samples: 299\n",
            "  AUC (low uncertainty): 0.8536\n",
            "  AUC (high uncertainty): 0.7215\n",
            "\n",
            "⚠️  Clinical Alert: 86 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_5/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_5/uncertainty_histogram.png\n",
            "Fold 5 AUC: 0.8120\n",
            "\n",
            "============================================================\n",
            "Overall Evaluation Results (Mean across 5 folds)\n",
            "============================================================\n",
            "Mean AUC: 0.7866\n",
            "Mean ECE: 0.1753\n",
            "Mean Uncertainty: 0.1546\n",
            "\n",
            "Uncertainty evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning Stacking Ensemble Evaluation...\")\n",
        "!python Code/scripts/evaluate_ensemble.py\n",
        "\n",
        "print(\"\\nRunning Uncertainty Quantification (MC Dropout)...\")\n",
        "!python Code/scripts/evaluate_uncertainty.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5_md"
      },
      "source": [
        "---\n",
        "## 7. Launch Dashboard (Optional)\n",
        "\n",
        "Run the Streamlit dashboard from Colab via **ngrok** tunnel.\n",
        "\n",
        "> Requires `NGROK_AUTH_TOKEN` in Colab Secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_dashboard",
        "outputId": "67abc212-4bbb-4654-910b-0d2c0050b720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Ngrok Token loaded from Secrets.\n",
            "Launching Streamlit App...\n",
            "Authenticating with ngrok...\n",
            "Starting Streamlit Server...\n",
            "Using system python: /usr/bin/python3\n",
            "Attempting to open public tunnel...\n",
            "\n",
            "============================================================\n",
            "   DASHBOARD LIVE AT: https://beauteously-uncaped-dario.ngrok-free.dev\n",
            "   LOCAL ADDRESS:     http://localhost:8501\n",
            "============================================================\n",
            "\n",
            "Press Ctrl+C to stop the server.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    print(\"✓ Ngrok Token loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Error loading NGROK_AUTH_TOKEN from Secrets. Falling back to manual input.\")\n",
        "    from getpass import getpass\n",
        "    auth_token = getpass(\"Enter Ngrok Auth Token manually: \")\n",
        "\n",
        "if auth_token:\n",
        "    with open(\"Code/.env\", \"w\") as f:\n",
        "        f.write(f\"NGROK_AUTH_TOKEN={auth_token}\\n\")\n",
        "\n",
        "print(\"Launching Streamlit App...\")\n",
        "!python Code/run_app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6_md"
      },
      "source": [
        "---\n",
        "## 8. Convert to TFLite & Auto-Push\n",
        "\n",
        "Convert the best trained model to TFLite format and push to GitHub automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_tflite",
        "outputId": "51628d71-aeeb-4ede-dbfb-c99134045cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-21 11:03:36.910062: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771671816.930562   57981 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771671816.937280   57981 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771671816.953537   57981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671816.953569   57981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671816.953573   57981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771671816.953576   57981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-21 11:03:36.958054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "Model: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "2026-02-21 11:03:42.938668: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771671822.940352   57981 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "✓ Keras Model Loaded\n",
            "Loading calibration data...\n",
            "  Fitting CSP Feature Extractor for calibration...\n",
            "  Extracting multi-modal features...\n",
            "  Data Loaded: FHR (2546, 1200, 1), Tab (2546, 18), Features (2546, 19)\n",
            "\n",
            "[1/2] Converting Standard TFLite Model...\n",
            "Saved artifact at '/tmp/tmpnezkjv9s'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 1200, 1), dtype=tf.float32, name='input_fhr'), TensorSpec(shape=(None, 18), dtype=tf.float32, name='input_tabular'), TensorSpec(shape=(None, 19), dtype=tf.float32, name='input_csp')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135777281216336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281215568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281213456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281214224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281216528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281218064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281216720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281218256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242136208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242135632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281218832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281228240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281228048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242120656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281228624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242120272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135821648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135832400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135833744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135833360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135835472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135835088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135834704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210140432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210142928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210144272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242120848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135821456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242130256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242130064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242131408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242131216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242132368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210143120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210147920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210147152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210150032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210149648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210152528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210149456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210152912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777209225232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242132944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242131024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242132176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242134288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242134096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135821264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135829712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135830480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135830288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135830864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135829904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135831248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135828752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135831824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135831632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135828560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135828176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135829136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1771671837.870032   57981 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1771671837.870067   57981 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2026-02-21 11:03:57.870774: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpnezkjv9s\n",
            "2026-02-21 11:03:57.878650: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2026-02-21 11:03:57.878675: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpnezkjv9s\n",
            "I0000 00:00:1771671838.001619   57981 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "2026-02-21 11:03:58.025636: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2026-02-21 11:03:58.871490: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpnezkjv9s\n",
            "2026-02-21 11:03:59.104577: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 1233807 microseconds.\n",
            "2026-02-21 11:03:59.344907: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "  Saved: /content/NeuroFetal-AI/Code/models/tflite/neurofetal_model.tflite (6855.5 KB)\n",
            "\n",
            "[2/2] Converting Int8 Quantized Model (Edge Optimized)...\n",
            "Saved artifact at '/tmp/tmpgaq0upv0'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 1200, 1), dtype=tf.float32, name='input_fhr'), TensorSpec(shape=(None, 18), dtype=tf.float32, name='input_tabular'), TensorSpec(shape=(None, 19), dtype=tf.float32, name='input_csp')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135777281216336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281215568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281213456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281214224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281216528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281218064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281216720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281218256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281220560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281219984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242136208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242135632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281218832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281222864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281223440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281217296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281226704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281225744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281221520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281227088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281228240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281228048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242120656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281228624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777281224208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242120272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242121424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135821648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135832400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135833744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135833360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135835472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135835088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135834704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210142928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210144272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242120848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242125648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242124688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242122000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242123728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135821456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135824720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242126416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242130256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242130064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242128336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242131408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242131216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242129680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242132368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242127760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210143120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210147920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210147152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210150032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210149648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210152528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777210152912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777209225232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242132944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242131024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242132176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242134288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242134096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135825872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135821264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135829712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135830480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135830288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135830864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135829904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135831248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135828752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135831824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135823952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135826256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135831632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777242133712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135822224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135828560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135827792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135828176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135777135829136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "W0000 00:00:1771671846.254272   57981 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1771671846.254298   57981 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2026-02-21 11:04:06.254548: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpgaq0upv0\n",
            "2026-02-21 11:04:06.265709: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2026-02-21 11:04:06.265740: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpgaq0upv0\n",
            "2026-02-21 11:04:06.372345: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2026-02-21 11:04:06.912981: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpgaq0upv0\n",
            "2026-02-21 11:04:07.080656: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 826112 microseconds.\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "  Saved: /content/NeuroFetal-AI/Code/models/tflite/neurofetal_model_quant_int8.tflite (1951.0 KB)\n",
            "  Compression: 3.5x smaller\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/convert_to_tflite.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "push_tflite",
        "outputId": "6ae7115b-1da0-4351-8648-788175e5270a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat/v4.0-timegan 4251b54] Auto-save: TFLite model\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " rewrite Code/models/tflite/neurofetal_model_quant_int8.tflite (73%)\n",
            "Enumerating objects: 11, done.\n",
            "Counting objects: 100% (11/11), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 1.65 MiB | 3.05 MiB/s, done.\n",
            "Total 6 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   a65dc13..4251b54  feat/v4.0-timegan -> feat/v4.0-timegan\n",
            "✓ TFLite model pushed.\n"
          ]
        }
      ],
      "source": [
        "# Push TFLite model\n",
        "import os\n",
        "\n",
        "tflite_path = \"Code/models/tflite/neurofetal_model_quant_int8.tflite\"\n",
        "if os.path.exists(tflite_path):\n",
        "    !git add {tflite_path}\n",
        "    !git commit -m \"Auto-save: TFLite model\"\n",
        "    !git push origin feat/v4.0-timegan\n",
        "    print(\"✓ TFLite model pushed.\")\n",
        "else:\n",
        "    print(\"⚠️ TFLite model not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "done_md"
      },
      "source": [
        "---\n",
        "## ✅ Pipeline Complete\n",
        "\n",
        "All 6 SOTA phases have been executed. Check the evaluation output above for final AUC and calibration metrics."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}