{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_md"
      },
      "source": [
        "# NeuroFetal AI — SOTA Training Pipeline\n",
        "\n",
        "**Version 4.0** — TimeGAN Augmentation Phase (AUC 0.90+ Target)\n",
        "\n",
        "This notebook orchestrates the full SOTA pipeline on Google Colab with GPU acceleration.\n",
        "\n",
        "### V4.0 Upgrade: TimeGAN Replaces SMOTE\n",
        "Instead of tabular SMOTE (linear interpolation), V4.0 uses a **1D Convolutional WGAN-GP** to generate\n",
        "synthetic pathological FHR/UC traces that preserve temporal dynamics. The generator was trained in\n",
        "`TimeGAN_Colab.ipynb` and produced 1,410 synthetic traces saved to `Datasets/synthetic/`.\n",
        "\n",
        "### Pipeline Steps\n",
        "| # | Phase | Script | Expected AUC Lift |\n",
        "|---|-------|--------|-------------------|\n",
        "| 1 | Setup | Clone repo (`feat/v4.0-timegan`), install deps | — |\n",
        "| 2 | Data Ingestion | `data_ingestion.py` — 18 features, pH 7.15, quality filter | +5–8 pts |\n",
        "| 3 | SSL Pretraining | `pretrain.py` — Masked Autoencoder on FHR | +2–3 pts |\n",
        "| 4 | Primary Training (TimeGAN) | `train.py --augmentation timegan` | +3–5 pts |\n",
        "| 4b | Primary Training (SMOTE baseline) | `train.py --augmentation smote` | baseline |\n",
        "| 5 | Ensemble Training | `train_diverse_ensemble.py` — InceptionNet + XGB + Stacking | +3–5 pts |\n",
        "| 6 | Evaluation | `evaluate_ensemble.py` — Temp scaling, TTA, calibration | +1–2 pts |\n",
        "| 7 | Deployment | `convert_to_tflite.py` — TFLite & auto-push | — |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_md"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "github_auth",
        "outputId": "aeaaa351-7599-4738-dc35-4defba4c190b"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# 1. GitHub Authentication\n",
        "GITHUB_REPO = \"Krishna200608/NeuroFetal-AI\"\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "    print(\"✓ GitHub Token loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Error loading GITHUB_TOKEN from Secrets. Falling back to manual input.\")\n",
        "    from getpass import getpass\n",
        "    GITHUB_TOKEN = getpass(\"Enter GitHub Personal Access Token (PAT): \")\n",
        "\n",
        "os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
        "os.environ['GITHUB_REPO'] = GITHUB_REPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone_repo",
        "outputId": "1e8cddda-cae0-43f0-a60b-b4ae228baadd"
      },
      "outputs": [],
      "source": [
        "# 2. Clone Repository & Checkout V4.0 Branch\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Reset to /content before deleting the repo folder\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Clean up any previous clone\n",
        "if os.path.exists(\"/content/NeuroFetal-AI\"):\n",
        "    shutil.rmtree(\"/content/NeuroFetal-AI\")\n",
        "\n",
        "print(\"Cloning repository...\")\n",
        "!git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\n",
        "\n",
        "os.chdir(\"/content/NeuroFetal-AI\")\n",
        "\n",
        "# Checkout V4.0 TimeGAN branch\n",
        "!git checkout feat/v4.0-timegan\n",
        "!git pull origin feat/v4.0-timegan\n",
        "print(\"✓ Cloned and checked out feat/v4.0-timegan!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "git_config_md"
      },
      "source": [
        "### 1.5 Git Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "git_config",
        "outputId": "4c107a1c-548b-40e0-bec1-7c8722bb8a5c"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"krishnasikheriya001@gmail.com\"\n",
        "!git config --global user.name \"Krishna200608\"\n",
        "print(\"✓ Git credentials set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deps_md"
      },
      "source": [
        "### 1.6 Install Dependencies\n",
        "Installs all packages required for the full SOTA pipeline (including XGBoost/LightGBM for ensemble)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_deps",
        "outputId": "94120677-a1bc-4dfb-bf5d-b7c47f9759eb"
      },
      "outputs": [],
      "source": [
        "print(\"Installing libraries...\")\n",
        "!pip install -q wfdb shap scipy imbalanced-learn pyngrok filterpy \\\n",
        "    scikit-learn matplotlib seaborn pandas numpy tensorflow \\\n",
        "    streamlit plotly python-dotenv xgboost lightgbm\n",
        "print(\"✓ Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_md"
      },
      "source": [
        "---\n",
        "## 2. Data Ingestion (Phase 1–2)\n",
        "\n",
        "Processes raw `.dat`/`.hea` files into clean `.npy` arrays.\n",
        "\n",
        "**SOTA enhancements:**\n",
        "- 18 tabular features (13 signal-derived: STV, LTV, accels/decels, baseline, variability…)\n",
        "- FHR normalization excluding 0-gaps\n",
        "- pH threshold relaxed to 7.15 (FIGO)\n",
        "- Signal quality filter (skip >50% loss)\n",
        "- Feature standardization (Z-score) with saved scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_ingestion",
        "outputId": "849d43b7-39e6-4e5f-c5cc-0ee916f7bbd1"
      },
      "outputs": [],
      "source": [
        "!python Code/scripts/data_ingestion.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_5_md"
      },
      "source": [
        "---\n",
        "## 3. Self-Supervised Pretraining\n",
        "\n",
        "Train the Masked Autoencoder (MAE) on unlabelled FHR data to learn robust temporal representations.\n",
        "\n",
        "Saves encoder weights → `Code/models/pretrained_fhr_encoder.weights.keras`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_pretrain",
        "outputId": "80a30cc8-7ca0-492a-b15f-e1e6726f699f"
      },
      "outputs": [],
      "source": [
        "!python Code/scripts/pretrain.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_md"
      },
      "source": [
        "---\n",
        "## 4. Primary Model Training (V4.0 TimeGAN)\n",
        "\n",
        "Train the **AttentionFusionResNet** using 5-Fold Cross-Validation with **TimeGAN augmentation**.\n",
        "\n",
        "**V4.0 upgrade:** Replaces tabular SMOTE with pre-generated synthetic pathological traces from WGAN-GP.\n",
        "\n",
        "**SOTA enhancements (carried from V3.0):**\n",
        "- 200 epochs with cosine annealing + warmup\n",
        "- Focal Loss (α=0.65, γ=2.0)\n",
        "- 4x data augmentation (SpecAugment + CutMix + time-warp + jitter + mixup)\n",
        "- AdamW with weight decay 5e-4\n",
        "- SSL pretrained backbone\n",
        "- Early stopping patience = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pull_before_train"
      },
      "outputs": [],
      "source": [
        "# Pull latest changes from V4.0 branch\n",
        "!git pull origin feat/v4.0-timegan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_training",
        "outputId": "ca798368-b851-40ff-c80f-93d0f334f0fc"
      },
      "outputs": [],
      "source": [
        "# V4.0: TimeGAN augmentation (default)\n",
        "!python Code/scripts/train.py --augmentation timegan --epochs 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4_comparison_md"
      },
      "source": [
        "### 4b. SMOTE Baseline Comparison (Optional)\n",
        "\n",
        "Run this cell to compare TimeGAN vs SMOTE augmentation. Skip if you only need TimeGAN results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4_smote_comparison"
      },
      "source": [
        "# Optional: Run SMOTE baseline for comparison\n",
        "# !python Code/scripts/train.py --augmentation smote --epochs 150"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "push_models",
        "outputId": "a1105e79-2371-453e-e0be-91fd7677e2ea"
      },
      "outputs": [],
      "source": [
        "# Auto-push trained models to GitHub\n",
        "import os\n",
        "\n",
        "for fold in range(1, 6):\n",
        "    model_path = f\"Code/models/enhanced_model_fold_{fold}.keras\"\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Pushing model for Fold {fold}...\")\n",
        "        !git add {model_path}\n",
        "        !git commit -m \"Auto-save: Trained SOTA model Fold {fold}\"\n",
        "        !git push origin main\n",
        "        print(f\"✓ Fold {fold} pushed.\")\n",
        "    else:\n",
        "        print(f\"⚠️ Not found: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzEALoB7Xxvj",
        "outputId": "c983ad37-525b-4a62-9a23-3ae224fd804e"
      },
      "outputs": [],
      "source": [
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_md"
      },
      "source": [
        "---\n",
        "## 5. Diverse Ensemble Training (Phase 5)\n",
        "\n",
        "Train three diverse model families and combine with a stacking meta-learner:\n",
        "\n",
        "1. **AttentionFusionResNet** — primary (already trained above)\n",
        "2. **1D-InceptionNet** — multi-scale temporal patterns (kernel 5/15/40)\n",
        "3. **XGBoost / LightGBM** — gradient boosting on tabular + CSP + FHR features\n",
        "\n",
        "Out-of-fold predictions across 5 folds → Logistic Regression stacking\n",
        "\n",
        "**Expected additional AUC lift: +3–5 pts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_ensemble_training",
        "outputId": "081628d8-733f-44e7-e213-a9a1a4b38c4a"
      },
      "outputs": [],
      "source": [
        "!python Code/scripts/train_diverse_ensemble.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "push_ensemble",
        "outputId": "dc313ec0-7668-4833-b57d-40e86444b58b"
      },
      "outputs": [],
      "source": [
        "# Push ensemble artifacts\n",
        "import os\n",
        "\n",
        "ensemble_files = [\n",
        "    \"Code/models/stacking_meta_learner.pkl\",\n",
        "    \"Code/models/xgb_model.pkl\",\n",
        "]\n",
        "\n",
        "# Also push any InceptionNet fold models\n",
        "for fold in range(1, 6):\n",
        "    inception_path = f\"Code/models/inception_fold_{fold}.keras\"\n",
        "    if os.path.exists(inception_path):\n",
        "        ensemble_files.append(inception_path)\n",
        "\n",
        "pushed = []\n",
        "for f in ensemble_files:\n",
        "    if os.path.exists(f):\n",
        "        !git add {f}\n",
        "        pushed.append(f)\n",
        "\n",
        "if pushed:\n",
        "    !git commit -m \"Auto-save: Diverse ensemble models (InceptionNet + XGB + meta-learner)\"\n",
        "    !git push origin main\n",
        "    print(f\"✓ Pushed {len(pushed)} ensemble artifacts.\")\n",
        "else:\n",
        "    print(\"⚠️ No ensemble files found to push.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_5_md"
      },
      "source": [
        "---\n",
        "## 6. Evaluation & Calibration (Phase 6)\n",
        "\n",
        "**Stacking Ensemble Evaluation** with:\n",
        "- Temperature scaling (Guo et al., 2017)\n",
        "- Optimal threshold search (Youden's J / F1 / cost-sensitive)\n",
        "- Enhanced 3-pass TTA (original + flip + noise)\n",
        "- AUPRC reporting for imbalanced data\n",
        "\n",
        "**Uncertainty Quantification** via MC Dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_eval",
        "outputId": "6462117e-08d7-47e1-bae5-8bc08160cf45"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Stacking Ensemble Evaluation...\")\n",
        "!python Code/scripts/evaluate_ensemble.py\n",
        "\n",
        "print(\"\\nRunning Uncertainty Quantification (MC Dropout)...\")\n",
        "!python Code/scripts/evaluate_uncertainty.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5_md"
      },
      "source": [
        "---\n",
        "## 7. Launch Dashboard (Optional)\n",
        "\n",
        "Run the Streamlit dashboard from Colab via **ngrok** tunnel.\n",
        "\n",
        "> Requires `NGROK_AUTH_TOKEN` in Colab Secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_dashboard",
        "outputId": "cf35120a-0ee0-4a02-a7b1-71b79e5c34f2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    print(\"✓ Ngrok Token loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Error loading NGROK_AUTH_TOKEN from Secrets. Falling back to manual input.\")\n",
        "    from getpass import getpass\n",
        "    auth_token = getpass(\"Enter Ngrok Auth Token manually: \")\n",
        "\n",
        "if auth_token:\n",
        "    with open(\"Code/.env\", \"w\") as f:\n",
        "        f.write(f\"NGROK_AUTH_TOKEN={auth_token}\\n\")\n",
        "\n",
        "print(\"Launching Streamlit App...\")\n",
        "!python Code/run_app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6_md"
      },
      "source": [
        "---\n",
        "## 8. Convert to TFLite & Auto-Push\n",
        "\n",
        "Convert the best trained model to TFLite format and push to GitHub automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_tflite",
        "outputId": "0b8b2227-47f9-40cf-ad27-d6194d554a2a"
      },
      "outputs": [],
      "source": [
        "!python Code/scripts/convert_to_tflite.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "push_tflite",
        "outputId": "7b8e7e0e-4c11-4a74-ea06-9bf0b7a5fb09"
      },
      "outputs": [],
      "source": [
        "# Push TFLite model\n",
        "import os\n",
        "\n",
        "tflite_path = \"Code/models/tflite/neurofetal_model_quant_int8.tflite\"\n",
        "if os.path.exists(tflite_path):\n",
        "    !git add {tflite_path}\n",
        "    !git commit -m \"Auto-save: TFLite model\"\n",
        "    !git push origin main\n",
        "    print(\"✓ TFLite model pushed.\")\n",
        "else:\n",
        "    print(\"⚠️ TFLite model not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "done_md"
      },
      "source": [
        "---\n",
        "## ✅ Pipeline Complete\n",
        "\n",
        "All 6 SOTA phases have been executed. Check the evaluation output above for final AUC and calibration metrics."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}