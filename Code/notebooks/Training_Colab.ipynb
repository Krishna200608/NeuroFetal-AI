{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKHeRA2AkmtW"
      },
      "source": [
        "# NeuroFetal AI - Enhanced Fusion ResNet Training\n",
        "\n",
        "**Version 2.0** - Advanced Enhancements:\n",
        "- 3-Input Architecture (FHR + Tabular + CSP)\n",
        "- Squeeze-and-Excitation (SE) Blocks\n",
        "- Multi-Head Self-Attention\n",
        "- Focal Loss for Class Imbalance\n",
        "\n",
        "### Instructions:\n",
        "1. **Runtime → Change runtime type → GPU (T4)**\n",
        "2. Run cells in order\n",
        "3. Use ** Update Repo** cell anytime to pull latest changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgtFQn1wkmtZ"
      },
      "source": [
        "## Step 0: GitHub Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtzSWno_kmtZ",
        "outputId": "d48b5feb-8a42-42de-a3b8-ad2e21bf6cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GitHub Personal Access Token: ··········\n",
            "Token saved to session.\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "GITHUB_REPO = \"Krishna200608/NeuroFetal-AI\"\n",
        "GITHUB_TOKEN = getpass(\"GitHub Personal Access Token: \")\n",
        "\n",
        "os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
        "os.environ['GITHUB_REPO'] = GITHUB_REPO\n",
        "print(\"Token saved to session.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKltgc-Ckmta"
      },
      "source": [
        "## Step 1: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwiYL_jqkmta",
        "outputId": "847305ef-5389-4419-e660-eb606ad8baca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Cloning into 'NeuroFetal-AI'...\n",
            "remote: Enumerating objects: 1354, done.\u001b[K\n",
            "remote: Counting objects: 100% (1354/1354), done.\u001b[K\n",
            "remote: Compressing objects: 100% (741/741), done.\u001b[K\n",
            "remote: Total 1354 (delta 673), reused 1276 (delta 599), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1354/1354), 40.81 MiB | 15.37 MiB/s, done.\n",
            "Resolving deltas: 100% (673/673), done.\n",
            "\n",
            "SUCCESS: Found 552 dataset records!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Always start from /content\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "GITHUB_REPO = os.environ.get('GITHUB_REPO', 'Krishna200608/NeuroFetal-AI')\n",
        "GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN', '')\n",
        "\n",
        "# Clean clone for fresh start\n",
        "if os.path.exists(\"NeuroFetal-AI\"):\n",
        "    shutil.rmtree(\"NeuroFetal-AI\")\n",
        "    print(\"Removed old clone.\")\n",
        "\n",
        "print(\"Cloning repository...\")\n",
        "if GITHUB_TOKEN:\n",
        "    !git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\n",
        "else:\n",
        "    !git clone https://github.com/{GITHUB_REPO}.git\n",
        "\n",
        "# Verify\n",
        "dataset_path = \"/content/NeuroFetal-AI/Datasets/ctu_uhb_data\"\n",
        "if os.path.exists(dataset_path):\n",
        "    count = len([f for f in os.listdir(dataset_path) if f.endswith('.dat')])\n",
        "    print(f\"\\nSUCCESS: Found {count} dataset records!\")\n",
        "else:\n",
        "    print(f\"\\n ERROR: Dataset folder not found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz3FmjhHkmtb"
      },
      "source": [
        "## Update Repo (Run anytime to pull latest changes)\n",
        "**Run this cell whenever you make changes on GitHub or encounter errors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqDHyPockmtb",
        "outputId": "6b9c3275-4bbb-4514-bad9-58f15d478e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 864 bytes | 432.00 KiB/s, done.\n",
            "From https://github.com/Krishna200608/NeuroFetal-AI\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   995247c..498fe3f  main       -> origin/main\n",
            "Updating 995247c..498fe3f\n",
            "Fast-forward\n",
            " Code/utils/attention_blocks.py | 10 \u001b[32m++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 8 insertions(+), 2 deletions(-)\n",
            "\n",
            " Repository updated! Re-run training cells below.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/NeuroFetal-AI\")\n",
        "!git pull origin main\n",
        "print(\"\\n Repository updated! Re-run training cells below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxV9-Vfdkmtb"
      },
      "source": [
        "## Step 2: Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVVjLuPwkmtc",
        "outputId": "a9be0aa7-5e81-465a-e388-e18db04672cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Working dir: /content/NeuroFetal-AI/Code/scripts\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "PROJECT_ROOT = \"/content/NeuroFetal-AI\"\n",
        "CODE_DIR = os.path.join(PROJECT_ROOT, \"Code\")\n",
        "SCRIPTS_DIR = os.path.join(CODE_DIR, \"scripts\")\n",
        "UTILS_DIR = os.path.join(CODE_DIR, \"utils\")\n",
        "\n",
        "os.chdir(SCRIPTS_DIR)\n",
        "sys.path.insert(0, SCRIPTS_DIR)\n",
        "sys.path.insert(0, UTILS_DIR)\n",
        "sys.path.insert(0, CODE_DIR)\n",
        "\n",
        "print(f\" Working dir: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2CES8S0kmtc"
      },
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P3hbxnehkmtd"
      },
      "outputs": [],
      "source": [
        "!pip install -q wfdb shap scipy --no-deps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e9CgLUQkmtd",
        "outputId": "f255c58b-8962-4596-e231-cbeab5d6cca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n",
            "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQc9vKaSkmtd"
      },
      "source": [
        "## Step 4: Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep6hGEzPkmte",
        "outputId": "5819b6a0-23aa-4136-96bf-35e0e469e90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running data ingestion...\n",
            "Found 552 records.\n",
            "Processed 100 records...\n",
            "Processed 200 records...\n",
            "Processed 300 records...\n",
            "Processed 400 records...\n",
            "Processed 500 records...\n",
            "Processing complete. Processed 552 patients into 2760 slices.\n",
            "Shapes: X_fhr (2760, 1200), X_tabular (2760, 3), y (2760,)\n",
            "Class balance: 200 compromised / 2760 total\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "processed_dir = \"/content/NeuroFetal-AI/Datasets/processed\"\n",
        "\n",
        "if os.path.exists(os.path.join(processed_dir, \"X_fhr.npy\")):\n",
        "    print(\"Processed data exists. Skipping ingestion.\")\n",
        "else:\n",
        "    print(\"Running data ingestion...\")\n",
        "    !python data_ingestion.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9Wl_HaHkmte",
        "outputId": "d09338c0-961b-4e3b-ba74-3afb4e5c618e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FHR: (2760, 1200), Tabular: (2760, 3), Labels: (2760,)\n",
            "Class Balance: 7.25% positive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_fhr = np.load(os.path.join(processed_dir, \"X_fhr.npy\"))\n",
        "X_tabular = np.load(os.path.join(processed_dir, \"X_tabular.npy\"))\n",
        "y = np.load(os.path.join(processed_dir, \"y.npy\"))\n",
        "\n",
        "print(f\"FHR: {X_fhr.shape}, Tabular: {X_tabular.shape}, Labels: {y.shape}\")\n",
        "print(f\"Class Balance: {np.mean(y):.2%} positive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS14iYkzkmte"
      },
      "source": [
        "## Step 5: Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVuSkrsbkmte",
        "outputId": "480fe901-3e78-4504-9f25-36c30dd1b490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-04 17:00:09.166810: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770224409.188467    2057 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770224409.194648    2057 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770224409.210017    2057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770224409.210044    2057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770224409.210048    2057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770224409.210053    2057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "NeuroFetal AI - Enhanced Training Pipeline\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Warning: X_uc.npy not found. CSP features will use synthetic UC.\n",
            "Data loaded:\n",
            "  FHR: (2760, 1200, 1)\n",
            "  Tabular: (2760, 3)\n",
            "  Labels: (2760,)\n",
            "  UC: Not available (will use synthetic)\n",
            "  Class balance: 7.25% positive (compromised)\n",
            "\n",
            "Generating synthetic UC signal for CSP demonstration...\n",
            "\n",
            "Extracting CSP features for Fold 1...\n",
            "  CSP features: train=(2208, 19), val=(552, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 1\n",
            "============================================================\n",
            "2026-02-04 17:00:21.696565: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770224421.696733    2057 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Using Focal Loss (α=0.25, γ=2.0)\n",
            "\n",
            "Training on 2208 samples, validating on 552 samples\n",
            "Class balance - Train: 7.25% positive, Val: 7.25% positive\n",
            "Epoch 1/50\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770224432.996066    2129 service.cc:152] XLA service 0x79ad88004350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1770224432.996101    2129 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1770224457.643051    2129 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-04 17:01:00.952046: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-04 17:01:00.981653: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.8 = (f32[32,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,1,150]{3,2,1,0} %bitcast.34789, f32[128,128,1,3]{3,2,1,0} %bitcast.34793), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/EnhancedFusionResNet_1/conv1d_6_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-04 17:01:01.380917: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-04 17:01:01.412479: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.430924128s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.8 = (f32[32,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,1,150]{3,2,1,0} %bitcast.34789, f32[128,128,1,3]{3,2,1,0} %bitcast.34793), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/EnhancedFusionResNet_1/conv1d_6_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "I0000 00:00:1770224474.342186    2129 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m67/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.4934 - loss: nan - sens_at_spec_85: 0.0848\n",
            "Epoch 1: val_auc improved from -inf to 0.50000, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 938ms/step - auc: 0.4934 - loss: nan - sens_at_spec_85: 0.0825 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m67/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - auc: 0.4851 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16ms/step - auc: 0.4857 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m67/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m68/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "Fold 1 Results:\n",
            "  loss: nan\n",
            "  auc: 0.5000\n",
            "  sens_at_spec_85: 0.0000\n",
            "\n",
            "Extracting CSP features for Fold 2...\n",
            "  CSP features: train=(2208, 19), val=(552, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 2\n",
            "============================================================\n",
            "Using Focal Loss (α=0.25, γ=2.0)\n",
            "\n",
            "Training on 2208 samples, validating on 552 samples\n",
            "Class balance - Train: 7.25% positive, Val: 7.25% positive\n",
            "Epoch 1/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - auc: 0.4831 - loss: nan - sens_at_spec_85: 0.0330\n",
            "Epoch 1: val_auc improved from -inf to 0.50000, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - auc: 0.4832 - loss: nan - sens_at_spec_85: 0.0328 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m68/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m68/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "Fold 2 Results:\n",
            "  loss: nan\n",
            "  auc: 0.5000\n",
            "  sens_at_spec_85: 0.0000\n",
            "\n",
            "Extracting CSP features for Fold 3...\n",
            "  CSP features: train=(2208, 19), val=(552, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 3\n",
            "============================================================\n",
            "Using Focal Loss (α=0.25, γ=2.0)\n",
            "\n",
            "Training on 2208 samples, validating on 552 samples\n",
            "Class balance - Train: 7.25% positive, Val: 7.25% positive\n",
            "Epoch 1/50\n",
            "\u001b[1m67/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - auc: 0.5053 - loss: nan - sens_at_spec_85: 0.0465\n",
            "Epoch 1: val_auc improved from -inf to 0.50000, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 879ms/step - auc: 0.5051 - loss: nan - sens_at_spec_85: 0.0453 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "Fold 3 Results:\n",
            "  loss: nan\n",
            "  auc: 0.5000\n",
            "  sens_at_spec_85: 0.0000\n",
            "\n",
            "Extracting CSP features for Fold 4...\n",
            "  CSP features: train=(2208, 19), val=(552, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 4\n",
            "============================================================\n",
            "Using Focal Loss (α=0.25, γ=2.0)\n",
            "\n",
            "Training on 2208 samples, validating on 552 samples\n",
            "Class balance - Train: 7.25% positive, Val: 7.25% positive\n",
            "Epoch 1/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - auc: 0.5217 - loss: nan - sens_at_spec_85: 0.0859\n",
            "Epoch 1: val_auc improved from -inf to 0.50000, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - auc: 0.5216 - loss: nan - sens_at_spec_85: 0.0859 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m68/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.4923 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.4929 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m67/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "Fold 4 Results:\n",
            "  loss: nan\n",
            "  auc: 0.5000\n",
            "  sens_at_spec_85: 0.0000\n",
            "\n",
            "Extracting CSP features for Fold 5...\n",
            "  CSP features: train=(2208, 19), val=(552, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 5\n",
            "============================================================\n",
            "Using Focal Loss (α=0.25, γ=2.0)\n",
            "\n",
            "Training on 2208 samples, validating on 552 samples\n",
            "Class balance - Train: 7.25% positive, Val: 7.25% positive\n",
            "Epoch 1/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.4868 - loss: nan - sens_at_spec_85: 0.0192\n",
            "Epoch 1: val_auc improved from -inf to 0.50000, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 879ms/step - auc: 0.4870 - loss: nan - sens_at_spec_85: 0.0190 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m68/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 18ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m66/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m65/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.50000\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m67/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.50000\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - auc: 0.5000 - loss: nan - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5000 - val_loss: nan - val_sens_at_spec_85: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "Fold 5 Results:\n",
            "  loss: nan\n",
            "  auc: 0.5000\n",
            "  sens_at_spec_85: 0.0000\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE - SUMMARY\n",
            "============================================================\n",
            "\n",
            "AUC across folds: 0.5000 ± 0.0000\n",
            "  Individual folds: ['0.5000', '0.5000', '0.5000', '0.5000', '0.5000']\n",
            "\n",
            "Results saved to: /content/NeuroFetal-AI/Reports/training_logs/training_log_20260204_171404.json\n",
            "\n",
            "============================================================\n",
            "✓ Training pipeline completed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFHYbm-Zkmte"
      },
      "source": [
        "## Step 6: Explainability (XAI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO0vTA6Qkmtf",
        "outputId": "41b60bdf-1ac0-4e86-a582-74731aff7b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-04 17:14:08.526516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770225248.546708    6668 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770225248.554492    6668 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770225248.570279    6668 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770225248.570305    6668 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770225248.570309    6668 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770225248.570314    6668 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading model from /content/NeuroFetal-AI/Code/models/best_model_fold_1.keras...\n",
            "2026-02-04 17:14:17.127949: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770225257.128122    6668 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Generating Grad-CAM using layer: conv1d_7\n",
            "I0000 00:00:1770225258.886717    6668 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "Saved grad_cam.png\n",
            "Running SHAP...\n",
            "/usr/local/lib/python3.12/dist-packages/shap/explainers/_deep/deep_tf.py:94: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "  warnings.warn(\n",
            "Saved shap_summary.png\n"
          ]
        }
      ],
      "source": [
        "!python xai.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrRvx-kJkmtf"
      },
      "source": [
        "## Step 7: Push Results to GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e8X6crEXkmtf"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"krishnasikheriya001@gmail.com\"\n",
        "!git config --global user.name \"Krishna200608\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooNx0Skhkmtf",
        "outputId": "ff979852-22eb-4ded-c3a3-b43abe0e85c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git restore --staged <file>...\" to unstage)\n",
            "\t\u001b[32mmodified:   Code/figures/grad_cam.png\u001b[m\n",
            "\t\u001b[32mmodified:   Code/figures/shap_summary.png\u001b[m\n",
            "\t\u001b[32mnew file:   Code/models/enhanced_model_fold_1.keras\u001b[m\n",
            "\t\u001b[32mnew file:   Code/models/enhanced_model_fold_2.keras\u001b[m\n",
            "\t\u001b[32mnew file:   Code/models/enhanced_model_fold_3.keras\u001b[m\n",
            "\t\u001b[32mnew file:   Code/models/enhanced_model_fold_4.keras\u001b[m\n",
            "\t\u001b[32mnew file:   Code/models/enhanced_model_fold_5.keras\u001b[m\n",
            "\t\u001b[32mnew file:   Reports/training_logs/training_log_20260204_171404.json\u001b[m\n",
            "\n",
            "[main ba85474] Add trained model from Colab\n",
            " 8 files changed, 49 insertions(+)\n",
            " rewrite Code/figures/grad_cam.png (98%)\n",
            " rewrite Code/figures/shap_summary.png (83%)\n",
            " create mode 100644 Code/models/enhanced_model_fold_1.keras\n",
            " create mode 100644 Code/models/enhanced_model_fold_2.keras\n",
            " create mode 100644 Code/models/enhanced_model_fold_3.keras\n",
            " create mode 100644 Code/models/enhanced_model_fold_4.keras\n",
            " create mode 100644 Code/models/enhanced_model_fold_5.keras\n",
            " create mode 100644 Reports/training_logs/training_log_20260204_171404.json\n",
            "Enumerating objects: 22, done.\n",
            "Counting objects: 100% (22/22), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (15/15), done.\n",
            "Writing objects: 100% (15/15), 33.56 MiB | 11.43 MiB/s, done.\n",
            "Total 15 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   498fe3f..ba85474  main -> main\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/NeuroFetal-AI\")\n",
        "\n",
        "!git add Code/models/*.keras Reports/training_logs/*.json Code/figures/*.png 2>/dev/null || true\n",
        "!git status\n",
        "!git commit -m \"Add trained model from Colab\" || echo \"Nothing to commit\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iObl8Vl0kmtf"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5YYtOO9kmtf",
        "outputId": "9f57b2cb-d7f8-44c0-e678-8ab72cc45e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean AUC: 0.5000 ± 0.0000\n"
          ]
        }
      ],
      "source": [
        "import json, glob, os\n",
        "\n",
        "log_dir = \"/content/NeuroFetal-AI/Reports/training_logs\"\n",
        "logs = sorted(glob.glob(os.path.join(log_dir, \"training_log_*.json\")))\n",
        "\n",
        "if logs:\n",
        "    with open(logs[-1]) as f:\n",
        "        r = json.load(f)\n",
        "    print(f\"Mean AUC: {r['summary']['mean_auc']:.4f} ± {r['summary']['std_auc']:.4f}\")\n",
        "else:\n",
        "    print(\"No training logs found.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}