{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# NeuroFetal AI - Enhanced Fusion ResNet Training\n",
        "\n",
        "**Version 2.0** - With Advanced Enhancements:\n",
        "- 3-Input Architecture (FHR + Tabular + CSP)\n",
        "- Squeeze-and-Excitation (SE) Blocks\n",
        "- Multi-Head Self-Attention\n",
        "- 19 CSP Features (MAD, Beta_0, SQI, etc.)\n",
        "- Focal Loss for Class Imbalance\n",
        "\n",
        "### Instructions:\n",
        "1. **Runtime -> Change runtime type -> GPU (T4)**\n",
        "2. Run cells in order\n",
        "3. Results save to `Reports/training_logs/`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clone-section",
      "metadata": {},
      "source": [
        "## Step 0: Clone Repository from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clone-repo",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION - UPDATE THESE\n",
        "# =============================================================================\n",
        "GITHUB_REPO = \"Krishna200608/NeuroFetal-AI\"  # Your GitHub repo\n",
        "BRANCH = \"main\"  # Branch to clone\n",
        "\n",
        "# Clone repo\n",
        "if not os.path.exists(\"/content/NeuroFetal-AI\"):\n",
        "    !git clone --depth 1 --branch {BRANCH} https://github.com/{GITHUB_REPO}.git /content/NeuroFetal-AI\n",
        "    print(\"Repository cloned successfully!\")\n",
        "else:\n",
        "    # Pull latest changes\n",
        "    !cd /content/NeuroFetal-AI && git pull origin {BRANCH}\n",
        "    print(\"Repository updated!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-paths",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# =============================================================================\n",
        "# PATH SETUP\n",
        "# =============================================================================\n",
        "PROJECT_ROOT = \"/content/NeuroFetal-AI/\"\n",
        "CODE_DIR = os.path.join(PROJECT_ROOT, \"Code\")\n",
        "SCRIPTS_DIR = os.path.join(CODE_DIR, \"scripts\")\n",
        "UTILS_DIR = os.path.join(CODE_DIR, \"utils\")\n",
        "\n",
        "# Validate\n",
        "if not os.path.exists(SCRIPTS_DIR):\n",
        "    print(f\"ERROR: Path not found: {SCRIPTS_DIR}\")\n",
        "    print(\"Check if your repo structure has Code/scripts/\")\n",
        "else:\n",
        "    os.chdir(SCRIPTS_DIR)\n",
        "    sys.path.insert(0, SCRIPTS_DIR)\n",
        "    sys.path.insert(0, UTILS_DIR)\n",
        "    sys.path.insert(0, CODE_DIR)\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "    \n",
        "    print(f\"\\nScripts folder:\")\n",
        "    for f in sorted(os.listdir(SCRIPTS_DIR)):\n",
        "        if f.endswith('.py'):\n",
        "            print(f\"   - {f}\")\n",
        "    print(f\"\\nUtils folder:\")\n",
        "    for f in sorted(os.listdir(UTILS_DIR)):\n",
        "        if f.endswith('.py'):\n",
        "            print(f\"   - {f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "install-deps",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pip-install",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q wfdb shap scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-gpu",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "data-section",
      "metadata": {},
      "source": [
        "## Step 2: Download CTU-UHB Dataset\n",
        "\n",
        "The dataset is hosted on PhysioNet. We'll download it directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "download-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DATASET_DIR = os.path.join(PROJECT_ROOT, \"Datasets\", \"ctu-uhb-ctgdb\")\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "# Download from PhysioNet if not exists\n",
        "if not os.path.exists(os.path.join(DATASET_DIR, \"1001.dat\")):\n",
        "    print(\"Downloading CTU-UHB dataset from PhysioNet...\")\n",
        "    !wget -r -N -c -np -nH --cut-dirs=2 -P {DATASET_DIR} https://physionet.org/files/ctu-uhb-ctgdb/1.0.0/\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(f\"Dataset already exists at {DATASET_DIR}\")\n",
        "    print(f\"Files: {len([f for f in os.listdir(DATASET_DIR) if f.endswith('.dat')])} records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ingestion-section",
      "metadata": {},
      "source": [
        "## Step 3: Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "data-ingestion",
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_dir = os.path.join(PROJECT_ROOT, \"Datasets\", \"processed\")\n",
        "if os.path.exists(os.path.join(processed_dir, \"X_fhr.npy\")):\n",
        "    print(\"Processed data exists. Skipping ingestion.\")\n",
        "else:\n",
        "    print(\"Running data ingestion...\")\n",
        "    !python data_ingestion.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_fhr = np.load(os.path.join(processed_dir, \"X_fhr.npy\"))\n",
        "X_tabular = np.load(os.path.join(processed_dir, \"X_tabular.npy\"))\n",
        "y = np.load(os.path.join(processed_dir, \"y.npy\"))\n",
        "\n",
        "print(f\"Data Summary:\")\n",
        "print(f\"   FHR Shape: {X_fhr.shape}\")\n",
        "print(f\"   Tabular Shape: {X_tabular.shape}\")\n",
        "print(f\"   Labels: {y.shape}\")\n",
        "print(f\"   Class Balance: {np.mean(y):.2%} positive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model-section",
      "metadata": {},
      "source": [
        "## Step 4: Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inspect-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import build_enhanced_fusion_resnet\n",
        "\n",
        "model = build_enhanced_fusion_resnet(\n",
        "    input_shape_fhr=(X_fhr.shape[1], 1),\n",
        "    input_shape_tabular=(X_tabular.shape[1],),\n",
        "    input_shape_csp=(19,),\n",
        "    use_se_blocks=True,\n",
        "    use_attention=True\n",
        ")\n",
        "\n",
        "print(f\"Total Parameters: {model.count_params():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "training-section",
      "metadata": {},
      "source": [
        "## Step 5: Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-training",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xai-section",
      "metadata": {},
      "source": [
        "## Step 6: Explainability (XAI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-xai",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python xai.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "save-section",
      "metadata": {},
      "source": [
        "## Step 7: Save Results to GitHub (Optional)\n",
        "\n",
        "Push trained models and results back to your repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "git-config",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure git (run once)\n",
        "!git config --global user.email \"your-email@example.com\"\n",
        "!git config --global user.name \"Your Name\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "git-push",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Commit and push results\n",
        "# NOTE: For private repos, you'll need to authenticate\n",
        "# Option 1: Use Personal Access Token\n",
        "# !git remote set-url origin https://<TOKEN>@github.com/{GITHUB_REPO}.git\n",
        "\n",
        "os.chdir(PROJECT_ROOT)\n",
        "!git add Code/models/*.keras Reports/training_logs/*.json Code/figures/*.png\n",
        "!git commit -m \"Add trained model and results from Colab\"\n",
        "!git push origin {BRANCH}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "results-section",
      "metadata": {},
      "source": [
        "## Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "show-results",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import glob\n",
        "\n",
        "log_dir = os.path.join(PROJECT_ROOT, \"Reports\", \"training_logs\")\n",
        "logs = sorted(glob.glob(os.path.join(log_dir, \"training_log_*.json\")))\n",
        "\n",
        "if logs:\n",
        "    with open(logs[-1]) as f:\n",
        "        results = json.load(f)\n",
        "    print(f\"Mean AUC: {results['summary']['mean_auc']:.4f} +/- {results['summary']['std_auc']:.4f}\")\n",
        "else:\n",
        "    print(\"No training logs found. Run training first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}