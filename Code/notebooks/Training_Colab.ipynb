{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_md"
      },
      "source": [
        "# NeuroFetal AI — SOTA Training Pipeline\n",
        "\n",
        "**Version 4.0** — 6-Phase SOTA Strategy (AUC 0.84+ Target)\n",
        "\n",
        "This notebook orchestrates the full SOTA pipeline on Google Colab with GPU acceleration.\n",
        "\n",
        "### Pipeline Steps\n",
        "| # | Phase | Script | Expected AUC Lift |\n",
        "|---|-------|--------|-------------------|\n",
        "| 1 | Setup | Clone repo, install deps | — |\n",
        "| 2 | Data Ingestion | `data_ingestion.py` — 18 features, pH 7.15, quality filter | +5–8 pts |\n",
        "| 3 | SSL Pretraining | `pretrain.py` — Masked Autoencoder on FHR | +2–3 pts |\n",
        "| 4 | Primary Training | `train.py` — 200 epochs, focal loss, 4x augment | +3–5 pts |\n",
        "| 5 | Ensemble Training | `train_diverse_ensemble.py` — InceptionNet + XGB + Stacking | +3–5 pts |\n",
        "| 6 | Evaluation | `evaluate_ensemble.py` — Temp scaling, TTA, calibration | +1–2 pts |\n",
        "| 7 | Deployment | `convert_to_tflite.py` — TFLite & auto-push | — |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_md"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "github_auth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeaaa351-7599-4738-dc35-4defba4c190b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GitHub Token loaded from Secrets.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# 1. GitHub Authentication\n",
        "GITHUB_REPO = \"Krishna200608/NeuroFetal-AI\"\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "    print(\"✓ GitHub Token loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Error loading GITHUB_TOKEN from Secrets. Falling back to manual input.\")\n",
        "    from getpass import getpass\n",
        "    GITHUB_TOKEN = getpass(\"Enter GitHub Personal Access Token (PAT): \")\n",
        "\n",
        "os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
        "os.environ['GITHUB_REPO'] = GITHUB_REPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clone_repo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8cddda-cae0-43f0-a60b-b4ae228baadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Cloning into 'NeuroFetal-AI'...\n",
            "remote: Enumerating objects: 2112, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 2112 (delta 97), reused 85 (delta 84), pack-reused 1992 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2112/2112), 645.05 MiB | 16.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1204/1204), done.\n",
            "Updating files: 100% (1211/1211), done.\n",
            "✓ Cloned successfully!\n"
          ]
        }
      ],
      "source": [
        "# 2. Clone Repository\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Reset to /content before deleting the repo folder\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Clean up any previous clone\n",
        "if os.path.exists(\"/content/NeuroFetal-AI\"):\n",
        "    shutil.rmtree(\"/content/NeuroFetal-AI\")\n",
        "\n",
        "print(\"Cloning repository...\")\n",
        "!git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\n",
        "\n",
        "os.chdir(\"/content/NeuroFetal-AI\")\n",
        "print(\"✓ Cloned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "git_config_md"
      },
      "source": [
        "### 1.5 Git Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "git_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c107a1c-548b-40e0-bec1-7c8722bb8a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Git credentials set.\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.email \"krishnasikheriya001@gmail.com\"\n",
        "!git config --global user.name \"Krishna200608\"\n",
        "print(\"✓ Git credentials set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deps_md"
      },
      "source": [
        "### 1.6 Install Dependencies\n",
        "Installs all packages required for the full SOTA pipeline (including XGBoost/LightGBM for ensemble)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "install_deps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94120677-a1bc-4dfb-bf5d-b7c47f9759eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing libraries...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✓ Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing libraries...\")\n",
        "!pip install -q wfdb shap scipy imbalanced-learn pyngrok filterpy \\\n",
        "    scikit-learn matplotlib seaborn pandas numpy tensorflow \\\n",
        "    streamlit plotly python-dotenv xgboost lightgbm\n",
        "print(\"✓ Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_md"
      },
      "source": [
        "---\n",
        "## 2. Data Ingestion (Phase 1–2)\n",
        "\n",
        "Processes raw `.dat`/`.hea` files into clean `.npy` arrays.\n",
        "\n",
        "**SOTA enhancements:**\n",
        "- 18 tabular features (13 signal-derived: STV, LTV, accels/decels, baseline, variability…)\n",
        "- FHR normalization excluding 0-gaps\n",
        "- pH threshold relaxed to 7.15 (FIGO)\n",
        "- Signal quality filter (skip >50% loss)\n",
        "- Feature standardization (Z-score) with saved scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "run_ingestion",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849d43b7-39e6-4e5f-c5cc-0ee916f7bbd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 552 records.\n",
            "pH threshold: 7.15\n",
            "Max signal loss: 50%\n",
            "Processed 100 records...\n",
            "Processed 200 records...\n",
            "Processed 300 records...\n",
            "Processed 400 records...\n",
            "Processed 500 records...\n",
            "\n",
            "Processing complete.\n",
            "  Patients: 552\n",
            "  Total windows: 2546\n",
            "  Skipped (quality): 214\n",
            "  Shapes: X_fhr=(2546, 1200), X_uc=(2546, 1200), X_tabular=(2546, 18), y=(2546,)\n",
            "  Tabular features (18): ['Age', 'Parity', 'Gestation', 'Gravidity', 'Weight', 'fhr_baseline', 'fhr_stv', 'fhr_ltv', 'fhr_accel_count', 'fhr_decel_count', 'fhr_decel_area', 'fhr_range', 'fhr_iqr', 'fhr_entropy', 'uc_freq', 'uc_intensity_mean', 'fhr_uc_lag', 'signal_loss_pct']\n",
            "  Class balance: 470.0 compromised / 2546 total (18.5%)\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/data_ingestion.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_5_md"
      },
      "source": [
        "---\n",
        "## 3. Self-Supervised Pretraining\n",
        "\n",
        "Train the Masked Autoencoder (MAE) on unlabelled FHR data to learn robust temporal representations.\n",
        "\n",
        "Saves encoder weights → `Code/models/pretrained_fhr_encoder.weights.keras`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "run_pretrain",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a30cc8-7ca0-492a-b15f-e1e6726f699f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-12 17:45:18.685272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770918318.706202    3003 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770918318.713749    3003 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770918318.730595    3003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770918318.730621    3003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770918318.730664    3003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770918318.730708    3003 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-12 17:45:18.735319: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "============================================================\n",
            "SSL Pretraining: Masked Autoencoder\n",
            "============================================================\n",
            "Loading data...\n",
            "Data shape: (2546, 1200, 1)\n",
            "Building MAE...\n",
            "2026-02-12 17:45:27.303593: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770918327.306139    3003 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Starting training for 50 epochs...\n",
            "Epoch 1/50\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770918346.037814    3079 service.cc:152] XLA service 0x7d0cf4005a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1770918346.037850    3079 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-12 17:45:46.425748: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2026-02-12 17:45:47.201029: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:62] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. random_uniform/RandomUniform\n",
            "I0000 00:00:1770918348.975250    3079 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-12 17:45:51.826602: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 17:45:52.117401: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 17:45:52.267903: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "2026-02-12 17:45:53.268002: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.32 = (f32[64,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,128,1,150]{3,2,1,0} %bitcast.27442, f32[128,128,1,3]{3,2,1,0} %bitcast.27446), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-12 17:45:53.622218: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 17:45:54.188108: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 17:45:54.252506: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.98460633s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.32 = (f32[64,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,128,1,150]{3,2,1,0} %bitcast.27442, f32[128,128,1,3]{3,2,1,0} %bitcast.27446), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "I0000 00:00:1770918367.569277    3079 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 495ms/step - loss: 0.1244\n",
            "Epoch 2/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - loss: 0.0584\n",
            "Epoch 3/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0519\n",
            "Epoch 4/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0489\n",
            "Epoch 5/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0438\n",
            "Epoch 6/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0406\n",
            "Epoch 7/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0403\n",
            "Epoch 8/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0382\n",
            "Epoch 9/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0376\n",
            "Epoch 10/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0370\n",
            "Epoch 11/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0355\n",
            "Epoch 12/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0361\n",
            "Epoch 13/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0353\n",
            "Epoch 14/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0340\n",
            "Epoch 15/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0352\n",
            "Epoch 16/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0346\n",
            "Epoch 17/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0344\n",
            "Epoch 18/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0348\n",
            "Epoch 19/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0342\n",
            "Epoch 20/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0332\n",
            "Epoch 21/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0323\n",
            "Epoch 22/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0332\n",
            "Epoch 23/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0332\n",
            "Epoch 24/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0326\n",
            "Epoch 25/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0325\n",
            "Epoch 26/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0315\n",
            "Epoch 27/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0332\n",
            "Epoch 28/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0318\n",
            "Epoch 29/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0311\n",
            "Epoch 30/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0320\n",
            "Epoch 31/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0307\n",
            "Epoch 32/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0306\n",
            "Epoch 33/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0306\n",
            "Epoch 34/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0313\n",
            "Epoch 35/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0297\n",
            "Epoch 36/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0305\n",
            "Epoch 37/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0311\n",
            "Epoch 38/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0299\n",
            "Epoch 39/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0292\n",
            "Epoch 40/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0291\n",
            "Epoch 41/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0290\n",
            "Epoch 42/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0293\n",
            "Epoch 43/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0292\n",
            "Epoch 44/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0286\n",
            "Epoch 45/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0304\n",
            "Epoch 46/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0291\n",
            "Epoch 47/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0289\n",
            "Epoch 48/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0291\n",
            "Epoch 49/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0287\n",
            "Epoch 50/50\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0290\n",
            "Saving encoder model to /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "✓ Pretraining complete!\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/pretrain.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_md"
      },
      "source": [
        "---\n",
        "## 4. Primary Model Training (Phase 3–4)\n",
        "\n",
        "Train the **AttentionFusionResNet** using 5-Fold Cross-Validation.\n",
        "\n",
        "**SOTA enhancements:**\n",
        "- 200 epochs with cosine annealing + warmup\n",
        "- Focal Loss (α=0.65, γ=2.0) — less aggressive for better calibration\n",
        "- 4x data augmentation (SpecAugment + CutMix + time-warp + jitter + mixup)\n",
        "- AdamW with weight decay 5e-4\n",
        "- Backbone right-sized to 192-dim with stochastic depth\n",
        "- Auxiliary pH regression head for multi-task learning\n",
        "- Early stopping patience = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pull_before_train"
      },
      "outputs": [],
      "source": [
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "run_training",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca798368-b851-40ff-c80f-93d0f334f0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-12 17:48:40.590413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770918520.610998    4361 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770918520.618996    4361 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770918520.634991    4361 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770918520.635013    4361 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770918520.635016    4361 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770918520.635022    4361 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-12 17:48:40.639666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "============================================================\n",
            "NeuroFetal AI - Enhanced Training Pipeline\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Data loaded:\n",
            "  FHR: (2546, 1200, 1)\n",
            "  Tabular: (2546, 18)\n",
            "  Labels: (2546,)\n",
            "  UC: Available\n",
            "  Class balance: 18.46% positive (compromised)\n",
            "\n",
            "✓ Real UC data available - CSP features ENABLED.\n",
            "\n",
            "========================================\n",
            "Running Fold 1/5\n",
            "========================================\n",
            "\n",
            "Applying SMOTE to Fold 1...\n",
            "  Before SMOTE: 376.0 positives / 2036 total\n",
            "  SMOTE Input: (2036, 2418) (Pos Class: 376.0 samples)\n",
            "  SMOTE Output: (2490, 2418) (Pos Class: 830.0 samples)\n",
            "  After SMOTE:  830.0 positives / 2490 total\n",
            "\n",
            "Extracting CSP features for Fold 1...\n",
            "  CSP features: train=(2490, 19), val=(510, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 1\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2490 → 9960\n",
            "Applied label smoothing (factor=0.1)\n",
            "2026-02-12 17:48:57.949232: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770918537.950797    4361 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "I0000 00:00:1770918540.545751    4361 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9960 samples, validating on 510 samples\n",
            "Class balance - Train: 34.97% positive, Val: 18.43% positive\n",
            "Epoch 1/200\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770918563.963980    4452 service.cc:152] XLA service 0x7a20ac006090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1770918563.964021    4452 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-12 17:49:24.573339: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2026-02-12 17:50:15.512089: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 17:50:15.593991: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.21 = (f32[32,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,1,150]{3,2,1,0} %bitcast.70353, f32[128,128,1,3]{3,2,1,0} %bitcast.70357), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/AttentionFusionResNet_1/shared_fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-12 17:50:15.964943: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 17:50:15.997127: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.403210381s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.21 = (f32[32,128,1,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,1,150]{3,2,1,0} %bitcast.70353, f32[128,128,1,3]{3,2,1,0} %bitcast.70357), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/AttentionFusionResNet_1/shared_fhr_encoder_1/conv1d_8_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "I0000 00:00:1770918637.766684    4452 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - auc: 0.0000e+00 - loss: 0.2308 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.52323, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 629ms/step - auc: 0.0000e+00 - loss: 0.2308 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5232 - val_loss: 0.1450 - val_sens_at_spec_85: 0.1170 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.2044 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.2044 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4535 - val_loss: 0.1427 - val_sens_at_spec_85: 0.0638 - learning_rate: 2.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.2005 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.2005 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4171 - val_loss: 0.1470 - val_sens_at_spec_85: 0.0851 - learning_rate: 3.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1976 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1976 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4726 - val_loss: 0.1459 - val_sens_at_spec_85: 0.0638 - learning_rate: 4.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1944 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1944 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4346 - val_loss: 0.1573 - val_sens_at_spec_85: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1937 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1937 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4260 - val_loss: 0.1568 - val_sens_at_spec_85: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1940 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1940 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4448 - val_loss: 0.1478 - val_sens_at_spec_85: 0.0426 - learning_rate: 4.9997e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1904 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1904 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4683 - val_loss: 0.1522 - val_sens_at_spec_85: 0.0638 - learning_rate: 4.9987e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1915 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.52323\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1915 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4320 - val_loss: 0.1589 - val_sens_at_spec_85: 0.1170 - learning_rate: 4.9971e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1850 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.52323 to 0.58557, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1850 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5856 - val_loss: 0.1429 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.9948e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1847 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.58557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1847 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5639 - val_loss: 0.1409 - val_sens_at_spec_85: 0.1702 - learning_rate: 4.9919e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1833 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.58557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1833 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5592 - val_loss: 0.1455 - val_sens_at_spec_85: 0.1596 - learning_rate: 4.9883e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1797 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc improved from 0.58557 to 0.60091, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1797 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6009 - val_loss: 0.1516 - val_sens_at_spec_85: 0.1915 - learning_rate: 4.9841e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1788 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc did not improve from 0.60091\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1788 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5607 - val_loss: 0.1555 - val_sens_at_spec_85: 0.1170 - learning_rate: 4.9793e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1744 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.60091\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1744 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5315 - val_loss: 0.1558 - val_sens_at_spec_85: 0.1277 - learning_rate: 4.9738e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1707 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.60091\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1707 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5855 - val_loss: 0.1572 - val_sens_at_spec_85: 0.1170 - learning_rate: 4.9676e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1733 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.60091\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1733 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6005 - val_loss: 0.1525 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.9608e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1650 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc improved from 0.60091 to 0.62003, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1650 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6200 - val_loss: 0.1493 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.9534e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1664 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.62003\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1664 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5655 - val_loss: 0.1612 - val_sens_at_spec_85: 0.1809 - learning_rate: 4.9454e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1692 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.62003\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1692 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5500 - val_loss: 0.1615 - val_sens_at_spec_85: 0.1383 - learning_rate: 4.9367e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1576 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.62003\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1576 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5701 - val_loss: 0.1734 - val_sens_at_spec_85: 0.1277 - learning_rate: 4.9274e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1574 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc improved from 0.62003 to 0.62322, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1575 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6232 - val_loss: 0.1782 - val_sens_at_spec_85: 0.1809 - learning_rate: 4.9174e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1544 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.62322\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1544 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5760 - val_loss: 0.1969 - val_sens_at_spec_85: 0.1489 - learning_rate: 4.9068e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1512 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.62322\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1512 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5965 - val_loss: 0.1759 - val_sens_at_spec_85: 0.2021 - learning_rate: 4.8956e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1474 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.62322\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1474 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6203 - val_loss: 0.2157 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.8838e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1431 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.62322\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1431 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6123 - val_loss: 0.1619 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.8713e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1447 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.62322\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1447 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5894 - val_loss: 0.1856 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.8583e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1429 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc improved from 0.62322 to 0.63089, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1430 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6309 - val_loss: 0.1960 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.8446e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1359 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.63089\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1359 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6268 - val_loss: 0.1821 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.8303e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1358 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.63089\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1358 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6240 - val_loss: 0.3628 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.8154e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1350 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.63089\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1349 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6133 - val_loss: 0.2764 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.7999e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1295 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc improved from 0.63089 to 0.66918, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1295 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6692 - val_loss: 0.2248 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.7839e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1275 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1275 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5988 - val_loss: 0.2292 - val_sens_at_spec_85: 0.2234 - learning_rate: 4.7672e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1276 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1276 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6210 - val_loss: 0.3302 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.7499e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1192 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1193 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6063 - val_loss: 0.3063 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.7321e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1186 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1186 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6196 - val_loss: 0.3385 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.7136e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1164 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1164 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6304 - val_loss: 0.2601 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.6946e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1155 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6468 - val_loss: 0.3758 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.6751e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1119 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1119 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6404 - val_loss: 0.4339 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.6549e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1064 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1064 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6512 - val_loss: 0.2585 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.6342e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1055 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1056 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6359 - val_loss: 0.3788 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.6130e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1034 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1034 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6533 - val_loss: 0.3288 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.5912e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1084 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1084 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6485 - val_loss: 0.4854 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.5688e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1055 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1055 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6545 - val_loss: 0.2851 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.5460e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1041 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1041 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6479 - val_loss: 0.3025 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.5225e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1000 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1000 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6486 - val_loss: 0.2924 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.4986e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1004 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1004 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6356 - val_loss: 0.3149 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.4742e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0979 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0979 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6454 - val_loss: 0.2999 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.4492e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0939 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0939 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6385 - val_loss: 0.4141 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.4237e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0948 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0948 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6361 - val_loss: 0.3273 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.3977e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0925 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0926 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6161 - val_loss: 0.2783 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.3713e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0945 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0945 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6282 - val_loss: 0.3527 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.3443e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0922 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0922 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6085 - val_loss: 0.4674 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.3169e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0895 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0895 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6458 - val_loss: 0.3072 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.2890e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0883 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0883 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6521 - val_loss: 0.4337 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.2606e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0875 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0875 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6362 - val_loss: 0.3972 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.2318e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0847 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.66918\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0847 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6302 - val_loss: 0.3606 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.2025e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0852 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc improved from 0.66918 to 0.67717, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0852 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6772 - val_loss: 0.5739 - val_sens_at_spec_85: 0.3617 - learning_rate: 4.1728e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0865 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.67717\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0865 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6752 - val_loss: 0.3728 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.1427e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0828 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.67717\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0828 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6597 - val_loss: 0.5474 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.1121e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0830 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.67717\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0830 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6614 - val_loss: 0.4071 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.0811e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0804 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.67717\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0804 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6257 - val_loss: 0.4818 - val_sens_at_spec_85: 0.2234 - learning_rate: 4.0497e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0843 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc improved from 0.67717 to 0.68965, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0843 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6896 - val_loss: 0.4053 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.0179e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0811 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0811 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6713 - val_loss: 0.4909 - val_sens_at_spec_85: 0.3511 - learning_rate: 3.9857e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0817 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0817 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6529 - val_loss: 0.4653 - val_sens_at_spec_85: 0.2766 - learning_rate: 3.9531e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0784 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0785 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6408 - val_loss: 0.4573 - val_sens_at_spec_85: 0.2979 - learning_rate: 3.9202e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0795 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0795 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6294 - val_loss: 0.5089 - val_sens_at_spec_85: 0.3085 - learning_rate: 3.8868e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1037 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1036 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6715 - val_loss: 0.4224 - val_sens_at_spec_85: 0.3830 - learning_rate: 3.8531e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0796 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0796 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6364 - val_loss: 0.4037 - val_sens_at_spec_85: 0.3298 - learning_rate: 3.8191e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0784 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0783 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6412 - val_loss: 0.5470 - val_sens_at_spec_85: 0.2766 - learning_rate: 3.7847e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0777 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0777 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6322 - val_loss: 0.4781 - val_sens_at_spec_85: 0.2553 - learning_rate: 3.7500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0775 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0775 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6544 - val_loss: 0.4478 - val_sens_at_spec_85: 0.3298 - learning_rate: 3.7150e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0778 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0778 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6591 - val_loss: 0.5461 - val_sens_at_spec_85: 0.3404 - learning_rate: 3.6796e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0769 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0768 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6774 - val_loss: 0.3889 - val_sens_at_spec_85: 0.2872 - learning_rate: 3.6439e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0782 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0782 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6735 - val_loss: 0.4748 - val_sens_at_spec_85: 0.2979 - learning_rate: 3.6080e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0773 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0773 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6864 - val_loss: 0.5121 - val_sens_at_spec_85: 0.4149 - learning_rate: 3.5717e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0735 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0735 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6725 - val_loss: 0.5748 - val_sens_at_spec_85: 0.3404 - learning_rate: 3.5352e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0726 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0726 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6452 - val_loss: 0.5682 - val_sens_at_spec_85: 0.3936 - learning_rate: 3.4984e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0750 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0750 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6478 - val_loss: 0.4976 - val_sens_at_spec_85: 0.3830 - learning_rate: 3.4614e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0735 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0735 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6591 - val_loss: 0.4867 - val_sens_at_spec_85: 0.3511 - learning_rate: 3.4241e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0753 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0753 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6780 - val_loss: 0.3917 - val_sens_at_spec_85: 0.3511 - learning_rate: 3.3865e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0715 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0715 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6606 - val_loss: 0.4384 - val_sens_at_spec_85: 0.3511 - learning_rate: 3.3487e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0717 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0717 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6855 - val_loss: 0.6553 - val_sens_at_spec_85: 0.3830 - learning_rate: 3.3107e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0715 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0715 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6644 - val_loss: 0.5376 - val_sens_at_spec_85: 0.3723 - learning_rate: 3.2725e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0718 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0718 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6744 - val_loss: 0.4372 - val_sens_at_spec_85: 0.3404 - learning_rate: 3.2341e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0699 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0699 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6706 - val_loss: 0.5189 - val_sens_at_spec_85: 0.3617 - learning_rate: 3.1955e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0696 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0696 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6581 - val_loss: 0.4437 - val_sens_at_spec_85: 0.2766 - learning_rate: 3.1568e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0715 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0715 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6660 - val_loss: 0.5836 - val_sens_at_spec_85: 0.2979 - learning_rate: 3.1178e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0708 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0708 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6611 - val_loss: 0.5656 - val_sens_at_spec_85: 0.3511 - learning_rate: 3.0787e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0691 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0691 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6755 - val_loss: 0.4436 - val_sens_at_spec_85: 0.3936 - learning_rate: 3.0395e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0690 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0690 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6646 - val_loss: 0.4612 - val_sens_at_spec_85: 0.3404 - learning_rate: 3.0001e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0681 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0681 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6672 - val_loss: 0.4661 - val_sens_at_spec_85: 0.3511 - learning_rate: 2.9605e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0704 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0704 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6487 - val_loss: 0.5308 - val_sens_at_spec_85: 0.3298 - learning_rate: 2.9209e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0685 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0685 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6688 - val_loss: 0.4878 - val_sens_at_spec_85: 0.4043 - learning_rate: 2.8811e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0676 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0676 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6636 - val_loss: 0.6441 - val_sens_at_spec_85: 0.2660 - learning_rate: 2.8413e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6600 - val_loss: 0.5810 - val_sens_at_spec_85: 0.3298 - learning_rate: 2.8013e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0683 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0683 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6402 - val_loss: 0.5375 - val_sens_at_spec_85: 0.2660 - learning_rate: 2.7613e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.68965\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6740 - val_loss: 0.5356 - val_sens_at_spec_85: 0.3617 - learning_rate: 2.7212e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0668 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc improved from 0.68965 to 0.69003, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0668 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6900 - val_loss: 0.4322 - val_sens_at_spec_85: 0.3936 - learning_rate: 2.6811e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0676 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.69003\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0676 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6647 - val_loss: 0.4402 - val_sens_at_spec_85: 0.3617 - learning_rate: 2.6409e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0686 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc improved from 0.69003 to 0.69402, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0686 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6940 - val_loss: 0.4927 - val_sens_at_spec_85: 0.3617 - learning_rate: 2.6007e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0667 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc improved from 0.69402 to 0.71309, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0667 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7131 - val_loss: 0.4469 - val_sens_at_spec_85: 0.4043 - learning_rate: 2.5604e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0664 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 103: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0664 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7034 - val_loss: 0.5027 - val_sens_at_spec_85: 0.4043 - learning_rate: 2.5201e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0640 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 104: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0640 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6930 - val_loss: 0.4202 - val_sens_at_spec_85: 0.3617 - learning_rate: 2.4799e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0661 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 105: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0661 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7116 - val_loss: 0.5509 - val_sens_at_spec_85: 0.3936 - learning_rate: 2.4396e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0647 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 106: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0647 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7104 - val_loss: 0.5399 - val_sens_at_spec_85: 0.4255 - learning_rate: 2.3993e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0667 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 107: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0667 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6859 - val_loss: 0.6125 - val_sens_at_spec_85: 0.4149 - learning_rate: 2.3591e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0673 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 108: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0673 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6976 - val_loss: 0.4796 - val_sens_at_spec_85: 0.3617 - learning_rate: 2.3189e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0682 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 109: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0682 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6719 - val_loss: 0.3865 - val_sens_at_spec_85: 0.3404 - learning_rate: 2.2788e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0670 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 110: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0670 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6884 - val_loss: 0.5424 - val_sens_at_spec_85: 0.3936 - learning_rate: 2.2387e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0664 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 111: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0664 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6695 - val_loss: 0.4896 - val_sens_at_spec_85: 0.3511 - learning_rate: 2.1987e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0645 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 112: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0645 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6989 - val_loss: 0.5081 - val_sens_at_spec_85: 0.4043 - learning_rate: 2.1587e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0644 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 113: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0645 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6945 - val_loss: 0.5155 - val_sens_at_spec_85: 0.3723 - learning_rate: 2.1189e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0640 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 114: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0640 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6906 - val_loss: 0.5402 - val_sens_at_spec_85: 0.3511 - learning_rate: 2.0791e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0653 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 115: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0653 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6832 - val_loss: 0.5492 - val_sens_at_spec_85: 0.3404 - learning_rate: 2.0395e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0658 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 116: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0658 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6843 - val_loss: 0.5958 - val_sens_at_spec_85: 0.3298 - learning_rate: 1.9999e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0628 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 117: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0628 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6717 - val_loss: 0.6189 - val_sens_at_spec_85: 0.3617 - learning_rate: 1.9605e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0639 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 118: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0639 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6936 - val_loss: 0.5597 - val_sens_at_spec_85: 0.3723 - learning_rate: 1.9213e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0666 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 119: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0665 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6769 - val_loss: 0.5242 - val_sens_at_spec_85: 0.3830 - learning_rate: 1.8822e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0641 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 120: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0641 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6697 - val_loss: 0.5954 - val_sens_at_spec_85: 0.3191 - learning_rate: 1.8432e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0636 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 121: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0636 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6956 - val_loss: 0.6075 - val_sens_at_spec_85: 0.3723 - learning_rate: 1.8045e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0634 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 122: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0634 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6975 - val_loss: 0.5516 - val_sens_at_spec_85: 0.3617 - learning_rate: 1.7659e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0650 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 123: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0649 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6835 - val_loss: 0.5579 - val_sens_at_spec_85: 0.2872 - learning_rate: 1.7275e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0636 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 124: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0636 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6922 - val_loss: 0.5516 - val_sens_at_spec_85: 0.3085 - learning_rate: 1.6893e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0630 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 125: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0630 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6827 - val_loss: 0.5917 - val_sens_at_spec_85: 0.3617 - learning_rate: 1.6513e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0627 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 126: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0627 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6882 - val_loss: 0.5220 - val_sens_at_spec_85: 0.3298 - learning_rate: 1.6135e-04\n",
            "Epoch 127/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0624 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 127: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0624 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6882 - val_loss: 0.6002 - val_sens_at_spec_85: 0.3830 - learning_rate: 1.5759e-04\n",
            "Epoch 128/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0625 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 128: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0625 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6872 - val_loss: 0.5718 - val_sens_at_spec_85: 0.3298 - learning_rate: 1.5386e-04\n",
            "Epoch 129/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0641 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 129: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0641 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6797 - val_loss: 0.5430 - val_sens_at_spec_85: 0.3511 - learning_rate: 1.5016e-04\n",
            "Epoch 130/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0626 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 130: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0626 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6834 - val_loss: 0.4702 - val_sens_at_spec_85: 0.3191 - learning_rate: 1.4648e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0644 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 131: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0644 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6924 - val_loss: 0.5165 - val_sens_at_spec_85: 0.3723 - learning_rate: 1.4283e-04\n",
            "Epoch 132/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0633 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 132: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0633 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6793 - val_loss: 0.5505 - val_sens_at_spec_85: 0.3404 - learning_rate: 1.3920e-04\n",
            "Epoch 133/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0622 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 133: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0622 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6840 - val_loss: 0.5378 - val_sens_at_spec_85: 0.3298 - learning_rate: 1.3561e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0632 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 134: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0632 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7054 - val_loss: 0.5006 - val_sens_at_spec_85: 0.3936 - learning_rate: 1.3204e-04\n",
            "Epoch 135/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0611 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 135: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0611 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6973 - val_loss: 0.5434 - val_sens_at_spec_85: 0.3511 - learning_rate: 1.2850e-04\n",
            "Epoch 136/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0625 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 136: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0625 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7018 - val_loss: 0.5960 - val_sens_at_spec_85: 0.3830 - learning_rate: 1.2500e-04\n",
            "Epoch 137/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0641 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 137: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0641 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6766 - val_loss: 0.5703 - val_sens_at_spec_85: 0.3511 - learning_rate: 1.2153e-04\n",
            "Epoch 138/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0611 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 138: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0611 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6712 - val_loss: 0.6376 - val_sens_at_spec_85: 0.3404 - learning_rate: 1.1809e-04\n",
            "Epoch 139/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0617 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 139: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0617 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6922 - val_loss: 0.5621 - val_sens_at_spec_85: 0.3404 - learning_rate: 1.1469e-04\n",
            "Epoch 140/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0610 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 140: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0610 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6873 - val_loss: 0.5364 - val_sens_at_spec_85: 0.3511 - learning_rate: 1.1132e-04\n",
            "Epoch 141/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0640 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 141: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0640 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6828 - val_loss: 0.6129 - val_sens_at_spec_85: 0.4149 - learning_rate: 1.0798e-04\n",
            "Epoch 142/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0634 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 142: val_auc did not improve from 0.71309\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0634 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6880 - val_loss: 0.6081 - val_sens_at_spec_85: 0.3511 - learning_rate: 1.0469e-04\n",
            "Epoch 142: early stopping\n",
            "Restoring model weights from the end of the best epoch: 102.\n",
            "\n",
            "Fold 1 Results:\n",
            "  loss: 0.4469\n",
            "  auc: 0.7131\n",
            "  sens_at_spec_85: 0.4043\n",
            "\n",
            "========================================\n",
            "Running Fold 2/5\n",
            "========================================\n",
            "\n",
            "Applying SMOTE to Fold 2...\n",
            "  Before SMOTE: 376.0 positives / 2037 total\n",
            "  SMOTE Input: (2037, 2418) (Pos Class: 376.0 samples)\n",
            "  SMOTE Output: (2491, 2418) (Pos Class: 830.0 samples)\n",
            "  After SMOTE:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 2...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 2\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.96% positive, Val: 18.47% positive\n",
            "Epoch 1/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - auc: 0.0000e+00 - loss: 0.2519 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.51592, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 667ms/step - auc: 0.0000e+00 - loss: 0.2518 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5159 - val_loss: 0.1472 - val_sens_at_spec_85: 0.1596 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.2014 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.51592\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.2014 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4919 - val_loss: 0.1516 - val_sens_at_spec_85: 0.1170 - learning_rate: 2.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1912 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc did not improve from 0.51592\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1912 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4930 - val_loss: 0.1521 - val_sens_at_spec_85: 0.1277 - learning_rate: 3.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1870 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc improved from 0.51592 to 0.53662, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1870 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5366 - val_loss: 0.1419 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1832 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc improved from 0.53662 to 0.61434, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1832 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6143 - val_loss: 0.1374 - val_sens_at_spec_85: 0.2553 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1762 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc improved from 0.61434 to 0.64067, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1762 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6407 - val_loss: 0.1361 - val_sens_at_spec_85: 0.2766 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1668 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.64067 to 0.69362, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1668 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6936 - val_loss: 0.1311 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.9997e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1617 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.69362\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1617 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6833 - val_loss: 0.1385 - val_sens_at_spec_85: 0.3298 - learning_rate: 4.9987e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1575 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.69362\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1575 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6934 - val_loss: 0.1323 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.9971e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1511 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.69362 to 0.70437, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1510 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7044 - val_loss: 0.1353 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.9948e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1478 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.70437\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1478 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6976 - val_loss: 0.1430 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.9919e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1396 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.70437\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1396 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7003 - val_loss: 0.1531 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.9883e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1388 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc improved from 0.70437 to 0.70617, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1388 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7062 - val_loss: 0.1415 - val_sens_at_spec_85: 0.3085 - learning_rate: 4.9841e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1298 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc improved from 0.70617 to 0.72743, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1298 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7274 - val_loss: 0.1369 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.9793e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1320 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.72743\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1320 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7141 - val_loss: 0.1658 - val_sens_at_spec_85: 0.3191 - learning_rate: 4.9738e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1294 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.72743\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1294 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7247 - val_loss: 0.2018 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.9676e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1296 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.72743\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1296 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6938 - val_loss: 0.1822 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.9608e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1232 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc improved from 0.72743 to 0.73557, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1232 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7356 - val_loss: 0.1569 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.9534e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1162 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.73557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1162 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7165 - val_loss: 0.1738 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.9454e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.73557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1156 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7253 - val_loss: 0.1608 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.9367e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1125 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.73557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1125 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7299 - val_loss: 0.1921 - val_sens_at_spec_85: 0.3511 - learning_rate: 4.9274e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1093 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc improved from 0.73557 to 0.74290, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1093 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7429 - val_loss: 0.1969 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.9174e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1036 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc improved from 0.74290 to 0.74672, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1036 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7467 - val_loss: 0.2013 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9068e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1002 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc improved from 0.74672 to 0.76028, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1003 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7603 - val_loss: 0.2039 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.8956e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0992 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.76028\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0992 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7466 - val_loss: 0.2303 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.8838e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0917 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.76028\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0917 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7387 - val_loss: 0.2160 - val_sens_at_spec_85: 0.3723 - learning_rate: 4.8713e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0922 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.76028\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0922 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7378 - val_loss: 0.2840 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.8583e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0911 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc improved from 0.76028 to 0.77463, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0910 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7746 - val_loss: 0.2074 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.8446e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0872 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc improved from 0.77463 to 0.78045, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0872 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7805 - val_loss: 0.2116 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.8303e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0855 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0855 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7418 - val_loss: 0.2330 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.8154e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0858 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0858 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7472 - val_loss: 0.3400 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.7999e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0823 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0823 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7564 - val_loss: 0.2549 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.7839e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0772 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0772 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7567 - val_loss: 0.3663 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.7672e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0766 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0766 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7587 - val_loss: 0.2644 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.7499e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0718 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0718 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7698 - val_loss: 0.2436 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.7321e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0747 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0747 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7547 - val_loss: 0.3140 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.7136e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0721 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0721 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7653 - val_loss: 0.2559 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.6946e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0720 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0720 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7732 - val_loss: 0.3741 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.6751e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0706 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0706 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7787 - val_loss: 0.2771 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.6549e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0689 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7764 - val_loss: 0.2480 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.6342e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0672 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0672 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7611 - val_loss: 0.3154 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.6130e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0591 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0591 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7575 - val_loss: 0.3169 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.5912e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0632 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0632 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7686 - val_loss: 0.3493 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.5688e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0623 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0623 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7633 - val_loss: 0.3746 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.5460e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0681 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0681 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7615 - val_loss: 0.3403 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.5225e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0605 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0605 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7774 - val_loss: 0.2998 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.4986e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0595 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0595 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7767 - val_loss: 0.2562 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.4742e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0587 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0587 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7714 - val_loss: 0.2582 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.4492e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0565 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0565 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7318 - val_loss: 0.4586 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.4237e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0587 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0586 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7529 - val_loss: 0.3820 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.3977e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0581 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0581 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7418 - val_loss: 0.3412 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.3713e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0524 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0524 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7544 - val_loss: 0.3311 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.3443e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0545 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0545 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7603 - val_loss: 0.4450 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.3169e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0537 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.78045\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0537 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7492 - val_loss: 0.4331 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.2890e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc improved from 0.78045 to 0.78899, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7890 - val_loss: 0.3505 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.2606e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0516 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0516 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7618 - val_loss: 0.4380 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.2318e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0470 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0470 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7734 - val_loss: 0.3889 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.2025e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7729 - val_loss: 0.4642 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.1728e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0491 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0492 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7389 - val_loss: 0.5345 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.1427e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0500 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0500 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7756 - val_loss: 0.3590 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.1121e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0478 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0478 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7519 - val_loss: 0.4771 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.0811e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0473 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0473 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7474 - val_loss: 0.4111 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.0497e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0469 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0469 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7614 - val_loss: 0.4766 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.0179e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0479 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0479 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7317 - val_loss: 0.6499 - val_sens_at_spec_85: 0.4362 - learning_rate: 3.9857e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0467 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0467 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7748 - val_loss: 0.3048 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.9531e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0459 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0459 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7549 - val_loss: 0.4277 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.9202e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0437 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0437 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7715 - val_loss: 0.3415 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.8868e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0420 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0420 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7695 - val_loss: 0.3792 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.8531e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0474 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0474 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7667 - val_loss: 0.5509 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.8191e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0415 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0415 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7693 - val_loss: 0.4160 - val_sens_at_spec_85: 0.5106 - learning_rate: 3.7847e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0421 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0421 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7713 - val_loss: 0.3838 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.7500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0423 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0423 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7506 - val_loss: 0.4705 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.7150e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0429 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0428 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7705 - val_loss: 0.6145 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.6796e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0431 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0431 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7840 - val_loss: 0.4236 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.6439e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0444 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0444 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7600 - val_loss: 0.5220 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.6080e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0411 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0411 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7749 - val_loss: 0.4820 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.5717e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0376 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.78899\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0376 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7678 - val_loss: 0.6501 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.5352e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0436 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc improved from 0.78899 to 0.79310, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0436 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7931 - val_loss: 0.4220 - val_sens_at_spec_85: 0.6064 - learning_rate: 3.4984e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0431 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0431 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7809 - val_loss: 0.5374 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.4614e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0378 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0378 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7704 - val_loss: 0.5836 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.4241e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0399 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0399 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7839 - val_loss: 0.4117 - val_sens_at_spec_85: 0.5213 - learning_rate: 3.3865e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7754 - val_loss: 0.6206 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.3487e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0393 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0393 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7742 - val_loss: 0.4215 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.3107e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0402 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0403 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7755 - val_loss: 0.3911 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.2725e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0413 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0413 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7633 - val_loss: 0.5444 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.2341e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0403 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0403 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7734 - val_loss: 0.4635 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.1955e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0387 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0387 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7678 - val_loss: 0.8280 - val_sens_at_spec_85: 0.4681 - learning_rate: 3.1568e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0374 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0374 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7669 - val_loss: 0.5897 - val_sens_at_spec_85: 0.4894 - learning_rate: 3.1178e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0360 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0361 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7699 - val_loss: 0.4726 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.0787e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0343 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0343 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7765 - val_loss: 0.4527 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.0395e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0371 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0371 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7707 - val_loss: 0.5058 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.0001e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0401 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0401 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7799 - val_loss: 0.4476 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.9605e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0372 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0372 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7735 - val_loss: 0.6869 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.9209e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0362 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0362 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7863 - val_loss: 0.4570 - val_sens_at_spec_85: 0.5000 - learning_rate: 2.8811e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0380 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0380 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7690 - val_loss: 0.6775 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.8413e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7718 - val_loss: 0.5802 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.8013e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0324 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0324 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7592 - val_loss: 0.6371 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.7613e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0356 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0356 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7618 - val_loss: 0.6123 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.7212e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0353 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0353 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7804 - val_loss: 0.7064 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.6811e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0340 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0340 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7686 - val_loss: 0.4864 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.6409e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0337 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0337 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7628 - val_loss: 0.7820 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.6007e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0342 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0342 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7663 - val_loss: 0.8076 - val_sens_at_spec_85: 0.5000 - learning_rate: 2.5604e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0338 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 103: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0338 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7538 - val_loss: 0.5552 - val_sens_at_spec_85: 0.5000 - learning_rate: 2.5201e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0353 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 104: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0353 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7614 - val_loss: 0.8392 - val_sens_at_spec_85: 0.5319 - learning_rate: 2.4799e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0363 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 105: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0362 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7577 - val_loss: 0.6520 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.4396e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0356 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 106: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0356 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7546 - val_loss: 0.8015 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.3993e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0314 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 107: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0314 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7597 - val_loss: 0.7403 - val_sens_at_spec_85: 0.4681 - learning_rate: 2.3591e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0324 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 108: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0324 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7572 - val_loss: 0.8532 - val_sens_at_spec_85: 0.4468 - learning_rate: 2.3189e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0318 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 109: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0318 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7608 - val_loss: 0.8111 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.2788e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0318 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 110: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0318 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7538 - val_loss: 0.7496 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.2387e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0343 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 111: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0343 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7295 - val_loss: 0.9467 - val_sens_at_spec_85: 0.4894 - learning_rate: 2.1987e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0346 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 112: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0346 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7627 - val_loss: 0.6476 - val_sens_at_spec_85: 0.5213 - learning_rate: 2.1587e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0328 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 113: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0328 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7581 - val_loss: 0.7449 - val_sens_at_spec_85: 0.5106 - learning_rate: 2.1189e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0336 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 114: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0336 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7724 - val_loss: 0.6686 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.0791e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0331 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 115: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0331 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7742 - val_loss: 0.6024 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.0395e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0324 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 116: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0324 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7670 - val_loss: 0.7119 - val_sens_at_spec_85: 0.5106 - learning_rate: 1.9999e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0305 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 117: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0305 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7509 - val_loss: 0.7216 - val_sens_at_spec_85: 0.5213 - learning_rate: 1.9605e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0314 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 118: val_auc did not improve from 0.79310\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0314 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7401 - val_loss: 0.9191 - val_sens_at_spec_85: 0.5000 - learning_rate: 1.9213e-04\n",
            "Epoch 118: early stopping\n",
            "Restoring model weights from the end of the best epoch: 78.\n",
            "\n",
            "Fold 2 Results:\n",
            "  loss: 0.4220\n",
            "  auc: 0.7931\n",
            "  sens_at_spec_85: 0.6064\n",
            "\n",
            "========================================\n",
            "Running Fold 3/5\n",
            "========================================\n",
            "\n",
            "Applying SMOTE to Fold 3...\n",
            "  Before SMOTE: 376.0 positives / 2037 total\n",
            "  SMOTE Input: (2037, 2418) (Pos Class: 376.0 samples)\n",
            "  SMOTE Output: (2491, 2418) (Pos Class: 830.0 samples)\n",
            "  After SMOTE:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 3...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 3\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.95% positive, Val: 18.47% positive\n",
            "Epoch 1/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - auc: 0.0000e+00 - loss: 0.2600 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.51148, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 645ms/step - auc: 0.0000e+00 - loss: 0.2599 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5115 - val_loss: 0.1419 - val_sens_at_spec_85: 0.1383 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1997 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.51148 to 0.55278, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1997 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5528 - val_loss: 0.1412 - val_sens_at_spec_85: 0.1170 - learning_rate: 2.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1929 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.55278 to 0.55347, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1929 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5535 - val_loss: 0.1398 - val_sens_at_spec_85: 0.2234 - learning_rate: 3.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1886 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc improved from 0.55347 to 0.58441, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1886 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5844 - val_loss: 0.1625 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1828 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.58441\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1828 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5513 - val_loss: 0.1411 - val_sens_at_spec_85: 0.1277 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1773 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc improved from 0.58441 to 0.67001, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1773 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6700 - val_loss: 0.1387 - val_sens_at_spec_85: 0.3617 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1713 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.67001 to 0.69737, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1713 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6974 - val_loss: 0.1300 - val_sens_at_spec_85: 0.3830 - learning_rate: 4.9997e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1690 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.69737\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1690 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6804 - val_loss: 0.1365 - val_sens_at_spec_85: 0.3404 - learning_rate: 4.9987e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1569 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc improved from 0.69737 to 0.71841, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1570 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7184 - val_loss: 0.1276 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.9971e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1553 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc improved from 0.71841 to 0.74792, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1553 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7479 - val_loss: 0.1246 - val_sens_at_spec_85: 0.3936 - learning_rate: 4.9948e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1511 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1511 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7353 - val_loss: 0.1275 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9919e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1520 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1520 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7319 - val_loss: 0.1306 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9883e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1447 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1447 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7307 - val_loss: 0.1362 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.9841e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1376 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1376 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7178 - val_loss: 0.1308 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9793e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1372 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1372 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7289 - val_loss: 0.1280 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9738e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1301 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1301 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7337 - val_loss: 0.1294 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.9676e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1295 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1295 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7201 - val_loss: 0.1410 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.9608e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1249 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1249 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7383 - val_loss: 0.1287 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9534e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1207 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.74792\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1207 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7327 - val_loss: 0.1469 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.9454e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1117 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc improved from 0.74792 to 0.75292, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1118 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7529 - val_loss: 0.1430 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.9367e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1095 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1095 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7370 - val_loss: 0.1673 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.9274e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1128 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1128 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7472 - val_loss: 0.1728 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.9174e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1046 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1046 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7464 - val_loss: 0.1621 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.9068e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1038 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1038 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7458 - val_loss: 0.1452 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.8956e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1030 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1030 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7472 - val_loss: 0.2200 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.8838e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0960 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0961 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7317 - val_loss: 0.2065 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.8713e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0896 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.75292\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0897 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7483 - val_loss: 0.1780 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.8583e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0853 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc improved from 0.75292 to 0.76812, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0853 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7681 - val_loss: 0.1878 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.8446e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0877 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0877 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7509 - val_loss: 0.1995 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.8303e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0821 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0821 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7541 - val_loss: 0.2397 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.8154e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0852 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0852 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7646 - val_loss: 0.2212 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.7999e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0781 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0781 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7508 - val_loss: 0.2979 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.7839e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0829 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0829 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7475 - val_loss: 0.2515 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.7672e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0780 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0780 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7318 - val_loss: 0.2045 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.7499e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0754 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0754 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7405 - val_loss: 0.2637 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.7321e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0787 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.76812\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0787 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7374 - val_loss: 0.2524 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.7136e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0773 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc improved from 0.76812 to 0.76997, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0773 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7700 - val_loss: 0.2240 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.6946e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0723 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.76997\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0723 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7661 - val_loss: 0.2935 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.6751e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0713 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.76997\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0713 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7396 - val_loss: 0.3037 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.6549e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0659 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.76997\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0659 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7634 - val_loss: 0.3132 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.6342e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0654 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.76997\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0654 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7638 - val_loss: 0.3548 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.6130e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0666 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.76997\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0666 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7654 - val_loss: 0.2123 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.5912e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0668 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.76997\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0668 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7487 - val_loss: 0.3548 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.5688e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0657 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc improved from 0.76997 to 0.77128, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0657 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7713 - val_loss: 0.3030 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.5460e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0635 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0635 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7264 - val_loss: 0.3174 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.5225e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0651 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0651 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7639 - val_loss: 0.2517 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.4986e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0632 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0632 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7701 - val_loss: 0.4381 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.4742e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0592 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0592 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7667 - val_loss: 0.3994 - val_sens_at_spec_85: 0.5957 - learning_rate: 4.4492e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0588 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0588 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7665 - val_loss: 0.2544 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.4237e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0584 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0584 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7562 - val_loss: 0.3332 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.3977e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0541 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0541 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7673 - val_loss: 0.2982 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.3713e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0562 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0562 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7549 - val_loss: 0.2886 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.3443e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7534 - val_loss: 0.3125 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.3169e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0536 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0536 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7498 - val_loss: 0.4852 - val_sens_at_spec_85: 0.5957 - learning_rate: 4.2890e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0588 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0588 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7679 - val_loss: 0.3671 - val_sens_at_spec_85: 0.5851 - learning_rate: 4.2606e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0536 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0536 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7658 - val_loss: 0.4157 - val_sens_at_spec_85: 0.5957 - learning_rate: 4.2318e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0470 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0470 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7613 - val_loss: 0.2787 - val_sens_at_spec_85: 0.5851 - learning_rate: 4.2025e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0526 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0526 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7670 - val_loss: 0.3976 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.1728e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0501 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0501 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7610 - val_loss: 0.4348 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.1427e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0512 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0512 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7370 - val_loss: 0.3634 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.1121e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0511 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0511 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7565 - val_loss: 0.3012 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.0811e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0501 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0501 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7661 - val_loss: 0.3051 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.0497e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0546 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.77128\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0546 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7611 - val_loss: 0.3707 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.0179e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0514 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc improved from 0.77128 to 0.77629, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0514 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7763 - val_loss: 0.4130 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.9857e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0482 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0482 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7744 - val_loss: 0.3202 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.9531e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0491 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0491 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7513 - val_loss: 0.3356 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.9202e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0466 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0467 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7728 - val_loss: 0.4540 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.8868e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0468 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0468 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7487 - val_loss: 0.5707 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.8531e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0464 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0464 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7432 - val_loss: 0.3768 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.8191e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0461 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0461 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7737 - val_loss: 0.3208 - val_sens_at_spec_85: 0.6064 - learning_rate: 3.7847e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0443 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0443 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7645 - val_loss: 0.4208 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.7500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0475 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0475 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7517 - val_loss: 0.3837 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.7150e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0434 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0434 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7461 - val_loss: 0.6201 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.6796e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0447 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0447 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7683 - val_loss: 0.3423 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.6439e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0477 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0477 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7723 - val_loss: 0.4424 - val_sens_at_spec_85: 0.6277 - learning_rate: 3.6080e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0446 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0446 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7730 - val_loss: 0.4047 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.5717e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0455 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0455 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7513 - val_loss: 0.5166 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.5352e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0404 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0404 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7639 - val_loss: 0.4182 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.4984e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0425 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0425 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7559 - val_loss: 0.6009 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.4614e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0451 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0452 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7560 - val_loss: 0.4859 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.4241e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0423 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0423 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7429 - val_loss: 0.4859 - val_sens_at_spec_85: 0.4787 - learning_rate: 3.3865e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0422 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 82: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0422 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7498 - val_loss: 0.3949 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.3487e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0414 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 83: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0414 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7563 - val_loss: 0.5351 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.3107e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0400 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 84: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0400 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7389 - val_loss: 0.5018 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.2725e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0396 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 85: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0396 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7584 - val_loss: 0.7735 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.2341e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0393 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 86: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0393 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7755 - val_loss: 0.4135 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.1955e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0360 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 87: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0360 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7423 - val_loss: 0.6366 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.1568e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 88: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0503 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7694 - val_loss: 0.5441 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.1178e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0420 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 89: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0420 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7669 - val_loss: 0.5584 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.0787e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0358 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 90: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0358 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7531 - val_loss: 0.4243 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.0395e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0356 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 91: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0356 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7480 - val_loss: 0.5645 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.0001e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0397 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 92: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0397 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7511 - val_loss: 0.5195 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.9605e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0395 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 93: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0395 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7537 - val_loss: 0.4191 - val_sens_at_spec_85: 0.5638 - learning_rate: 2.9209e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0393 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 94: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0393 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7603 - val_loss: 0.4477 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.8811e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0366 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 95: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0366 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7383 - val_loss: 0.6610 - val_sens_at_spec_85: 0.5426 - learning_rate: 2.8413e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0344 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 96: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0344 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7579 - val_loss: 0.3897 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.8013e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 97: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7632 - val_loss: 0.3428 - val_sens_at_spec_85: 0.5745 - learning_rate: 2.7613e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 98: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7599 - val_loss: 0.6767 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.7212e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0387 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 99: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0387 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7425 - val_loss: 0.5887 - val_sens_at_spec_85: 0.5638 - learning_rate: 2.6811e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 100: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0364 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7481 - val_loss: 0.6132 - val_sens_at_spec_85: 0.5532 - learning_rate: 2.6409e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0352 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 101: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0352 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7352 - val_loss: 0.6840 - val_sens_at_spec_85: 0.5638 - learning_rate: 2.6007e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0341 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 102: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0341 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7452 - val_loss: 0.8420 - val_sens_at_spec_85: 0.5745 - learning_rate: 2.5604e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0365 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 103: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0365 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7471 - val_loss: 0.5895 - val_sens_at_spec_85: 0.5638 - learning_rate: 2.5201e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0335 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 104: val_auc did not improve from 0.77629\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0335 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7402 - val_loss: 0.5620 - val_sens_at_spec_85: 0.5745 - learning_rate: 2.4799e-04\n",
            "Epoch 104: early stopping\n",
            "Restoring model weights from the end of the best epoch: 64.\n",
            "\n",
            "Fold 3 Results:\n",
            "  loss: 0.4130\n",
            "  auc: 0.7763\n",
            "  sens_at_spec_85: 0.5532\n",
            "\n",
            "========================================\n",
            "Running Fold 4/5\n",
            "========================================\n",
            "\n",
            "Applying SMOTE to Fold 4...\n",
            "  Before SMOTE: 376.0 positives / 2037 total\n",
            "  SMOTE Input: (2037, 2418) (Pos Class: 376.0 samples)\n",
            "  SMOTE Output: (2491, 2418) (Pos Class: 830.0 samples)\n",
            "  After SMOTE:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 4...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 4\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 35.08% positive, Val: 18.47% positive\n",
            "Epoch 1/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - auc: 0.0000e+00 - loss: 0.2270 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.53327, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 645ms/step - auc: 0.0000e+00 - loss: 0.2270 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5333 - val_loss: 0.1402 - val_sens_at_spec_85: 0.2021 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.2058 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc did not improve from 0.53327\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.2058 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4927 - val_loss: 0.1463 - val_sens_at_spec_85: 0.1383 - learning_rate: 2.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.2018 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.53327 to 0.55795, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.2018 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5579 - val_loss: 0.1400 - val_sens_at_spec_85: 0.0957 - learning_rate: 3.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1978 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc did not improve from 0.55795\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1978 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5380 - val_loss: 0.1480 - val_sens_at_spec_85: 0.1596 - learning_rate: 4.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1967 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc did not improve from 0.55795\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1967 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5400 - val_loss: 0.1393 - val_sens_at_spec_85: 0.2234 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1959 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.55795\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1959 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4955 - val_loss: 0.1424 - val_sens_at_spec_85: 0.1383 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1918 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.55795 to 0.58952, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1918 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5895 - val_loss: 0.1430 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.9997e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1892 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.58952\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1892 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5859 - val_loss: 0.1474 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.9987e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1865 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc improved from 0.58952 to 0.62399, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1865 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6240 - val_loss: 0.1414 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.9971e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1869 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.62399\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1869 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5951 - val_loss: 0.1384 - val_sens_at_spec_85: 0.2234 - learning_rate: 4.9948e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1847 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc did not improve from 0.62399\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1847 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5686 - val_loss: 0.1422 - val_sens_at_spec_85: 0.2766 - learning_rate: 4.9919e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1834 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc did not improve from 0.62399\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1834 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5742 - val_loss: 0.1447 - val_sens_at_spec_85: 0.1596 - learning_rate: 4.9883e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1801 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc did not improve from 0.62399\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1801 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6151 - val_loss: 0.1405 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.9841e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1763 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc improved from 0.62399 to 0.64468, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - auc: 0.0000e+00 - loss: 0.1763 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6447 - val_loss: 0.1391 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.9793e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1763 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1763 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6257 - val_loss: 0.1397 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.9738e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1753 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1753 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6060 - val_loss: 0.1444 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.9676e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1723 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1724 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5633 - val_loss: 0.1494 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.9608e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1720 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1720 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5474 - val_loss: 0.1535 - val_sens_at_spec_85: 0.1702 - learning_rate: 4.9534e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1673 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1673 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5620 - val_loss: 0.1512 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.9454e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1661 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1661 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5607 - val_loss: 0.1574 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.9367e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1630 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1630 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5515 - val_loss: 0.1522 - val_sens_at_spec_85: 0.2553 - learning_rate: 4.9274e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1603 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1603 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5584 - val_loss: 0.1573 - val_sens_at_spec_85: 0.1915 - learning_rate: 4.9174e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1606 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1606 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5402 - val_loss: 0.1684 - val_sens_at_spec_85: 0.2234 - learning_rate: 4.9068e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1538 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1538 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5394 - val_loss: 0.1714 - val_sens_at_spec_85: 0.1383 - learning_rate: 4.8956e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1564 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1563 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5321 - val_loss: 0.1704 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.8838e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1497 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1497 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5495 - val_loss: 0.1706 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.8713e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1506 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1506 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5730 - val_loss: 0.1692 - val_sens_at_spec_85: 0.2021 - learning_rate: 4.8583e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1438 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1438 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5994 - val_loss: 0.1602 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.8446e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1442 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1443 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5272 - val_loss: 0.1843 - val_sens_at_spec_85: 0.1809 - learning_rate: 4.8303e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1420 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1420 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6203 - val_loss: 0.1657 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.8154e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1386 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1386 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5584 - val_loss: 0.1828 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.7999e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1399 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1398 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5798 - val_loss: 0.1822 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.7839e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1350 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1351 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5920 - val_loss: 0.1823 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.7672e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1308 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1308 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6055 - val_loss: 0.1746 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.7499e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1330 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1330 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5640 - val_loss: 0.1983 - val_sens_at_spec_85: 0.2021 - learning_rate: 4.7321e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.0000e+00 - loss: 0.1282 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1283 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6059 - val_loss: 0.1954 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.7136e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1277 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1277 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5697 - val_loss: 0.2075 - val_sens_at_spec_85: 0.2021 - learning_rate: 4.6946e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1239 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1239 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6175 - val_loss: 0.1935 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.6751e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1272 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1272 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5997 - val_loss: 0.1974 - val_sens_at_spec_85: 0.1809 - learning_rate: 4.6549e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1205 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1205 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6104 - val_loss: 0.2148 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.6342e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1158 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1158 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6006 - val_loss: 0.2070 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.6130e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1168 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1168 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6043 - val_loss: 0.2101 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.5912e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1153 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1154 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5650 - val_loss: 0.2170 - val_sens_at_spec_85: 0.2234 - learning_rate: 4.5688e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1117 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1117 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5512 - val_loss: 0.2488 - val_sens_at_spec_85: 0.2021 - learning_rate: 4.5460e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1116 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1117 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5754 - val_loss: 0.2439 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.5225e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1119 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1119 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5636 - val_loss: 0.2539 - val_sens_at_spec_85: 0.1702 - learning_rate: 4.4986e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1071 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1072 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5765 - val_loss: 0.2423 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.4742e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1057 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1057 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6144 - val_loss: 0.2657 - val_sens_at_spec_85: 0.2447 - learning_rate: 4.4492e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1030 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1030 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6031 - val_loss: 0.3617 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.4237e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1067 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1067 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5746 - val_loss: 0.3411 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.3977e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1010 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1010 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6068 - val_loss: 0.3180 - val_sens_at_spec_85: 0.2660 - learning_rate: 4.3713e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1001 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1001 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6101 - val_loss: 0.2867 - val_sens_at_spec_85: 0.2128 - learning_rate: 4.3443e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1006 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1006 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6111 - val_loss: 0.2829 - val_sens_at_spec_85: 0.2872 - learning_rate: 4.3169e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0990 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.64468\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0990 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5796 - val_loss: 0.3630 - val_sens_at_spec_85: 0.2340 - learning_rate: 4.2890e-04\n",
            "Epoch 54: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\n",
            "Fold 4 Results:\n",
            "  loss: 0.1391\n",
            "  auc: 0.6447\n",
            "  sens_at_spec_85: 0.2872\n",
            "\n",
            "========================================\n",
            "Running Fold 5/5\n",
            "========================================\n",
            "\n",
            "Applying SMOTE to Fold 5...\n",
            "  Before SMOTE: 376.0 positives / 2037 total\n",
            "  SMOTE Input: (2037, 2418) (Pos Class: 376.0 samples)\n",
            "  SMOTE Output: (2491, 2418) (Pos Class: 830.0 samples)\n",
            "  After SMOTE:  830.0 positives / 2491 total\n",
            "\n",
            "Extracting CSP features for Fold 5...\n",
            "  CSP features: train=(2491, 19), val=(509, 19)\n",
            "\n",
            "============================================================\n",
            "Training Fold 5\n",
            "============================================================\n",
            "Applying data augmentation (expand_factor=4)...\n",
            "  Augmented training samples: 2491 → 9964\n",
            "Applied label smoothing (factor=0.1)\n",
            "Using NOVEL AttentionFusionResNet with Cross-Modal Attention\n",
            "Loading pretrained SSL encoder weights from /content/NeuroFetal-AI/Code/models/pretrained_fhr_encoder.weights.keras...\n",
            "  Loading pretrained encoder model...\n",
            "  Building target encoder variables with dummy pass...\n",
            "✓ Partial weight transfer: 37 layers transferred, 2 skipped (shape mismatch)\n",
            "  Transfer Learning Activated (compatible layers loaded)\n",
            "Using Focal Loss (α=0.65, γ=2.0)\n",
            "Using Cosine Annealing with Warmup LR Scheduler\n",
            "\n",
            "Training on 9964 samples, validating on 509 samples\n",
            "Class balance - Train: 34.99% positive, Val: 18.47% positive\n",
            "Epoch 1/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - auc: 0.0000e+00 - loss: 0.2208 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 1: val_auc improved from -inf to 0.47913, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 646ms/step - auc: 0.0000e+00 - loss: 0.2208 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.4791 - val_loss: 0.1591 - val_sens_at_spec_85: 0.0745 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1844 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 2: val_auc improved from 0.47913 to 0.52467, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 31ms/step - auc: 0.0000e+00 - loss: 0.1844 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5247 - val_loss: 0.1632 - val_sens_at_spec_85: 0.1277 - learning_rate: 2.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1771 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 3: val_auc improved from 0.52467 to 0.58509, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - auc: 0.0000e+00 - loss: 0.1771 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.5851 - val_loss: 0.1420 - val_sens_at_spec_85: 0.1915 - learning_rate: 3.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1692 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 4: val_auc improved from 0.58509 to 0.62722, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1692 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6272 - val_loss: 0.1373 - val_sens_at_spec_85: 0.2979 - learning_rate: 4.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1593 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 5: val_auc improved from 0.62722 to 0.69108, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1593 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6911 - val_loss: 0.1306 - val_sens_at_spec_85: 0.3936 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1502 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 6: val_auc did not improve from 0.69108\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1502 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6814 - val_loss: 0.1349 - val_sens_at_spec_85: 0.3723 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1477 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 7: val_auc improved from 0.69108 to 0.72599, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.1477 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7260 - val_loss: 0.1298 - val_sens_at_spec_85: 0.4362 - learning_rate: 4.9997e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1406 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 8: val_auc did not improve from 0.72599\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1406 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.6829 - val_loss: 0.1434 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9987e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1327 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 9: val_auc did not improve from 0.72599\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1327 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7246 - val_loss: 0.1322 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.9971e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1248 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 10: val_auc did not improve from 0.72599\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1248 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7112 - val_loss: 0.1368 - val_sens_at_spec_85: 0.4043 - learning_rate: 4.9948e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1179 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 11: val_auc improved from 0.72599 to 0.73236, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1179 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7324 - val_loss: 0.1275 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.9919e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1150 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 12: val_auc improved from 0.73236 to 0.74093, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.1150 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7409 - val_loss: 0.1381 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.9883e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1100 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 13: val_auc did not improve from 0.74093\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1100 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7092 - val_loss: 0.1412 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.9841e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.1077 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 14: val_auc did not improve from 0.74093\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.1077 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7299 - val_loss: 0.1415 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.9793e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1013 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 15: val_auc did not improve from 0.74093\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.1013 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7108 - val_loss: 0.1519 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.9738e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0947 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 16: val_auc did not improve from 0.74093\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0947 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7210 - val_loss: 0.1441 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9676e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0918 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 17: val_auc improved from 0.74093 to 0.75015, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0918 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7502 - val_loss: 0.1444 - val_sens_at_spec_85: 0.4681 - learning_rate: 4.9608e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0890 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 18: val_auc did not improve from 0.75015\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0890 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7064 - val_loss: 0.1894 - val_sens_at_spec_85: 0.4149 - learning_rate: 4.9534e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0866 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 19: val_auc did not improve from 0.75015\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0866 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7317 - val_loss: 0.1564 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.9454e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0825 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 20: val_auc did not improve from 0.75015\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0825 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7353 - val_loss: 0.1785 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.9367e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0743 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 21: val_auc did not improve from 0.75015\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0743 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7474 - val_loss: 0.3434 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.9274e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0782 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 22: val_auc did not improve from 0.75015\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0782 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7338 - val_loss: 0.2372 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.9174e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0697 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 23: val_auc improved from 0.75015 to 0.75559, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0697 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7556 - val_loss: 0.2342 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.9068e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0666 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 24: val_auc improved from 0.75559 to 0.75719, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0667 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7572 - val_loss: 0.3160 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.8956e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0634 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 25: val_auc did not improve from 0.75719\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0634 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7218 - val_loss: 0.2920 - val_sens_at_spec_85: 0.4255 - learning_rate: 4.8838e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0627 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 26: val_auc improved from 0.75719 to 0.78209, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0627 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7821 - val_loss: 0.2424 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.8713e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0576 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 27: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0576 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7759 - val_loss: 0.2138 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.8583e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0500 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 28: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0500 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7677 - val_loss: 0.4661 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.8446e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0512 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 29: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0513 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7321 - val_loss: 0.7195 - val_sens_at_spec_85: 0.4574 - learning_rate: 4.8303e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 30: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0534 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7601 - val_loss: 0.3046 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.8154e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0488 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 31: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0488 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7419 - val_loss: 0.2653 - val_sens_at_spec_85: 0.5000 - learning_rate: 4.7999e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0520 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 32: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0521 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7430 - val_loss: 0.3200 - val_sens_at_spec_85: 0.4468 - learning_rate: 4.7839e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0559 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 33: val_auc did not improve from 0.78209\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0559 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7722 - val_loss: 0.3369 - val_sens_at_spec_85: 0.4787 - learning_rate: 4.7672e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0554 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 34: val_auc improved from 0.78209 to 0.79139, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.0554 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7914 - val_loss: 0.3371 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.7499e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 35: val_auc improved from 0.79139 to 0.79557, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - auc: 0.0000e+00 - loss: 0.0408 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7956 - val_loss: 0.3332 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.7321e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0478 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 36: val_auc did not improve from 0.79557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0478 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7637 - val_loss: 0.2991 - val_sens_at_spec_85: 0.4894 - learning_rate: 4.7136e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0465 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 37: val_auc did not improve from 0.79557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0465 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7930 - val_loss: 0.4825 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.6946e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0457 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 38: val_auc did not improve from 0.79557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0457 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7799 - val_loss: 0.6021 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.6751e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0413 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 39: val_auc did not improve from 0.79557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0413 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7837 - val_loss: 0.3556 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.6549e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0391 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 40: val_auc did not improve from 0.79557\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0391 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7846 - val_loss: 0.6739 - val_sens_at_spec_85: 0.5851 - learning_rate: 4.6342e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0397 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 41: val_auc improved from 0.79557 to 0.81710, saving model to /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - auc: 0.0000e+00 - loss: 0.0398 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8171 - val_loss: 0.3607 - val_sens_at_spec_85: 0.6277 - learning_rate: 4.6130e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0383 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 42: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0383 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7999 - val_loss: 0.4311 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.5912e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0314 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 43: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0314 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7968 - val_loss: 0.4170 - val_sens_at_spec_85: 0.6170 - learning_rate: 4.5688e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 44: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0370 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7907 - val_loss: 0.4464 - val_sens_at_spec_85: 0.5851 - learning_rate: 4.5460e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0342 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 45: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0342 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7925 - val_loss: 0.6903 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.5225e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0318 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 46: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0318 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7904 - val_loss: 0.6691 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.4986e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0309 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 47: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0309 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7818 - val_loss: 0.5618 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.4742e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0307 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 48: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0308 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7865 - val_loss: 0.4086 - val_sens_at_spec_85: 0.6170 - learning_rate: 4.4492e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0295 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 49: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0295 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7883 - val_loss: 0.8263 - val_sens_at_spec_85: 0.5319 - learning_rate: 4.4237e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0305 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 50: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0305 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7855 - val_loss: 0.8459 - val_sens_at_spec_85: 0.5745 - learning_rate: 4.3977e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0297 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 51: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0298 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7778 - val_loss: 0.6372 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.3713e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0349 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 52: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0349 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7888 - val_loss: 0.8151 - val_sens_at_spec_85: 0.5426 - learning_rate: 4.3443e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0263 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 53: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0263 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7917 - val_loss: 0.5722 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.3169e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0330 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 54: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0329 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7995 - val_loss: 0.8265 - val_sens_at_spec_85: 0.6064 - learning_rate: 4.2890e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0236 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 55: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0237 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7872 - val_loss: 0.7060 - val_sens_at_spec_85: 0.6277 - learning_rate: 4.2606e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0293 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 56: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0292 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7660 - val_loss: 0.6160 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.2318e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0259 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 57: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0259 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7819 - val_loss: 0.8904 - val_sens_at_spec_85: 0.5106 - learning_rate: 4.2025e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0232 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 58: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0232 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7730 - val_loss: 0.6210 - val_sens_at_spec_85: 0.5213 - learning_rate: 4.1728e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0223 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 59: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0223 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7801 - val_loss: 1.0236 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.1427e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0174 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 60: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0175 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7842 - val_loss: 0.8877 - val_sens_at_spec_85: 0.5851 - learning_rate: 4.1121e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 61: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7814 - val_loss: 0.9438 - val_sens_at_spec_85: 0.5638 - learning_rate: 4.0811e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0271 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 62: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0272 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7750 - val_loss: 0.7549 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.0497e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0274 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 63: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0274 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7898 - val_loss: 0.8841 - val_sens_at_spec_85: 0.5532 - learning_rate: 4.0179e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0287 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 64: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0287 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7913 - val_loss: 0.8996 - val_sens_at_spec_85: 0.5851 - learning_rate: 3.9857e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0221 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 65: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0221 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7833 - val_loss: 0.8704 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.9531e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0192 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 66: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0192 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7751 - val_loss: 0.4656 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.9202e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0262 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 67: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0262 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7877 - val_loss: 0.4915 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.8868e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 68: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7977 - val_loss: 0.7345 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.8531e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 69: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0201 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7690 - val_loss: 0.9517 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.8191e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 70: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0197 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7895 - val_loss: 0.5878 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.7847e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0207 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 71: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0207 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7986 - val_loss: 0.5491 - val_sens_at_spec_85: 0.6064 - learning_rate: 3.7500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0192 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 72: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0192 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7864 - val_loss: 0.8539 - val_sens_at_spec_85: 0.5426 - learning_rate: 3.7150e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0177 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 73: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0178 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7978 - val_loss: 0.9200 - val_sens_at_spec_85: 0.6277 - learning_rate: 3.6796e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0185 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 74: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0185 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7797 - val_loss: 1.1114 - val_sens_at_spec_85: 0.5957 - learning_rate: 3.6439e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0160 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 75: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0160 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7810 - val_loss: 1.0139 - val_sens_at_spec_85: 0.5745 - learning_rate: 3.6080e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0134 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 76: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0134 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7719 - val_loss: 1.4299 - val_sens_at_spec_85: 0.6064 - learning_rate: 3.5717e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0214 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 77: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0214 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7909 - val_loss: 1.1058 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.5352e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0171 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 78: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0171 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.8004 - val_loss: 0.6558 - val_sens_at_spec_85: 0.5638 - learning_rate: 3.4984e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.0000e+00 - loss: 0.0206 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 79: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0206 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7651 - val_loss: 1.3880 - val_sens_at_spec_85: 0.5532 - learning_rate: 3.4614e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 80: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0141 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7741 - val_loss: 0.9307 - val_sens_at_spec_85: 0.5319 - learning_rate: 3.4241e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - auc: 0.0000e+00 - loss: 0.0131 - sens_at_spec_85: 0.0000e+00\n",
            "Epoch 81: val_auc did not improve from 0.81710\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - auc: 0.0000e+00 - loss: 0.0131 - sens_at_spec_85: 0.0000e+00 - val_auc: 0.7673 - val_loss: 1.2521 - val_sens_at_spec_85: 0.5000 - learning_rate: 3.3865e-04\n",
            "Epoch 81: early stopping\n",
            "Restoring model weights from the end of the best epoch: 41.\n",
            "\n",
            "Fold 5 Results:\n",
            "  loss: 0.3607\n",
            "  auc: 0.8171\n",
            "  sens_at_spec_85: 0.6277\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE - SUMMARY\n",
            "============================================================\n",
            "\n",
            "AUC across folds: 0.7489 ± 0.0624\n",
            "  Individual folds: ['0.7131', '0.7931', '0.7763', '0.6447', '0.8171']\n",
            "\n",
            "Results saved to: /content/NeuroFetal-AI/Reports/training_logs/training_log_20260212_192837.json\n",
            "\n",
            "============================================================\n",
            "✓ Training pipeline completed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Full 5-fold training — approx 2-3 hours on T4 GPU\n",
        "!python Code/scripts/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "push_models",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1105e79-2371-453e-e0be-91fd7677e2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pushing model for Fold 1...\n",
            "[main 6043d7e] Auto-save: Trained SOTA model Fold 1\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 23.47 MiB | 8.49 MiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   b215adf..6043d7e  main -> main\n",
            "✓ Fold 1 pushed.\n",
            "Pushing model for Fold 2...\n",
            "[main 261fd2b] Auto-save: Trained SOTA model Fold 2\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 23.48 MiB | 6.46 MiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   6043d7e..261fd2b  main -> main\n",
            "✓ Fold 2 pushed.\n",
            "Pushing model for Fold 3...\n",
            "[main 1dc2354] Auto-save: Trained SOTA model Fold 3\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 23.52 MiB | 6.03 MiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   261fd2b..1dc2354  main -> main\n",
            "✓ Fold 3 pushed.\n",
            "Pushing model for Fold 4...\n",
            "[main 13b2af3] Auto-save: Trained SOTA model Fold 4\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 23.40 MiB | 5.92 MiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   1dc2354..13b2af3  main -> main\n",
            "✓ Fold 4 pushed.\n",
            "Pushing model for Fold 5...\n",
            "[main b024ef2] Auto-save: Trained SOTA model Fold 5\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 23.49 MiB | 9.01 MiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   13b2af3..b024ef2  main -> main\n",
            "✓ Fold 5 pushed.\n"
          ]
        }
      ],
      "source": [
        "# Auto-push trained models to GitHub\n",
        "import os\n",
        "\n",
        "for fold in range(1, 6):\n",
        "    model_path = f\"Code/models/enhanced_model_fold_{fold}.keras\"\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Pushing model for Fold {fold}...\")\n",
        "        !git add {model_path}\n",
        "        !git commit -m \"Auto-save: Trained SOTA model Fold {fold}\"\n",
        "        !git push origin main\n",
        "        print(f\"✓ Fold {fold} pushed.\")\n",
        "    else:\n",
        "        print(f\"⚠️ Not found: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzEALoB7Xxvj",
        "outputId": "c983ad37-525b-4a62-9a23-3ae224fd804e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Krishna200608/NeuroFetal-AI\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_md"
      },
      "source": [
        "---\n",
        "## 5. Diverse Ensemble Training (Phase 5)\n",
        "\n",
        "Train three diverse model families and combine with a stacking meta-learner:\n",
        "\n",
        "1. **AttentionFusionResNet** — primary (already trained above)\n",
        "2. **1D-InceptionNet** — multi-scale temporal patterns (kernel 5/15/40)\n",
        "3. **XGBoost / LightGBM** — gradient boosting on tabular + CSP + FHR features\n",
        "\n",
        "Out-of-fold predictions across 5 folds → Logistic Regression stacking\n",
        "\n",
        "**Expected additional AUC lift: +3–5 pts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "run_ensemble_training",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081628d8-733f-44e7-e213-a9a1a4b38c4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NeuroFetal AI — Diverse Ensemble Training (Phase 5)\n",
            "============================================================\n",
            "\n",
            "Data: FHR=(2546, 1200, 1), Tab=(2546, 18), y=(2546,)\n",
            "Class balance: 18.5% positive\n",
            "2026-02-12 19:44:49.692368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770925489.713556   49678 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770925489.720456   49678 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770925489.736540   49678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770925489.736566   49678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770925489.736570   49678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770925489.736576   49678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-12 19:44:49.741602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "============================================================\n",
            "Fold 1/5\n",
            "============================================================\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "2026-02-12 19:44:54.713298: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770925494.714864   49678 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770925499.398810   49719 service.cc:152] XLA service 0x7cb744003980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1770925499.398842   49719 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-12 19:44:59.445476: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1770925499.791384   49719 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1770925503.051604   49719 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "    Model A fold 1 AUC: 0.6045\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "2026-02-12 19:45:20.050821: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:20.400371: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:21.277114: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:21.679384: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:21.722972: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.17 = (f32[32,80,1,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,1,150]{3,2,1,0} %bitcast.26438, f32[32,80,1,40]{3,2,1,0} %bitcast.26442), window={size=1x40 pad=0_0x19_19}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/InceptionFusionNet_1/inc2_conv40_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-12 19:45:22.068016: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:22.452784: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:22.844539: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:23.236212: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:23.562659: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:23.897380: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-12 19:45:23.917468: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.195183758s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.17 = (f32[32,80,1,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,1,150]{3,2,1,0} %bitcast.26438, f32[32,80,1,40]{3,2,1,0} %bitcast.26442), window={size=1x40 pad=0_0x19_19}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/InceptionFusionNet_1/inc2_conv40_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "    Model B fold 1 AUC: 0.8001\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:47:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8306\n",
            "\n",
            "============================================================\n",
            "Fold 2/5\n",
            "============================================================\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 2 AUC: 0.7535\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 2 AUC: 0.7853\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:49:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8493\n",
            "\n",
            "============================================================\n",
            "Fold 3/5\n",
            "============================================================\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 3 AUC: 0.7515\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 3 AUC: 0.8247\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:51:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8835\n",
            "\n",
            "============================================================\n",
            "Fold 4/5\n",
            "============================================================\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 4 AUC: 0.5583\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 4 AUC: 0.7650\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:53:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8800\n",
            "\n",
            "============================================================\n",
            "Fold 5/5\n",
            "============================================================\n",
            "\n",
            "  [Model A] AttentionFusionResNet...\n",
            "    Model A fold 5 AUC: 0.7684\n",
            "\n",
            "  [Model B] InceptionNet...\n",
            "    Model B fold 5 AUC: 0.8136\n",
            "\n",
            "  [Model C] XGBoost/LightGBM...\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [19:55:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "    XGBoost validation AUC: 0.8832\n",
            "\n",
            "============================================================\n",
            "OOF AUC Summary\n",
            "============================================================\n",
            "  model_a: 0.6873 ± 0.0878\n",
            "  model_b: 0.7978 ± 0.0210\n",
            "  model_c: 0.8653 ± 0.0216\n",
            "\n",
            "  Stacking Meta-Learner AUC: 0.8702\n",
            "  Meta-learner weights: [0.65078289 2.1338868  5.40926848]\n",
            "  Meta-learner bias: [-4.55415499]\n",
            "  Weighted Average AUC (w=[0.4, 0.3, 0.3]): 0.8386\n",
            "  Meta-learner saved to: /content/NeuroFetal-AI/Code/models/stacking_meta_learner.pkl\n",
            "\n",
            "Results saved to: /content/NeuroFetal-AI/Reports/training_logs/ensemble_log_20260212_195505.json\n",
            "\n",
            "✓ Diverse ensemble training complete!\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/train_diverse_ensemble.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "push_ensemble",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc313ec0-7668-4833-b57d-40e86444b58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 71a7b62] Auto-save: Diverse ensemble models (InceptionNet + XGB + meta-learner)\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 515 bytes | 515.00 KiB/s, done.\n",
            "Total 5 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   4779678..71a7b62  main -> main\n",
            "✓ Pushed 1 ensemble artifacts.\n"
          ]
        }
      ],
      "source": [
        "# Push ensemble artifacts\n",
        "import os\n",
        "\n",
        "ensemble_files = [\n",
        "    \"Code/models/stacking_meta_learner.pkl\",\n",
        "    \"Code/models/xgb_model.pkl\",\n",
        "]\n",
        "\n",
        "# Also push any InceptionNet fold models\n",
        "for fold in range(1, 6):\n",
        "    inception_path = f\"Code/models/inception_fold_{fold}.keras\"\n",
        "    if os.path.exists(inception_path):\n",
        "        ensemble_files.append(inception_path)\n",
        "\n",
        "pushed = []\n",
        "for f in ensemble_files:\n",
        "    if os.path.exists(f):\n",
        "        !git add {f}\n",
        "        pushed.append(f)\n",
        "\n",
        "if pushed:\n",
        "    !git commit -m \"Auto-save: Diverse ensemble models (InceptionNet + XGB + meta-learner)\"\n",
        "    !git push origin main\n",
        "    print(f\"✓ Pushed {len(pushed)} ensemble artifacts.\")\n",
        "else:\n",
        "    print(\"⚠️ No ensemble files found to push.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_5_md"
      },
      "source": [
        "---\n",
        "## 6. Evaluation & Calibration (Phase 6)\n",
        "\n",
        "**Stacking Ensemble Evaluation** with:\n",
        "- Temperature scaling (Guo et al., 2017)\n",
        "- Optimal threshold search (Youden's J / F1 / cost-sensitive)\n",
        "- Enhanced 3-pass TTA (original + flip + noise)\n",
        "- AUPRC reporting for imbalanced data\n",
        "\n",
        "**Uncertainty Quantification** via MC Dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "run_eval",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6462117e-08d7-47e1-bae5-8bc08160cf45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Stacking Ensemble Evaluation...\n",
            "2026-02-12 19:56:11.055900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770926171.085410   59865 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770926171.095424   59865 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770926171.111810   59865 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926171.111836   59865 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926171.111840   59865 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926171.111845   59865 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-12 19:56:11.116325: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "============================================================\n",
            "Ensemble & TTA Evaluation (SOTA with Calibration)\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Data shape: FHR=(2546, 1200, 1), Tab=(2546, 18), Labels=(2546,)\n",
            "Class balance: 18.5% positive\n",
            "\n",
            "--- Stacking Ensemble Evaluation ---\n",
            "  Stacking AUC: 0.8702\n",
            "  Model weights: [0.65078289 2.1338868  5.40926848]\n",
            "  AttentionFusionResNet AUC: 0.5779\n",
            "  InceptionNet AUC: 0.7831\n",
            "  XGBoost AUC: 0.8619\n",
            "\n",
            "--- Per-Fold Model A Evaluation ---\n",
            "\n",
            "--- Fold 1 ---\n",
            "2026-02-12 19:56:17.099703: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770926177.101281   59865 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770926183.520371   59912 service.cc:152] XLA service 0x7815540048b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1770926183.520402   59912 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-12 19:56:23.572720: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1770926183.935401   59912 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1770926187.218746   59912 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "  Fold 1 AUC (with TTA): 0.7051\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Fold 2 AUC (with TTA): 0.7753\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Fold 3 AUC (with TTA): 0.7860\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Fold 4 AUC (with TTA): 0.6397\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Fold 5 AUC (with TTA): 0.7800\n",
            "\n",
            "--- Temperature Scaling ---\n",
            "  Optimal temperature: 1.697\n",
            "  Calibrated AUC: 0.7311\n",
            "\n",
            "--- Optimal Threshold Search ---\n",
            "  Youden's J optimal threshold: 0.2175\n",
            "  At this threshold: Sensitivity=0.753, Specificity=0.839\n",
            "  F1 optimal threshold: 0.3253\n",
            "  At this threshold: Precision=0.616, Recall=0.649\n",
            "  Cost-sensitive threshold (FN penalty=3.0x): 0.2900\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "  Mean Fold AUC (Model A + TTA):       0.7372 ± 0.0569\n",
            "  Global OOF AUC (Raw):                0.7311\n",
            "  Global OOF AUC (Rank Normalized):    0.7374\n",
            "  Global OOF AUC (Calibrated):         0.7311\n",
            "  Stacking Ensemble AUC:               0.8702\n",
            "\n",
            "  Optimal Thresholds:\n",
            "    youden: 0.2175\n",
            "    f1: 0.3253\n",
            "    cost_sensitive: 0.2900\n",
            "    default: 0.5000\n",
            "\n",
            "  Classification Report (threshold=0.218):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.94      0.84      0.89      2076\n",
            " Compromised       0.51      0.75      0.61       470\n",
            "\n",
            "    accuracy                           0.82      2546\n",
            "   macro avg       0.73      0.80      0.75      2546\n",
            "weighted avg       0.86      0.82      0.83      2546\n",
            "\n",
            "  AUPRC (Average Precision): 0.6553\n",
            "\n",
            "  Results saved to: /content/NeuroFetal-AI/Reports/ensemble_analysis/evaluation_results_20260212_195721.json\n",
            "\n",
            "------------------------------------------------------------\n",
            "  🎯 TARGET ACHIEVED: AUC = 0.8702 (> 0.84)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Running Uncertainty Quantification (MC Dropout)...\n",
            "2026-02-12 19:57:23.893031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770926243.913436   60385 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770926243.920657   60385 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770926243.936472   60385 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926243.936504   60385 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926243.936508   60385 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926243.936511   60385 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-12 19:57:23.941090: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading data...\n",
            "Detailed: Loaded UC signals for CSP.\n",
            "\n",
            "Processing Fold 1...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "2026-02-12 19:57:31.187179: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770926251.188732   60385 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "I0000 00:00:1770926254.814548   60385 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.3964\n",
            "  Mean uncertainty: 0.1135\n",
            "  Max uncertainty: 0.2437\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.7046\n",
            "  Expected Calibration Error: 0.2121\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 390\n",
            "  High uncertainty samples: 120\n",
            "  AUC (low uncertainty): 0.7308\n",
            "  AUC (high uncertainty): 0.6277\n",
            "\n",
            "⚠️  Clinical Alert: 47 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_1/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_1/uncertainty_histogram.png\n",
            "Fold 1 AUC: 0.7046\n",
            "\n",
            "Processing Fold 2...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_2.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.2713\n",
            "  Mean uncertainty: 0.1262\n",
            "  Max uncertainty: 0.3077\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.7705\n",
            "  Expected Calibration Error: 0.0877\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 315\n",
            "  High uncertainty samples: 194\n",
            "  AUC (low uncertainty): 0.7928\n",
            "  AUC (high uncertainty): 0.6764\n",
            "\n",
            "⚠️  Clinical Alert: 54 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_2/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_2/uncertainty_histogram.png\n",
            "Fold 2 AUC: 0.7705\n",
            "\n",
            "Processing Fold 3...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_3.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.2840\n",
            "  Mean uncertainty: 0.1318\n",
            "  Max uncertainty: 0.3032\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.7718\n",
            "  Expected Calibration Error: 0.0994\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 310\n",
            "  High uncertainty samples: 199\n",
            "  AUC (low uncertainty): 0.8017\n",
            "  AUC (high uncertainty): 0.7744\n",
            "\n",
            "⚠️  Clinical Alert: 53 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_3/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_3/uncertainty_histogram.png\n",
            "Fold 3 AUC: 0.7718\n",
            "\n",
            "Processing Fold 4...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_4.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.6016\n",
            "  Mean uncertainty: 0.0469\n",
            "  Max uncertainty: 0.0899\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.6352\n",
            "  Expected Calibration Error: 0.4169\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 509\n",
            "  High uncertainty samples: 0\n",
            "  AUC (low uncertainty): 0.6352\n",
            "\n",
            "⚠️  Clinical Alert: 0 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_4/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_4/uncertainty_histogram.png\n",
            "Fold 4 AUC: 0.6352\n",
            "\n",
            "Processing Fold 5...\n",
            "\n",
            "============================================================\n",
            "MC Dropout Uncertainty Evaluation\n",
            "============================================================\n",
            "\n",
            "Loading model from: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_5.keras\n",
            "\n",
            "Performing 50 MC Dropout forward passes...\n",
            "\n",
            "Prediction Statistics:\n",
            "  Mean prediction: 0.3199\n",
            "  Mean uncertainty: 0.1451\n",
            "  Max uncertainty: 0.3340\n",
            "\n",
            "Performance Metrics:\n",
            "  AUC (MC mean): 0.7789\n",
            "  Expected Calibration Error: 0.1442\n",
            "\n",
            "Uncertainty Stratification (threshold=0.15):\n",
            "  Low uncertainty samples: 245\n",
            "  High uncertainty samples: 264\n",
            "  AUC (low uncertainty): 0.8399\n",
            "  AUC (high uncertainty): 0.6977\n",
            "\n",
            "⚠️  Clinical Alert: 88 high-risk predictions with high uncertainty\n",
            "   These cases should be flagged for additional clinical review.\n",
            "Calibration plot saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_5/calibration_curve.png\n",
            "Uncertainty histogram saved to: /content/NeuroFetal-AI/Reports/uncertainty_analysis/fold_5/uncertainty_histogram.png\n",
            "Fold 5 AUC: 0.7789\n",
            "\n",
            "============================================================\n",
            "Overall Evaluation Results (Mean across 5 folds)\n",
            "============================================================\n",
            "Mean AUC: 0.7322\n",
            "Mean ECE: 0.1920\n",
            "Mean Uncertainty: 0.1127\n",
            "\n",
            "Uncertainty evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning Stacking Ensemble Evaluation...\")\n",
        "!python Code/scripts/evaluate_ensemble.py\n",
        "\n",
        "print(\"\\nRunning Uncertainty Quantification (MC Dropout)...\")\n",
        "!python Code/scripts/evaluate_uncertainty.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5_md"
      },
      "source": [
        "---\n",
        "## 7. Launch Dashboard (Optional)\n",
        "\n",
        "Run the Streamlit dashboard from Colab via **ngrok** tunnel.\n",
        "\n",
        "> Requires `NGROK_AUTH_TOKEN` in Colab Secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_dashboard",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf35120a-0ee0-4a02-a7b1-71b79e5c34f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Ngrok Token loaded from Secrets.\n",
            "Launching Streamlit App...\n",
            "Authenticating with ngrok...\n",
            "Starting Streamlit Server...\n",
            "Attempting to open public tunnel...\n",
            "\n",
            "============================================================\n",
            "   DASHBOARD LIVE AT: https://beauteously-uncaped-dario.ngrok-free.dev\n",
            "   LOCAL ADDRESS:     http://localhost:8501\n",
            "============================================================\n",
            "\n",
            "Press Ctrl+C to stop the server.\n",
            "\n",
            "🛑 Stopping NeuroFetal AI Dashboard...\n",
            "   -> Terminating Streamlit process...\n",
            "\n",
            "🛑 Stopping NeuroFetal AI Dashboard...\n",
            "   -> Terminating Streamlit process...\n",
            "t=2026-02-12T20:02:34+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-bf8927d8-0823-4deb-858b-13443a08d196 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "t=2026-02-12T20:02:34+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-bf8927d8-0823-4deb-858b-13443a08d196 err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    print(\"✓ Ngrok Token loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Error loading NGROK_AUTH_TOKEN from Secrets. Falling back to manual input.\")\n",
        "    from getpass import getpass\n",
        "    auth_token = getpass(\"Enter Ngrok Auth Token manually: \")\n",
        "\n",
        "if auth_token:\n",
        "    with open(\"Code/.env\", \"w\") as f:\n",
        "        f.write(f\"NGROK_AUTH_TOKEN={auth_token}\\n\")\n",
        "\n",
        "print(\"Launching Streamlit App...\")\n",
        "!python Code/run_app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6_md"
      },
      "source": [
        "---\n",
        "## 8. Convert to TFLite & Auto-Push\n",
        "\n",
        "Convert the best trained model to TFLite format and push to GitHub automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "run_tflite",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8b2227-47f9-40cf-ad27-d6194d554a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-12 19:59:03.848454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770926343.871034   60893 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770926343.882783   60893 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770926343.906066   60893 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926343.906091   60893 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926343.906096   60893 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770926343.906100   60893 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-12 19:59:03.911112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "Model: /content/NeuroFetal-AI/Code/models/enhanced_model_fold_1.keras\n",
            "2026-02-12 19:59:09.655001: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770926349.656550   60893 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "✓ Keras Model Loaded\n",
            "Loading calibration data...\n",
            "  Fitting CSP Feature Extractor for calibration...\n",
            "  Extracting multi-modal features...\n",
            "  Data Loaded: FHR (2546, 1200, 1), Tab (2546, 18), Features (2546, 19)\n",
            "\n",
            "[1/2] Converting Standard TFLite Model...\n",
            "Saved artifact at '/tmp/tmpazvy_nim'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 1200, 1), dtype=tf.float32, name='input_fhr'), TensorSpec(shape=(None, 18), dtype=tf.float32, name='input_tabular'), TensorSpec(shape=(None, 19), dtype=tf.float32, name='input_csp')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139394935328016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935327248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935325136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935325904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935330704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935330896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935332048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935332432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935332240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917513744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917515088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917514320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935330512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935335312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935335120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935335888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917499728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917498960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917499344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912175504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912185104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912186448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912186064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912188176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912187792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912190288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909930704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909933200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909934544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917499536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912175312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917508368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917508176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917509520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917509328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917510480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909933392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909938192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909937424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909940304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909939920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909942800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909939728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909943184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394908966352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917509136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917510288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917512016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917512400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917512208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912180112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912180304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912182416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912183184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912182992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912183568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912182608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912183952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912181456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912184528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912175696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912184336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912180688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912181264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912181840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1770926365.744974   60893 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1770926365.745011   60893 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2026-02-12 19:59:25.745720: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpazvy_nim\n",
            "2026-02-12 19:59:25.754386: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2026-02-12 19:59:25.754409: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpazvy_nim\n",
            "I0000 00:00:1770926365.845722   60893 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "2026-02-12 19:59:25.861335: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2026-02-12 19:59:26.372653: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpazvy_nim\n",
            "2026-02-12 19:59:26.522766: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 777050 microseconds.\n",
            "2026-02-12 19:59:26.675004: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "  Saved: /content/NeuroFetal-AI/Code/models/tflite/neurofetal_model.tflite (6855.5 KB)\n",
            "\n",
            "[2/2] Converting Int8 Quantized Model (Edge Optimized)...\n",
            "Saved artifact at '/tmp/tmpobv5ci0_'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 1200, 1), dtype=tf.float32, name='input_fhr'), TensorSpec(shape=(None, 18), dtype=tf.float32, name='input_tabular'), TensorSpec(shape=(None, 19), dtype=tf.float32, name='input_csp')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139394935328016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935327248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935325136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935325904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935330704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935330896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935332048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935332432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935332240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935331664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917513744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917515088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917514320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935330512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935334544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935329360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935335312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935335120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935336080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935328976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935333008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935335888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935337424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935339920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935338768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394935340304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917499728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917498960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917499344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912175504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912185104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912186448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912186064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912188176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912187792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912190288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909933200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909934544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917500112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917503760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917502800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917499536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917501840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912175312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917504528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917508368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917508176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917506448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917509520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917509328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912176656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917507792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917510480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917505872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909933392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909938192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909937424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909940304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909939920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909942800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394909943184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394908966352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917509136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917510288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917512016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917511440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917512400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394917512208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912178192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912180112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912180304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912182416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912183184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912182992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912183568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912182608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912183952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912181456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912184528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912177808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912175696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912184336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912174544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912180688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912181264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912179344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139394912181840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "W0000 00:00:1770926372.608155   60893 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1770926372.608178   60893 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2026-02-12 19:59:32.608403: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpobv5ci0_\n",
            "2026-02-12 19:59:32.619315: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2026-02-12 19:59:32.619338: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpobv5ci0_\n",
            "2026-02-12 19:59:32.722824: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2026-02-12 19:59:33.254739: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpobv5ci0_\n",
            "2026-02-12 19:59:33.402801: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 794401 microseconds.\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "  Saved: /content/NeuroFetal-AI/Code/models/tflite/neurofetal_model_quant_int8.tflite (1951.0 KB)\n",
            "  Compression: 3.5x smaller\n"
          ]
        }
      ],
      "source": [
        "!python Code/scripts/convert_to_tflite.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "push_tflite",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8e7e0e-4c11-4a74-ea06-9bf0b7a5fb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 5e7a852] Auto-save: TFLite model\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " rewrite Code/models/tflite/neurofetal_model_quant_int8.tflite (75%)\n",
            "Enumerating objects: 11, done.\n",
            "Counting objects: 100% (11/11), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 1.64 MiB | 4.14 MiB/s, done.\n",
            "Total 6 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/Krishna200608/NeuroFetal-AI.git\n",
            "   71a7b62..5e7a852  main -> main\n",
            "✓ TFLite model pushed.\n"
          ]
        }
      ],
      "source": [
        "# Push TFLite model\n",
        "import os\n",
        "\n",
        "tflite_path = \"Code/models/tflite/neurofetal_model_quant_int8.tflite\"\n",
        "if os.path.exists(tflite_path):\n",
        "    !git add {tflite_path}\n",
        "    !git commit -m \"Auto-save: TFLite model\"\n",
        "    !git push origin main\n",
        "    print(\"✓ TFLite model pushed.\")\n",
        "else:\n",
        "    print(\"⚠️ TFLite model not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "done_md"
      },
      "source": [
        "---\n",
        "## ✅ Pipeline Complete\n",
        "\n",
        "All 6 SOTA phases have been executed. Check the evaluation output above for final AUC and calibration metrics."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}