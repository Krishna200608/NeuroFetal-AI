{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Baseline Model 2: Classical ML (Petrozziello et al., 2018)\n",
                "\n",
                "**Objective:** Reproduce Classical Machine Learning baselines (Logistic Regression, Random Forest) using handcrafted features.\n",
                "\n",
                "**Reference:** Petrozziello, A., et al. (2018). *Multimedia Information Retrieval for Multimodal Fetal Monitoring.*\n",
                "\n",
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import numpy as np\n",
                "import joblib\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import roc_auc_score, accuracy_score\n",
                "\n",
                "# --- GitHub & Colab Setup ---\n",
                "try:\n",
                "    from google.colab import userdata\n",
                "    \n",
                "    # 1. Clone Repo using Secret Token\n",
                "    token = userdata.get('GITHUB_AUTH_TOKEN')\n",
                "    repo_name = \"NeuroFetal-AI\"\n",
                "    username = \"Krishna200608\"\n",
                "    repo_url = f\"https://{token}@github.com/{username}/{repo_name}.git\"\n",
                "    \n",
                "    if not os.path.exists(repo_name):\n",
                "        print(f\"Cloning {repo_name}...\")\n",
                "        get_ipython().system(f\"git clone {repo_url}\")\n",
                "    \n",
                "    # 2. Configure Git\n",
                "    os.chdir(repo_name)\n",
                "    get_ipython().system('git config --global user.email \"krishnasikheriya001@gmail.com\"')\n",
                "    get_ipython().system('git config --global user.name \"Krishna200608\"')\n",
                "    \n",
                "    # 3. Install Dependencies\n",
                "    get_ipython().system('pip install wfdb')\n",
                "\n",
                "    BASE_DIR = os.getcwd()\n",
                "    sys.path.append(os.path.join(BASE_DIR, \"Code\", \"scripts\"))\n",
                "    print(\"Running in Colab (GitHub Integration Active)\")\n",
                "\n",
                "except ImportError:\n",
                "    # Local Fallback\n",
                "    BASE_DIR = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
                "    sys.path.append(os.path.abspath(os.path.join(\"..\", \"scripts\")))\n",
                "    print(\"Running Locally\")\n",
                "\n",
                "import data_ingestion\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Tabular Data\n",
                "Run `data_ingestion.py` if needed to generate `X_tabular.npy`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, \"Datasets\", \"processed\")\n",
                "X_path = os.path.join(PROCESSED_DATA_DIR, \"X_tabular.npy\")\n",
                "y_path = os.path.join(PROCESSED_DATA_DIR, \"y.npy\")\n",
                "\n",
                "# Check if data exists, if not, try ingestion\n",
                "if not os.path.exists(X_path) or not os.path.exists(y_path):\n",
                "    print(\"Tabular data not found. Running ingestion to extract features...\")\n",
                "    get_ipython().system(f\"python Code/scripts/data_ingestion.py\")\n",
                "\n",
                "try:\n",
                "    X_tabular = np.load(X_path)\n",
                "    y = np.load(y_path)\n",
                "    print(f\"Loaded tabular features: {X_tabular.shape}\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Features not found. Ensure ingestion ran successfully.\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train & Evaluate Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "\n",
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=2000),\n",
                "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "}\n",
                "\n",
                "scores = {name: {'auc': [], 'acc': []} for name in models}\n",
                "X = np.nan_to_num(X_tabular, nan=0.0)\n",
                "\n",
                "print(\"Starting Cross-Validation...\")\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
                "    print(f\"Fold {fold+1}\")\n",
                "    X_train, X_val = X[train_idx], X[val_idx]\n",
                "    y_train, y_val = y[train_idx], y[val_idx]\n",
                "    \n",
                "    scaler = StandardScaler()\n",
                "    X_train_scaled = scaler.fit_transform(X_train)\n",
                "    X_val_scaled = scaler.transform(X_val)\n",
                "    \n",
                "    for name, model in models.items():\n",
                "        clf = model\n",
                "        if name == \"Random Forest\":\n",
                "            clf.fit(X_train, y_train)\n",
                "            input_val = X_val\n",
                "        else:\n",
                "            clf.fit(X_train_scaled, y_train)\n",
                "            input_val = X_val_scaled\n",
                "            \n",
                "        if hasattr(clf, \"predict_proba\"):\n",
                "            y_pred_prob = clf.predict_proba(input_val)[:, 1]\n",
                "        else:\n",
                "            y_pred_prob = clf.predict(input_val)\n",
                "            \n",
                "        acc = accuracy_score(y_val, (y_pred_prob > 0.5).astype(int))\n",
                "        auc = roc_auc_score(y_val, y_pred_prob)\n",
                "        \n",
                "        scores[name]['auc'].append(auc)\n",
                "        scores[name]['acc'].append(acc)\n",
                "        \n",
                "        # Save Model (Update: Saving the last fold model for checking)\n",
                "        model_dir = os.path.join(BASE_DIR, \"Code\", \"Baseline\", \"Models\")\n",
                "        os.makedirs(model_dir, exist_ok=True)\n",
                "        \n",
                "        model_path = os.path.join(model_dir, f\"baseline_paper4_{name.replace(' ', '_')}.pkl\")\n",
                "        joblib.dump(clf, model_path)\n",
                "\n",
                "print(\"\\n=== Results ===\")\n",
                "for name in models:\n",
                "    print(f\"{name} AUC: {np.mean(scores[name]['auc']):.4f} +/- {np.std(scores[name]['auc']):.4f}\")\n",
                "    print(f\"{name} Acc: {np.mean(scores[name]['acc']):.4f}\")\n",
                "\n",
                "print(f\"Models saved to {model_dir}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Save Results & Push to GitHub\n",
                "results_path = os.path.join(BASE_DIR, \"Code\", \"Baseline\", \"baseline_paper4_results.txt\")\n",
                "\n",
                "with open(results_path, \"w\") as f:\n",
                "    f.write(f\"Ref: Paper 4 (Petrozziello 2018) - Classical ML Baseline (Colab Run)\\n\")\n",
                "    for name in models:\n",
                "        mean_auc = np.mean(scores[name]['auc'])\n",
                "        std_auc = np.std(scores[name]['auc'])\n",
                "        mean_acc = np.mean(scores[name]['acc'])\n",
                "        f.write(f\"{name}: AUC {mean_auc:.4f} +/- {std_auc:.4f}, Acc {mean_acc:.4f}\\n\")\n",
                "print(f\"Results saved to {results_path}\")\n",
                "\n",
                "# Git Commit & Push\n",
                "try:\n",
                "    if 'google.colab' in sys.modules:\n",
                "        print(\"Pushing results to GitHub...\")\n",
                "        os.chdir(BASE_DIR)\n",
                "        \n",
                "        get_ipython().system('git config --global user.email \"krishnasikheriya001@gmail.com\"')\n",
                "        get_ipython().system('git config --global user.name \"Krishna200608\"')\n",
                "        \n",
                "        get_ipython().system('git pull origin main')\n",
                "        get_ipython().system('git add Code/Baseline/Models/*.pkl Code/Baseline/*.txt')\n",
                "        get_ipython().system('git commit -m \"Update Classical ML Baseline Results (Colab)\"')\n",
                "        get_ipython().system('git push origin main')\n",
                "        print(\"Successfully pushed to GitHub!\")\n",
                "except Exception as e:\n",
                "    print(f\"Git Push Failed: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}